pgh
%43
\chapter{Построение абстракций~с помощью процедур}
\label{BUILDING-ABSTRACTIONS-WITH-PROCEDURES}
%\markboth{Глава 1 \qquad Построение абстракций~с помощью процедур}{}
\thispagestyle{empty}

\epigraph{
Действия, в которых ум проявляет свои способности в отношении
своих простых идей, суть главным образом следующие три: 1)~Соединение
нескольких простых идей в одну сложную; так образовались все сложные
идеи,  2)~Сведение вместе двух идей, все равно, простых или сложных, и
сопоставление их друг с другом так, чтобы обозревать их сразу, но не
соединять в одну; так ум приобретает все свои идеи отношений, 3)~Обособление 
идей от всех других идей, сопутствующих им в реальной
действительности; это действие называется <<абстрагированием>>, и при
его помощи образованы все общие идеи в уме.
\index{ru}{Локк, Джон||John Locke||n|}%
\index{en}{John Locke||Локк, Джон||n|}%
\index{ru}{Савин,~А.Н.||||n|}}%
{Джон Локк. \\
%\textit{
<<Опыт~о человеческом разуме>> (1690) \\ %}
(Перевод А.Н.~Савина)}

Мы собираемся изучать понятие
\index{ru}{процесс||process|||}\index{en}{process||процесс|||}%
\index{ru}{вычислительный процесс||computational process|||}\index{en}{computational process||вычислительный процесс|||}{\em вычислительного процесса} (com\-pu\-ta\-ti\-o\-nal process).
Вычислительные процессы --- это абстрактные
существа, которые живут~в компьютерах.  Развиваясь, процессы
манипулируют абстракциями другого типа, которые называются
\index{ru}{данные||data|||}\index{en}{data||данные|||}{\em дан\-ными} (data). Эволюция процесса направляется набором
правил, называемым \index{ru}{программа||program|||}\index{en}{program||программа|||}{\em программой} (program).~В сущности, мы
заколдовываем духов компьютера~с помощью своих чар.


Вычислительные процессы~и вправду вполне соответствуют представлениям
колдуна~о д\'ухах.  Их нельзя увидеть или
потрогать.  Они вообще сделаны не из вещества. В то же время они
совершенно реальны.  Они могут выполнять умственную работу, могут
отвечать на вопросы. Они способны воздействовать на внешний мир,
оплачивая счета~в банке или управляя рукой робота на заводе.
Программы, которыми мы пользуемся для заклинания процессов, похожи
на чары колдуна.  Они тщательно составляются из символических
выражений на сложных~и немногим известных \index{ru}{язык программирования||programming language|||}\index{en}{programming language||язык программирования|||}{\em языках
программирования} (programming languages), описывающих задачи, которые мы хотим
поручить процессам.

На исправно работающем компьютере вычислительный процесс
выполняет программы точно~и безошибочно. Таким образом, подобно
ученику чародея, про\-грам\-мис\-ты-но\-вич\-ки должны научиться понимать и
предсказывать последствия своих заклинаний.  Даже мелкие ошибки
(их обычно называют\index{ru}{блоха||bug|||}\index{en}{bug||блоха|||} {\em блохами} (bugs)
или {\em глюками} (glitches))\index{ru}{глюк||glitch|||}\index{en}{glitch||глюк|||}, могут привести~к сложным~и 
непредсказуемым последствиям.

К счастью, обучение программированию не так опасно, как
обучение колдовству, поскольку духи,~с которыми мы имеем дело, надежно
связаны.  В то же время программирование~в реальном мире
требует осторожности, профессионализма~и мудрости.  Например, мелкая
ошибка в программе автоматизированного проектирования может привести~к 
катастрофе самолета, прорыву плотины или самоуничтожению промышленного 
робота.

Специалисты по программному обеспечению умеют организовывать
программы так, чтобы быть потом обоснованно уверенными: 
получившиеся процессы будут выполнять те задачи, для которых они
предназначены.  Они могут изобразить поведение системы заранее.  Они
знают, как построить программу так, чтобы непредвиденные проблемы не
привели~к катастрофическим последствиям,~а когда эти проблемы
возникают, программисты умеют\index{ru}{отладка||debugging|||}\index{en}{debugging||отладка|||}{\em отлаживать} (debug) свои
программы.
Хорошо спроектированные вычислительные системы, подобно хорошо
спроектированным автомобилям или ядерным реакторам, построены модульно, 
так что их части могут создаваться, заменяться~и отлаживаться по
отдельности.

\paragraph{Программирование на Лиспе}


Для описания процессов нам нужен подходящий язык,~и~с этой 
целью мы используем язык программирования Лисп.  Точно так же, как
обычные наши мысли чаще всего выражаются на естественном языке
(например, английском, французском или японском),~а описания
количественных явлений выражаются языком математики, наши процедурные
мысли будут выражаться на Лиспе. \index{ru}{Lisp (Лисп)|история||||} Лисп был изобретен~в конце 1950-х как
формализм для рассуждений об определенном типе логических выражений,
называемых \index{ru}{уравнения рекурсии||recursion   equations|||}\index{en}{recursion   equations||уравнения рекурсии|||}{\em уравнения рекурсии} (recursion   equations), как~о модели
вычислений.  Язык был придуман Джоном Маккарти
\index{ru}{Маккарти, Джон||John McCarthy||n|}\index{en}{John McCarthy||Маккарти, Джон||n|}
и основывается на его
статье <<Рекурсивные функции над символьными выражениями~и их
вычисление~с помощью машины>> (McCarthy 1960).

Несмотря на то, что Лисп возник как математический
формализм, это практический язык программирования.
\index{ru}{интерпретатор||interpreter|||}\index{en}{interpreter||интерпретатор|||}{\em Интерпретатор} (interpreter) Лиспа представляет
собой машину, 
которая выполняет процессы, описанные на языке Лисп.
Первый интерпретатор Лиспа написал сам Маккарти~с помощью
коллег~и студентов из Группы по Искусственному Интеллекту
\index{ru}{MIT|Исследовательская лаборатория по Электронике||||} Исследовательской лаборатории по Электронике MIT и
Вычислительного центра MIT\footnote{{\em Руководство программиста по Лиспу 1} появилось~в 1960 году,~а {\em Руководство
программиста по Лиспу~1.5} (McCarthy 1965)\index{ru}{Маккарти, Джон||John McCarthy||n|п}\index{en}{John McCarthy||Маккарти, Джон||n|п} в 1965 году.  Ранняя история Лиспа описана~в 
McCarthy 1978.
}.
\index{ru}{Lisp (Лисп)|сокращение от LISt Processing||||}%
Лисп, чье название происходит от сокращения английских слов LISt
Processing (обработка списков), был создан~с целью обеспечить
возможность символьной обработки для решения таких программистских
задач, как символьное дифференцирование~и интегрирование
алгебраических выражений.~С этой целью он содержал новые объекты данных, 
известные под названием атомов~и списков, что резко отличало его от
других языков того времени.

Лисп не был результатом срежиссированного проекта.
Он развивался не\-фор\-маль\-но, экспериментальным путем,~с учетом  
запросов пользователей~и прагматических соображений реализации.
Неформальная эволюция Лиспа продолжалась долгие годы,~и сообщество
пользователей Лиспа традиционно отвергало попытки провозгласить
какое-либо <<официальное>> описание языка.  Вместе~с гибкостью и
изяществом первоначального замысла такая эволюция позволила Лиспу,
который сейчас по возрасту второй из широко используемых языков (старше только
\index{ru}{Fortran (Фортран)|||||}Фортран), непрерывно адаптироваться~и вбирать~в себя
наиболее современные идеи~о проектировании программ.  Таким образом,
сегодня Лисп представляет собой семью диалектов, которые, хотя и
разделяют большую часть изначальных свойств, могут существенным
образом друг от друга отличаться.  Тот диалект, которым мы пользуемся~в 
этой книге, называется 
\index{ru}{диалекты Лиспа|Scheme  (Схема)|Lisp
  dialects|||}\index{en}{Lisp dialects||диалекты Лиспа|Scheme
  (Схема)||}\index{ru}{Scheme (Схема)|||||}Scheme
(Схема)\footnote{Большинство крупных
Лисп-программ 1970х, были написаны на одном из двух диалектов:
\index{ru}{диалекты Лиспа|MacLisp (МакЛисп)||||п}\index{ru}{MacLisp (МакЛисп)|||||п}MacLisp 
(Moon 1978;\index{ru}{Мун, Дэвид~А.||David~A. Moon||n|п}\index{en}{David~A. Moon||Мун, Дэвид~А.||n|п} Pitman 1983),\index{ru}{Питман, Кент||Kent Pitman||n|п}\index{en}{Kent Pitman||Питман, Кент||n|п}
разработанный~в рамках  
\index{ru}{MIT|проект MAC||||п}проекта MAC~в MIT, и
\index{ru}{диалекты Лиспа|InterLisp (ИнтерЛисп)||||п}\index{ru}{InterLisp (ИнтерЛисп)|||||п}%
InterLisp (Teitelman 1974),\index{ru}{Тейтельман, Уоррен||Warren
  Teitelman||n|п}\index{en}{Warren Teitelman||Тейтельман, Уоррен||n|п}
разработанный~в компании <<Болт, Беранек~и Ньюман>>\index{ru}{<<Болт,
  Беранек~и Ньюман>>||Bolt, Beranek and Newman,
  inc.||n|п}\index{en}{Bolt, Beranek and Newman, inc.||<<Болт, Беранек
 и Ньюман>>||n|п}
и~в 
\index{ru}{Xerox, исследовательский центр~в Пало Альто||Xerox Palo
  Alto Research Center|||п}\index{en}{Xerox Palo Alto Research
  Center||Xerox, исследовательский центр~в Пало
  Альто|||п}Исследовательском центре компании Xerox~в Пало
Альто. Диалект
\index{ru}{диалекты Лиспа|Portable Standard Lisp (Переносимый
  Стандартный Лисп)||||п}\index{ru}{Portable Standard Lisp
  (Переносимый Стандартный Лисп)|||||п}Portable Standard Lisp
(Переносимый Стандартный Лисп,
Hearn 1969; Griss 1981)\index{ru}{Грисс, Мартин Льюис||Martin Lewis
  Griss||n|п}\index{en}{Martin Lewis Griss||Грисс, Мартин
  Льюис||n|п}\index{ru}{Херн,
  Энтони~К.||Anthony~C. Hearn||n|п}\index{en}{Anthony~C. Hearn||Херн,
  Энтони~К.||n|п}
был спроектирован так, чтобы его легко было переносить на разные
машины. MacLisp породил несколько поддиалектов, например 
\index{ru}{диалекты Лиспа|Franz Lisp (Франц
  Лисп)||||п}\index{ru}{Franz Lisp (Франц Лисп)|||||п}Franz Lisp, разработанный~в 
\index{ru}{Калифорнийский университет~в Беркли||University of
  California at Berkeley|||п}\index{en}{University of California at
  Berkeley||Калифорнийский университет~в Беркли|||п}Калифорнийском университете~в Беркли,~и 
\index{ru}{диалекты Лиспа|Zetalisp (Зеталисп)||||п}\index{ru}{Zetalisp
  (Зеталисп)|||||п}Zetalisp (Moon 1981), который основывался на
специализированном процессоре, спроектированном~в 
\index{ru}{MIT|лаборатория Искусственного Интеллекта||||п}лаборатории
Искусственного Интеллекта~в MIT для наиболее эффективного
выполнения программ на Лиспе.  Диалект Лиспа, используемый~в этой книге, 
называется  
\index{ru}{Scheme (Схема)|история||||п}Scheme (Steele 1975).  Он был изобретен в
1975 году Гаем Льюисом Стилом мл.~и Джеральдом Джеем
Сассманом\index{ru}{Стил, Гай Льюис мл.||Guy Lewis Steele
  Jr.||n|п}\index{en}{Guy Lewis Steele Jr.||Стил, Гай Льюис
  мл.||n|п}\index{ru}{Сассман, Джеральд Джей||Gerald Jay
  Sussman||n|п}\index{en}{Gerald Jay Sussman||Сассман, Джеральд
  Джей||n|п}
в лаборатории Искусственного Интеллекта MIT,~а затем заново реализован
для использования~в учебных целях~в MIT. Scheme стала стандартом IEEE
в 1990 году (IEEE 1900).  Диалект  
\index{ru}{диалекты Лиспа|Common Lisp||||п}\index{ru}{Common
  Lisp|||||п}Common Lisp (Steele 1982; Steele 1990)
был специально разработан Лисп-сообществом так, чтобы сочетать свойства более
ранних диалектов Лиспа~и стать промышленным стандартом Лиспа. Common
Lisp стал стандартом ANSI~в 1994 году (ANSI 1994).
}.

Из-за своего экспериментального характера~и внимания к
символьной обработке первое время\index{ru}{Lisp (Лисп)|эффективность||||}\index{ru}{эффективность|Лиспа||||} Лисп был весьма неэффективен при решении вычислительных задач, по крайней мере по сравнению~с 
\index{ru}{Lisp (Лисп)|vs. Фортран||||} Фортраном.
Однако за прошедшие годы были разработаны компиляторы Лиспа, которые
переводят программы~в машинный код, способный производить численные
вычисления~с разумной эффективностью. А для специализированных
приложений Лисп удавалось использовать весьма эффективно\footnote{Одним из таких приложений был пионерский эксперимент,
имевший научное значение --- интегрирование движения Солнечной системы,
которое превосходило по точности предыдущие результаты примерно на два 
порядка~и продемонстрировало, что 
\index{ru}{хаос~в динамике Солнечной системы||chaos in Solar
  system|||п}\index{en}{chaos in Solar system||хаос~в динамике
  Солнечной системы|||п}динамика Солнечной системы хаотична.
Это вычисление стало возможным благодаря новым алгоритмам
интегрирования, специализированному компилятору~и специализированному
компьютеру; причем все они были реализованы~с помощью программных
средств, написанных на Лиспе (Abelson et al. 1992;
Sussman and Wisdom 1992).\index{ru}{Абельсон, Харольд||Harold
  Abelson||n|п}\index{en}{Harold Abelson||Абельсон,
  Харольд||n|п}\index{ru}{Сассман, Джеральд Джей||Gerald Jay
  Sussman||n|п}\index{en}{Gerald Jay Sussman||Сассман, Джеральд
  Джей||n|п}\index{ru}{Уиздом, Джек||Jack Wisdom||n|п}\index{en}{Jack
  Wisdom||Уиздом, Джек||n|п}
}.
Хотя Лисп~и не преодолел пока свою старую репутацию безнадежно
медленного языка,~в наше время он используется во многих
приложениях, где эффективность не является главной заботой.  Например, 
Лисп стал любимым языком для оболочек операционных систем,~а также в
качестве языка расширения для редакторов~и систем автоматизированного
проектирования\-.

Но коль скоро Лисп не похож на типичные языки, почему же мы тогда
используем его как основу для нашего разговора~о программировании?
\index{ru}{Lisp (Лисп)|уникальные свойства||||}
Потому что этот язык обладает уникальными свойствами, которые делают
его замечательным средством для изучения важнейших конструкций
программирования~и структур данных,~а также для соотнесения их с
деталями языка, которые их поддерживают.  Самое существенное из этих свойств~--- то, что лисповские описания процессов, называемые
\index{ru}{процедура||procedure|||}\index{en}{procedure||процедура|||}{\em процедурами} (procedures)\index{ru}{процедура|как данные||||}, сами по себе могут
представляться~и 
обрабатываться как данные Лиспа.
Важность этого~в том, что существуют мощные методы проектирования
программ, которые опираются на возможность сгладить традиционное
различение <<пассивных>> данных~и <<активных>> процессов.
Как мы обнаружим, способность Лиспа рассматривать процедуры~в качестве 
данных делает его одним из самых удобных языков для исследования этих
методов.  Способность представлять процедуры~в качестве данных делает Лисп
еще~и замечательным языком для написания программ, которые должны
манипулировать другими программами~в качестве данных, таких как
интерпретаторы~и компиляторы, поддерживающие компьютерные языки.  А
помимо~и превыше всех этих соображений, писать программы на Лиспе~--- 
громадное удовольствие.

\section{Элементы программирования}
\label{THE-ELEMENTS-OF-PROGRAMMING}

\index{ru}{программирование|элементы||||}
Мощный язык программирования~--- это нечто большее. чем
просто средство,~с помощью которого можно учить компьютер решать
задачи.  Язык также служит средой,~в которой мы организуем свое
мышление~о процессах.  Таким образом, когда мы описываем язык, мы
должны уделять особое внимание тем средствам, которые в нем имеются
для того, чтобы комбинировать простые понятия~и получать
из них сложные.  Всякий язык программирования обладает тремя
предназначенными для этого механизмами:

      
\begin{description}

\item[элементарные выражения,]\index{ru}{элементарные выражения||primitive expressions|||}\index{en}{primitive expressions||элементарные выражения|||}
представляющие минимальные сущности,~с 
которыми язык имеет дело;
{\sloppy

}%HERE!
\item[средства комбинирования,]\index{ru}{средства комбинирования||means of cvombination|||}\index{en}{means of cvombination||средства комбинирования|||}
с помощью которых из простых объектов
составляются сложные;
\item[средства абстракции,]\index{ru}{средства абстракции||means of abstraction|||}\index{en}{means of abstraction||средства абстракции|||}
с помощью которых сложные объекты можно называть~и 
обращаться~с ними как~с единым целым.

\sloppy
\end{description}

В программировании мы имеем дело~с двумя типами объектов:
\index{ru}{процедура|||||}процедурами~и\index{ru}{данные|||||} данными.  (Впоследствии мы обнаружим, что на самом деле большой
разницы между ними нет.)  Говоря неформально, данные~--- это
<<материал>>, который мы хотим обрабатывать, а процедуры~--- это
описания правил обработки данных.  Таким образом, от любого мощного языка
программирования требуется способность описывать простые данные и
элементарные процедуры, а также наличие средств
комбинирования и абстракции процедур и данных.

В этой главе мы будем работать только~с простыми 
\index{ru}{данные|численные||||} 
\index{ru}{численные данные||numerical data|||}\index{en}{numerical data||численные данные|||} 
численными данными, так что мы сможем сконцентрировать внимание на
правилах построения процедур\footnote{Называть числа <<простыми данными>>~--- это бесстыдный 
блеф.  На самом деле работа~с числами является одной из самых сложных
и запутанных сторон любого языка программирования. Вот некоторые из
возникающих при этом вопросов: Некоторые компьютеры отличают
\index{ru}{числа|целые vs. вещественные||||п}\index{ru}{целые
  числа||integers|||п}\index{en}{integers||целые
  числа|||п}\index{ru}{числа|целые|numbers|integer||п}\index{en}{numbers|integer|числа|целые||п}{\em целые числа} (integers), вроде 2, от
\index{ru}{числа|вещественные|numbers|real||п}\index{en}{numbers|real|числа|вещественные||п}{\em вещественных} (real numbers), вроде 2.71.
Отличается ли вещественное число 2.00 от целого 2?  Используются ли
одни~и те же арифметические операции для целых~и для вещественных
чисел?  Что получится, если 6 поделить на 2: 3 или 3.0? Насколько
большие числа мы можем представить?  Сколько десятичных цифр после
запятой мы можем хранить?  Совпадает ли диапазон целых чисел с
диапазоном вещественных? И помимо этих вопросов, разумеется,
существует множество проблем, связанных~с 
\index{ru}{ошибка округления||roundoff error|||п}\index{en}{roundoff error||ошибка округления|||п} 
ошибками округления --- целая наука 
\index{ru}{численный анализ||numerical analysis|||п}\index{en}{numerical analysis||численный анализ|||п} 
численного анализа.  
Поскольку~в этой книге мы говорим о
проектировании больших программ,~а не~о численных методах, все эти
проблемы мы будем игнорировать.  Численные примеры~в этой главе будут
демонстрировать такое поведение при округлении, какое можно наблюдать, 
если использовать арифметические операции, сохраняющие при работе с
вещественными числами ограниченное число десятичных цифр после
запятой.
}.
В последующих главах мы увидим, что те же самые правила позволяют
нам строить процедуры для работы со сложными данными.

\subsection{Выражения}
\label{EXPRESSIONS}


Самый простой способ начать обучение
программированию --- рассмотреть несколько типичных
примеров работы~с интерпретатором диалекта Лиспа Scheme.
Представьте, что Вы сидите за терминалом компьютера.  Вы печатаете
\index{ru}{выражение||expression|||}\index{en}{expression||выражение|||}{\em выражение} (expression),~а интерпретатор отвечает, выводя
результат \index{ru}{вычисление||evaluation|||}\index{en}{evaluation||вычисление|||}{\em вычисления} (evaluation) этого выражения.

\index{ru}{числа|в Лиспе|numbers|||}\index{en}{numbers||числа|в Лиспе||}
Один из типов\index{ru}{элементарные выражения|числа||||} элементарных выражений, которые Вы можете вводить ---
это числа.  (Говоря точнее, выражение, которое Вы печатаете, состоит
из цифр, представляющих число по основанию 10.)  Если Вы дадите Лиспу
число

\begin{Verbatim}[fontsize=\small]
486
\end{Verbatim}
интерпретатор ответит Вам, напечатав\footnote{\index{ru}{нотация в
    настоящей книге|наклонный шрифт для ответов
    интерпретатора|notation in this book|||п}\index{en}{notation
    in this book||нотация~в настоящей книге|наклонный шрифт для
    ответов интерпретатора||п}Здесь~и далее, когда нам нужно
будет
подчеркнуть разницу между вводом, который набирает на терминале пользователь,~и выводом,
который производит компьютер, мы будем изображать последний наклонным
шрифтом.
}

\begin{Verbatim}[fontsize=\small]
\textit{486}
\end{Verbatim}

Выражения, представляющие числа, могут сочетаться 
\index{ru}{комбинация|||||}с
\index{ru}{элементарные выражения|имя элементарной
  процедуры||||}выражением, представляющим
\index{ru}{арифметика|элементарные
  процедуры|arithmetic|||}\index{en}{arithmetic||арифметика|элементарные процедуры||}элементарную
процедуру (скажем,
{\tt +\index{ru}{+ (элементарная процедура сложения)||||pd|}\index{ru}{элементарные процедуры|{\tt +}||||}} или 
{\tt *\index{ru}{элементарные процедуры|{\tt *}||||}\index{ru}{*
    (элементарная процедура умножения)||||pd|}}), так что
получается\index{ru}{составное выражение||compound
  expression|||}\index{en}{compound expression||составное
  выражение|||}
составное выражение, представляющее собой применение процедуры~к этим
числам. Например:
{\sloppy

}
\begin{Verbatim}[fontsize=\small]
(+ 137 349)
\textit{486}

(- 1000 334)\index{ru}{элементарные процедуры|{\tt -}||||}
\textit{666}

(* 5 99)
\textit{495}

(/ 10 5)\index{ru}{элементарные процедуры|{\tt /}||||}
\textit{2}

(+ 2.7 10)
\textit{12.7}
\end{Verbatim}
\index{ru}{- (элементарная процедура вычитания)||||pd|}
\index{ru}{/ (элементарная процедура деления)||||pd|}

Выражения такого рода, образуемые путем заключения
списка выражений~в\index{ru}{скобки|обозначение применения функции~к аргументам||||} скобки~с целью обозначить применение 
функции~к аргументам, называются 
\index{ru}{применение процедур|обозначение комбинаций||||}
\index{ru}{комбинация||combination|||}\index{en}{combination||комбинация|||}{\em комбинациями} (combi\-na\-tions).
Самый левый элемент~в списке называется\index{ru}{оператор
  комбинации|||||}\index{ru}{оператор комбинации||operator of a
  combination|||}\index{en}{operator of a combination||оператор
  комбинации|||}{\em оператором} (operator),~а остальные элементы~---
\index{ru}{операнды комбинации||operands of a
  combination|||}\index{en}{operands of a combination||операнды
  комбинации|||}{\em операндами} (operands).
\index{ru}{значение|комбинации|value|||}\index{en}{value||значение|комбинации||}Значение
комбинации вычисляется путем применения процедуры, задаваемой
оператором,~к\index{ru}{аргумент(ы)||argument(s)|||}\index{en}{argument(s)||аргумент(ы)|||}{\em аргументам} (arguments), которые являются
значениями операндов.

Соглашение, по которому оператор ставится слева от 
операндов, известно как \index{ru}{префиксная нотация||prefix notation|||}\index{en}{prefix notation||префиксная нотация|||}{\em пре\-фикс\-ная нотация} (prefix notation), и
поначалу оно может сбивать~с толку, поскольку существенно
отличается от общепринятой математической записи.  Однако~у префиксной нотации есть несколько преимуществ.  Одно из них состоит~в том, что 
префиксная запись может распространяться на процедуры~с 
\index{ru}{аргумент(ы)|произвольное
  количество||||}\index{ru}{процедура|произвольное количество
  аргументов||||}произвольным количеством аргументов, как~в следующих
примерах:

\begin{Verbatim}[fontsize=\small]
(+ 21 35 12 7)
\textit{75}

(* 25 4 12)
\textit{1200}
\end{Verbatim}
Не возникает никакой неоднозначности, поскольку оператор 
всегда находится слева,~а вся комбинация ограничена скобками.

Второе преимущество префиксной нотации состоит~в том,
что она естественным образом расширяется, позволяя комбинациям
\index{ru}{вложение комбинаций||nested
  combinations|||}\index{en}{nested combinations||вложение
  комбинаций|||}{\em вкладываться} (nest) друг~в друга, то есть
допускает
комбинации, элементы которых сами являются комбинациями:

\begin{Verbatim}[fontsize=\small]
(+ (* 3 5) (- 10 6))
\textit{19}
\end{Verbatim}

Не существует (в принципе) никакого предела для глубины
такого вложения~и общей сложности выражений, которые может вычислять
интерпретатор Лиспа.  Это мы, люди, путаемся даже~в довольно простых
выражениях, например

\begin{Verbatim}[fontsize=\small]
(+ (* 3 (+ (* 2 4) (+ 3 5))) (+ (- 10 7) 6))
\end{Verbatim}
а интерпретатор~с готовностью вычисляет его~и дает ответ 57.  Мы
можем облегчить себе задачу, записывая такие выражения~в форме

\begin{Verbatim}[fontsize=\small]
(+ (* 3
      (+ (* 2 4)
         (+ 3 5)))
   (+ (- 10 7)
      6))
\end{Verbatim}
Эти правила форматирования называются \index{ru}{красивая печать||pretty printing|||}\index{en}{pretty printing||красивая печать|||}{\em красивая 
печать} (pretty printing). Согласно им, всякая длинная комбинация
записывается так, чтобы ее операнды выравнивались вертикально.
Получающиеся отступы ясно показывают структуру
выражения\footnote{\index{ru}{печать входных выражений||typing input
    expressions|||п}\index{en}{typing input expressions||печать
    входных выражений|||п}Как правило, Лисп-системы содержат средства,
которые помогают пользователям\index{ru}{форматирование входных
  выражений||formatting input expressions|||п}\index{en}{formatting
  input expressions||форматирование входных выражений|||п}
форматировать выражения.  Особенно удобны две
возможности: сдвигать курсор на правильную позицию для красивой печати 
каждый раз, когда начинается новая строка~и подсвечивать нужную левую
скобку каждый раз, когда печатается правая.}.

 Даже работая со сложными выражениями, интерпретатор
всегда ведет себя одинаковым образом: он считывает выражение с
терминала, вычисляет его~и печатает результат.  
\index{ru}{интерпретатор|цикл чтение-вычисление-печать||||}
Этот способ работы
иногда называют \index{ru}{цикл чтение-вычисление-печать||read-eval-print loop|||}\index{en}{read-eval-print loop||цикл чтение-вычисление-печать|||}{\em циклом
чтение-вычисление-печать} (read-eval-print loop).
Обратите особое внимание на то, что не нужно специально просить
интерпретатор напечатать значение выражения\footnote{\index{ru}{Lisp
    (Лисп)|эффективность||||п}Лисп следует соглашению, что~у всякого
выражения есть  \index{ru}{значение|выражения||||п}значение.  Это соглашение, вместе
со старой репутацией Лиспа как
неэффективного языка, послужило источником остроумного замечания Алана 
Перлиса\index{ru}{Перлис, Алан~Дж.|афоризмы|Alan~J. Perlis||n|п}\index{en}{Alan~J. Perlis||Перлис, Алан~Дж.|афоризмы|n|п} (парафразы из Оскара Уайльда),\index{ru}{Уайльд, Оскар, парафраза Перлиса||Oscar Wilde||n|п}\index{en}{Oscar Wilde||Уайльд, Оскар, парафраза Перлиса||n|п} что <<Программисты на Лиспе
знают значение всего на свете, но ничему не знают цену>>.
}.

\subsection{Имена~и окружение}
\label{NAMING-AND-THE-ENVIRONMENT}


Одна из важнейших характеристик языка программирования~---
какие~в нем существуют средства
использования\index{ru}{именование|вычислительных
  объектов|naming|||}\index{en}{naming||именование|вычислительных
  объектов||}
имен для
указания на вычислительные объекты.  Мы говорим, что имя
обозначает\index{ru}{элементарные выражения|имя переменной||||}
\index{ru}{переменная||variable|||}\index{en}{variable||переменная|||}{\em переменную} (variable), чьим 
\index{ru}{переменная|значение||||}\index{ru}{значение|переменной|value|||}\index{en}{value||значение|переменной||}{\em значением} (value) является объект.

В диалекте Лиспа Scheme мы даем вещам имена~с помощью
слова {\tt define}.\index{ru}{define (особая
  форма)||||pd|}\index{ru}{особые формы|\texttt{define}||||}
Предложение

\begin{Verbatim}[fontsize=\small]
(define size 2)
\end{Verbatim}
заставляет интерпретатор связать значение 2~с именем
{\tt size}\footnote{Мы не печатаем~в этой книге ответы интерпретатора
при вычислении определений, поскольку они зависят от конкретной
реализации языка.\index{ru}{неопределенные значения|\texttt{define}|unspecified values|||п}\index{en}{unspecified values||неопределенные значения|\texttt{define}||п}%
\index{ru}{define (особая форма)|значение выражения|||p|п}
}.
После того, как имя {\tt size} связано со значением 2,
мы можем указывать на значение 2~с помощью имени:

\begin{Verbatim}[fontsize=\small]
size
\textit{2}

(* 5 size)
\textit{10}
\end{Verbatim}

Вот еще примеры использования
{\tt define}:

\begin{Verbatim}[fontsize=\small]
(define pi 3.14159)

(define radius 10)

(* pi (* radius radius))
\textit{314.159}

(define circumference (* 2 pi radius))

circumference
\textit{62.8318}
\end{Verbatim}

Слово\index{ru}{средства абстракции|\texttt{define}||||} {\tt define} служит~в нашем языке
простейшим средством абстракции, поскольку оно позволяет нам
использовать простые имена для обозначения результатов сложных
операций, как, например, вычисленная только что длина окружности~---
{\tt circumference}.  Вообще говоря, вычислительные
объекты могут быть весьма сложными структурами,~и было бы очень
неудобно, если бы нам приходилось вспоминать~и повторять все их детали 
каждый раз, когда нам захочется их использовать.  На самом деле
сложные программы конструируются методом построения шаг за шагом
вычислительных объектов возрастающей сложности.  Интерпретатор делает
такое пошаговое построение программы особенно удобным, поскольку связи 
между именами~и объектами могут создаваться последовательно по мере
взаимодействия программиста~с компьютером.  Это свойство
интерпретаторов облегчает\index{ru}{пошаговое написание||incremental
  development|||}\index{en}{incremental     development||пошаговое
  написание|||}\index{ru}{программа|пошаговое написание||||}
пошаговое написание~и тестирование программ,
и во многом благодаря именно ему получается так,
что\index{ru}{программа|структура||||} программы на Лиспе
обычно состоят из большого количества относительно простых
процедур. 

Ясно, что раз интерпретатор способен
ассоциировать значения~с символами~и затем вспоминать их, то 
он должен иметь некоторого рода память, сохраняющую пары имя-объект.
Эта память называется 
\index{ru}{окружение||environment|||}\index{en}{environment||окружение|||}{\em окружением} (environment) (а точнее,
\index{ru}{глобальное окружение||global environment|||}\index{en}{global environment||глобальное окружение|||}{\em глобальным окружением} (global environment), поскольку позже мы увидим, 
что вычисление может иметь дело~с несколькими окружениями)\footnote{~В главе~\ref{MODULARITY-OBJECTS-AND-STATE}
мы увидим, что понятие окружения 
необходимо как для понимания работы интерпретаторов, так~и для их
реализации.}.

\subsection{Вычисление комбинаций}
\label{EVALUATING-COMBINATIONS}


\index{ru}{вычисление|комбинации||||}
\index{ru}{комбинация|вычисление||||}
Одна из наших целей~в этой главе~--- выделить элементы
процедурного мышления.  Рассуждая~в этом русле, примем во внимание, что
интерпретатор, вычисляя значение комбинации, тоже следует 
процедуре:

\begin{itemize}%MLR%Arrange the list
\item
Чтобы вычислить комбинацию, требуется:
  \begin{itemize}
\item  Вычислить все подвыражения
    комбинации.

\item Применить процедуру, которая является
    значением самого левого подвыражения (оператора)~к аргументам ---
    значениям остальных подвыражений (операндов).
  \end{itemize}
\end{itemize}
Даже~в этом простом правиле видны несколько важных свойств
процессов~в целом. Прежде всего, заметим, что на первом шаге
для того, чтобы провести процесс вычисления для комбинации,
нужно сначала проделать процесс вычисления для каждого элемента
комбинации.  Таким образом, правило вычисления
\index{ru}{рекурсия||recursion|||}\index{en}{recursion||рекурсия|||}{\em рекурсивно} (recursive) по своей природе; это означает, что в
качестве одного из своих шагов оно включает применение того же самого
правила\footnote{Может показаться странным, что правило
вычисления предписывает нам~в качестве части первого шага
вычислить самый левый элемент комбинации,~--- ведь до сих пор это мог 
быть только оператор вроде {\tt +} или
{\tt *}, представляющий встроенную процедуру, например, 
сложение или умножение.  Позже мы увидим, что полезно иметь
возможность работать~и~с комбинациями, чьи операторы сами по себе
являются составными выражениями.
}.

\index{ru}{рекурсия|выражение сложного процесса||||}Заметьте, какую краткость понятие рекурсии придает
описанию того, что~в случае комбинации~с глубоким вложением выглядело
бы как достаточно сложный процесс.  Например, чтобы вычислить

\begin{Verbatim}[fontsize=\small]
 (* (+ 2 (* 4 6))
    (+ 3 5 7))
\end{Verbatim}
требуется применить правило вычисления~к четырем различным
комбинациям.  Картину этого процесса можно получить, нарисовав 
\index{ru}{дерево|представление комбинации||||}\index{ru}{комбинация|в
  виде дерева||||}комбинацию~в виде дерева, как показано на
рис.~\ref{P1.1}. Каждая комбинация
представляется~в виде\index{ru}{вершина дерева||node of a
  tree|||}\index{en}{node of a tree||вершина дерева|||}вершины, а
ее оператор~и операнды~---~в виде 
\index{ru}{ветвь дерева||branch of a tree|||}\index{en}{branch of a
  tree||ветвь дерева|||}ветвей, исходящих из этой вершины.
\index{ru}{концевая вершина дерева||terminal node of a
  tree|||}\index{en}{terminal node of a tree||концевая вершина
  дерева|||}Концевые вершины (то есть те, из которых
не исходит ни одной ветви) представляют операторы или числа.
Рассматривая вычисление как дерево, мы можем представить себе, что
значения операндов распространяются от концевых вершин вверх и
затем комбинируются на все более высоких уровнях.  Впоследствии мы увидим, что
рекурсия~--- это вообще очень мощный метод обработки иерархических,
древовидных объектов.  На самом деле форма правила вычисления <<распространить
значения наверх>> является примером общего типа процессов, известного
как \index{ru}{накопление|по дереву|tree accumulation|||}\index{en}{tree accumulation||накопление|по дереву||}{\em накопление по дереву} (tree accumulation).

\begin{cntrfig}
%\synttree[ {\tt sqrt} [.b {\tt sqrt-iter} [ {\tt good-enough} [ {\tt square} ]%
% {\tt abs} ]][ {\tt improve} [.b {\tt average} ] ]]]
\input{xfig-mod/1-1.eepic}
\caption{Вычисление, представленное~в виде дерева.}
\label{P1.1}
\end{cntrfig}

Далее, заметим, что многократное применение
первого шага приводит нас~к такой точке, где нам нужно вычислять уже не
комбинации,~а элементарные выражения,~а именно числовые константы, встроенные
операторы или другие имена. С этими случаями мы справляемся,
положив, что:\index{ru}{вычисление|элементарных
  выражений||||}\index{ru}{элементарные выражения|вычисление||||}

\begin{plainlist}
\sloppy
\item
  значением числовых констант являются те
  числа, которые они называют;
\item
  значением встроенных операторов являются
  последовательности ма\-шинных команд, которые выполняют соответствующие
  операции;~и %HERE
\item
  значением остальных имен являются те
  объекты,~с которыми эти имена связаны~в окружении.
\end{plainlist}

Мы можем рассматривать второе правило как частный случай третьего,
постановив, что символы вроде {\tt +} и
{\tt *} тоже включены~в глобальное окружение~и связаны
с последовательностями машинных команд, которые~и есть их
<<значения>>.  Главное здесь~--- это роль\index{ru}{окружение|как контекст для вычисления||||} окружения
при определении значения символов~в выражениях. В таком диалоговом
языке, как Лисп, не имеет смысла говорить~о значении выражения, скажем,
{\tt (+ x 1)}, не указывая никакой информации об
окружении, которое дало бы значение символу {\tt x} (и
даже символу {\tt +}).  Как мы увидим~в 
главе~\ref{MODULARITY-OBJECTS-AND-STATE}, общее 
понятие окружения, предоставляющего контекст,~в котором
происходит вычисление, будет играть важную роль~в нашем понимании
того, как выполняются программы.

Заметим, что рассмотренное нами правило вычисления не
обрабатывает определений.  Например, вычисление {\tt (define x
3)} не означает применение {\tt define} к
двум аргументам, один из которых значение символа
{\tt x},~а другой равен 3, поскольку смысл
{\tt define} как раз~и состоит~в том, чтобы связать
{\tt x} со значением.  (Таким образом,
{\tt (define x~3)}~--- не комбинация.)\index{ru}{define (особая
  форма)|почему особая форма|||p|}

Такие исключения из вышеописанного правила вычисления
называются {\em особыми формами}\index{ru}{особая форма||special form|||} (special forms).\index{en}{special form||особая форма|||}
{\tt Define}~--- пока что единственный встретившийся нам
пример\index{ru}{вычисление|особых форм||||} особой формы, но очень скоро мы познакомимся~и~с другими.
У каждой особой формы свое собственное правило вычисления.
Разные виды выражений (вместе со своими правилами вычисления)
составляют\index{ru}{синтаксис|языка программирования||||} синтаксис языка программирования.  По сравнению с
большинством языков программирования,~у Лиспа очень простой синтаксис; 
а именно, правило вычисления для выражений может быть описано как
очень простое общее правило плюс специальные правила для небольшого числа
особых форм\footnote{\index{ru}{Lisp
    (Лисп)|vs. Паскаль||||п}\index{ru}{Pascal
    (Паскаль)|||||п}\index{ru}{точка с
    запятой||semicolon|||п}\index{en}{semicolon||точка с
    запятой|||п}Особые синтаксические формы, которые
представляют собой просто удобное альтернативное поверхностное
представление для того, что можно выразить более унифицированным
способом, иногда называют \index{ru}{синтаксический сахар||syntactic sugar|||п}\index{en}{syntactic sugar||синтаксический сахар|||п}{\em синтаксическим сахаром} (syntactic sugar), 
используя выражение Питера Ландина.\index{ru}{Ландин, Питер||Peter Landin||n|п}\index{en}{Peter Landin||Ландин, Питер||n|п}
По сравнению~с пользователями других языков,
программистов на Лиспе, как правило, мало волнует синтаксический
сахар. (Для контраста возьмите руководство по Паскалю~и посмотрите, сколько места 
там уделяется описанию синтаксиса).  Такое презрение~к синтаксису
отчасти происходит от гибкости Лиспа, позволяющего легко изменять 
поверхностный синтаксис,~а отчасти из наблюдения, что многие
<<удобные>> синтаксические конструкции, которые делают язык менее
последовательным, приносят~в конце концов больше вреда, чем пользы,
когда программы становятся большими~и сложными. По словам Алана
Перлиса, <<Синтаксический сахар вызывает\index{ru}{рак точки с
  запятой||cancer of the     semicolon|||п}\index{en}{cancer of the
  semicolon||рак точки~с запятой|||п}
рак точки~с запятой>>.\index{ru}{Перлис, Алан~Дж.|афоризмы|Alan~J. Perlis||n|п}\index{en}{Alan~J. Perlis||Перлис, Алан~Дж.|афоризмы|n|п}
}.

\subsection{Составные процедуры}
\label{COMPOUND-PROCEDURES}


Мы нашли~в Лиспе некоторые из тех элементов, которые
должны присутствовать~в любом мощном языке программирования:

\begin{plainlist}
\item
  Числа~и арифметические операции
  представляют собой элементарные данные~и процедуры.

\item
  Вложение комбинаций дает возможность комбинировать 
  операции.

\item
  Определения, которые связывают имена со
  значениями, дают ограниченные возможности абстракции.
\end{plainlist}
Теперь мы узнаем об\index{ru}{процедура|определение||||}
\index{ru}{определение процедуры||procedure definition|||}\index{en}{procedure definition||определение процедуры|||}{\em определениях процедур} (procedure definitions)~---
значительно более мощном методе абстракции,~с помощью
которого составной операции можно дать имя~и затем ссылаться на нее
как на единое целое.\index{ru}{процедура|определение||||}

Для начала рассмотрим, как выразить понятие
<<возведения~в квадрат>>.  Можно сказать так: <<Чтобы возвести 
что-нибудь~в квадрат, нужно умножить его само на себя>>. Вот как это
выражается~в нашем языке:

\begin{Verbatim}[fontsize=\small]
(define (square x) (* x x))\index{ru}{sqare||||pd|}
\end{Verbatim}


Это можно понимать так:

\begin{center}
\begin{tabular}{cccccl}
\tt{(define} & 
\tt{(square} & 
\tt{x)}      & 
\tt{(*}      &
\tt{x}       &
\tt{x))}       
\\

$\uparrow$   &  
$\uparrow$   & 
$\uparrow$   & 
$\uparrow$   & 
$\uparrow$   &
$\uparrow$   \\

Чтобы        & 
возвести~в квадрат & 
что-л.       &
умножь       & 
это          & 
само на себя  
\end{tabular}
\end{center}
%{\em Чтобы / возвести~в квадрат / что-то, / умножь / это / само насебя} 
Здесь мы имеем \index{ru}{составная процедура||compound procedure|||}\index{en}{compound procedure||составная процедура|||}{\em составную процедуру} (compound procedure), которой мы 
дали имя {\tt square}.\index{ru}{процедура|составная|procedure|compound||}\index{en}{procedure|compound|процедура|составная||}
Эта процедура представляет
операцию умножения чего-либо само на себя.  Та вещь, которую нужно
подвергнуть умножению, получает здесь имя {\tt x},
которое играет ту же роль, что~в естественных языках играет
местоимение.\index{ru}{именование|процедур||||}\index{ru}{процедура|создание
 с помощью \texttt{define}||||}\index{ru}{процедура|именование (с
  помощью \texttt{define})||||} Вычисление этого определения создает
составную процедуру
и связывает ее~с именем {\tt square}\footnote{Заметьте, что здесь присутствуют две различные
операции: мы создаем процедуру,~и мы даем ей имя
{\tt square}.  Возможно,~и на самом деле даже важно,
разделить эти два понятия: создавать процедуры, никак их не называя,~и 
давать имена процедурам, уже созданным заранее.  Мы увидим, как это
делается,~в разделе~\ref{CONSTRUCTING-PROCEDURES-USING-LAMBDA}.}.

Общая форма определения процедуры такова:
\index{ru}{define (особая форма)|для процедур|||pd|}
\index{ru}{особые формы|\texttt{define}||||}

\begin{Verbatim}[fontsize=\small]
(define (\textit{$\langle$имя$\rangle$} \textit{$\langle$формальные-параметры$\rangle$}) \textit{$\langle$тело$\rangle$})
\end{Verbatim}
\index{ru}{имя|процедуры||||}%

\textit{$\langle$Имя$\rangle$} --- это тот символ,~с которым нужно
связать~в окружении определение процедуры\footnote{\index{ru}{нотация~в настоящей книге|курсив~в синтаксисе выражений||||п}На всем протяжении этой книги мы будем описывать
обобщенный\index{ru}{синтаксис|выражений, описание||||п}синтаксис выражений, используя курсив в
угловых скобках --- напр. \textit{$\langle$имя$\rangle$}, чтобы обозначить <<дырки>>
в выражении, которые нужно заполнить, когда это выражение
используется~в языке.
}.
\index{ru}{имя|процедуры||||}\index{ru}{тело процедуры||body of a
  procedure|||}\index{en}{body of a procedure||тело
  процедуры|||}\index{ru}{формальные параметры процедуры||formal
  parameters|||}\index{en}{formal     parameters||формальные параметры
  процедуры|||}\index{ru}{процедура|тело||||}\index{ru}{процедура|формальные параметры||||}\index{ru}{процедура|имя||||}\textit{$\langle$Формальные-параметры$\rangle$} --- это имена, которые~в теле процедуры
используются для отсылки~к соответствующим аргументам процедуры.
\index{ru}{тело процедуры|||||}\textit{$\langle$Тело$\rangle$} ---
это выражение, которое вычислит результат применения
процедуры, когда формальные параметры будут заменены аргументами, к
которым процедура будет применяться\footnote{В более общем случае тело процедуры может быть
\index{ru}{последовательность выражений|в теле     процедуры|sequence
  of expressions|||п}\index{en}{sequence of
  expressions||последовательность выражений|в теле
  процедуры||п}последовательностью выражений. В этом случае
интерпретатор вычисляет
по очереди все выражения~в этой последовательности~и возвращает в
качестве значения применения процедуры значение последнего
выражения.}.
\textit{$\langle$Имя$\rangle$}~и 
\textit{$\langle$формальные-параметры$\rangle$} заключены~в 
\index{ru}{скобки|в определении процедуры|parentheses|||}\index{en}{parentheses||скобки|в определении процедуры||}
скобки, как это было бы при вызове определяемой процедуры.

Теперь, когда процедура {\tt square} определена, мы можем ее
использовать:

\begin{Verbatim}[fontsize=\small]
(square 21)
\textit{441}

(square (+ 2 5))
\textit{49}

(square (square 3))
\textit{81}
\end{Verbatim}

Кроме того, мы можем использовать
{\tt square} при определении других процедур. Например, 
$x^2 + y^2$ можно записать как

\begin{Verbatim}[fontsize=\small]
(+ (square x) (square y)))
\end{Verbatim}
Легко можно определить процедуру
{\tt sum-of-squares}, которая, получая~в качестве
аргументов два числа, дает~в результате сумму их квадратов:

\begin{Verbatim}[fontsize=\small]
(define (sum-of-squares x y) \index{ru}{sum-of-squares||||pd|}
  (+ (square x) (square y)))

(sum-of-squares 3 4)
\textit{25}
\end{Verbatim}
Теперь~и {\tt sum-of-squares} мы можем использовать как 
строительный блок при дальнейшем определении процедур:

\begin{Verbatim}[fontsize=\small]
(define (f a)
  (sum-of-squares (+ a 1) (* a 2)))

(f 5)
\textit{136}
\end{Verbatim}
\index{ru}{составная процедура|использование~в качестве элементарных||||}Составные процедуры используются точно так же,
как элементарные.~В 
самом деле, глядя на приведенное выше определение
{\tt sum-of-squares}, невозможно выяснить, была ли
{\tt square} встроена~в интерпретатор, подобно
{\tt +}~и {\tt *}, или ее определили
как составную процедуру.

\subsection{Подстановочная модель применения процедуры}
\label{SUBST-MODEL-FOR-PROC-APPL}

\index{ru}{подстановочная модель применения процедуры|||||}
Вычисляя комбинацию, оператор которой называет составную 
процедуру, интерпретатор осуществляет, вообще говоря, тот же процесс, что~и 
для комбинаций, операторы которых называют элементарные процедуры~---
процесс, описанный~в разделе~\ref{EVALUATING-COMBINATIONS}. А именно,
интерпретатор вычисляет элементы комбинации~и применяет процедуру
(значение оператора комбинации)~к аргументам (значениям операндов
комбинации).

Мы можем предположить, что механизм применения
элементарных процедур~к аргументам встроен~в интерпретатор.  Для
составных процедур процесс протекает так:

\begin{plainlist}

\item Чтобы применить составную
процедуру~к аргументам, требуется вычислить тело процедуры, заменив каждый
формальный параметр соответствующим аргументом.
\end{plainlist}

Чтобы проиллюстрировать этот процесс, вычислим комбинацию

\begin{Verbatim}[fontsize=\small]
(f 5)
\end{Verbatim}
где {\tt f} --- процедура, определенная~в 
разделе~\ref{COMPOUND-PROCEDURES}.  Начинаем мы~с того, что
восстанавливаем тело {\tt f}:

\begin{Verbatim}[fontsize=\small]
(sum-of-squares (+ a 1) (* a 2))
\end{Verbatim}
Затем мы заменяем формальный параметр {\tt a} на
аргумент 5:

\begin{Verbatim}[fontsize=\small]
(sum-of-squares (+ 5 1) (* 5 2))
\end{Verbatim}
Таким образом, задача сводится~к вычислению комбинации~с двумя
операндами~и оператором {\tt sum-of-squares}.
Вычисление этой комбинации включает три подзадачи.  Нам нужно
вычислить оператор, чтобы получить процедуру, которую требуется
применить,~а также операнды, чтобы получить аргументы.  При этом
{\tt (+ 5 1)} дает 6,~а {\tt (* 5
2)} дает 10, так что нам требуется применить процедуру
{\tt sum-of-squares}~к 6~и 10.  Эти значения
подставляются на место формальных параметров {\tt x} и
{\tt y}~в теле {\tt sum-of-squares},
приводя выражение к

\begin{Verbatim}[fontsize=\small]
(+ (square 6) (square 10))
\end{Verbatim}
Когда мы используем определение {\tt square}, это
приводится~к 

\begin{Verbatim}[fontsize=\small]
(+ (* 6 6) (* 10 10))
\end{Verbatim}
что при умножении сводится к

\begin{Verbatim}[fontsize=\small]
(+ 36 100)
\end{Verbatim}
и, наконец, к

\begin{Verbatim}[fontsize=\small]
136
\end{Verbatim}

Только что описанный нами процесс называется
\index{ru}{подстановочная модель применения процедуры||substitution model|||}%
\index{en}{substitution model||подстановочная модель применения процедуры|||}%
{\em подстановочной моделью} (substitution model) применения процедуры.
Ее можно использовать как модель, которая определяет <<смысл>>
понятия применения процедуры, пока рассматриваются процедуры из этой
главы.  Имеются, однако, две детали, которые необходимо подчеркнуть:

\begin{plainlist}


\item
Цель подстановочной модели --- помочь нам
представить, как применяются процедуры,~а не дать описание того, как на самом
деле работает интерпретатор.  Как правило, интерпретаторы вычисляют
применения процедур~к аргументам без манипуляций~с текстом
процедуры, которые выражаются~в подстановке значений для формальных
параметров.  На практике <<подстановка>> реализуется~с помощью
локальных окружений для формальных параметров.  Более
подробно мы обсудим это~в главах~\ref{MODULARITY-OBJECTS-AND-STATE}~и \ref{METALINGUISTIC-ABSTRACTION}, где мы
детально исследуем реализацию интерпретатора.

\item
На протяжении этой книги мы представим
последовательность усложняющихся моделей того, как работает
интерпретатор, завершающуюся полным воплощением интерпретатора и
компилятора~в главе~\ref{COMPUTING-WITH-REGISTER-MACHINES}.
Подстановочная модель --- только первая 
из них, способ начать формально мыслить~о моделях вычисления.  Вообще,
моделируя  
\index{ru}{моделирование|в науке~и технике|modeling|||}\index{en}{modeling||моделирование|в науке~и технике||} 
различные явления~в науке~и технике, мы начинаем с
упрощенных, неполных моделей.  Подстановочная модель~в этом смысле не
исключение. В частности, когда~в главе~\ref{MODULARITY-OBJECTS-AND-STATE} мы обратимся 
к использованию процедур~с <<изменяемыми данными>>, то мы увидим, что
подстановочная модель этого не выдерживает~и ее нужно заменить более
сложной моделью применения процедур\footnote{Несмотря на простоту подстановочной модели,
дать строгое математическое определение процессу подстановки
оказывается удивительно сложно.  Проблема возникает из-за возможности
смешения имен, которые используются как формальные параметры процедуры,
с именами (возможно,~с ними совпадающими), которые используются в
выражениях,~к которым процедура может применяться.  Имеется долгая
история неверных определений
{\em подстановки} (substitution)\index{ru}{подстановка||substitution|||п}\index{en}{substitution||подстановка|||п} в
литературе по логике~и языкам программирования. Подробное обсуждение
подстановки можно найти~в Stoy 1977.
\index{ru}{Стой, Джозеф~Э.||Joseph~E. Stoy||n|п}\index{en}{Joseph~E. Stoy||Стой, Джозеф~Э.||n|п}
}.
\end{plainlist}

\paragraph{Аппликативный~и нормальный порядки вычисления}


В соответствии~с описанием из раздела~\ref{EVALUATING-COMBINATIONS}, интерпретатор
сначала вычисляет оператор~и операнды,~а затем применяет получившуюся
процедуру~к получившимся аргументам.  Но это не единственный способ
осуществлять вычисления.  Другая модель вычисления не вычисляет
аргументы, пока не понадобится их значение.
Вместо этого она подставляет на место параметров выражения-операнды,
пока не получит выражение,~в котором присутствуют только элементарные
операторы,~и лишь затем вычисляет его.  Если бы мы
использовали этот метод, вычисление

\begin{Verbatim}[fontsize=\small]
(f 5)
\end{Verbatim}
прошло бы последовательность подстановок

\begin{Verbatim}[fontsize=\small]
(sum-of-squares (+ 5 1) (* 5 2))

(+    (square (+ 5 1))      (square (* 5 2))  )

(+    (* (+ 5 1) (+ 5 1))   (* (* 5 2) (* 5 2)))
\end{Verbatim}
за которыми последуют редукции

\begin{Verbatim}[fontsize=\small]
(+         (* 6 6)             (* 10 10))

(+           36                   100)

                     136
\end{Verbatim}
Это дает тот же результат, что~и предыдущая модель вычислений, но
процесс его получения отличается. В частности, вычисление
{\tt (+ 5 1)}~и {\tt (* 5 2)}
выполняется здесь по два раза,~в соответствии~с редукцией выражения

\begin{Verbatim}[fontsize=\small]
(* x x)
\end{Verbatim}
где {\tt x} заменяется, соответственно, на {\tt (+ 
5 1)}~и {\tt (* 5 2)}.

Альтернативный метод <<полная подстановка, затем
редукция>> известен под названием \index{ru}{нормальный порядок вычислений||normal-order evaluation|||}\index{en}{normal-order evaluation||нормальный порядок вычислений|||}{\em нормальный порядок
вычислений} (normal-order evaluation),~в противоположность методу <<вычисление
аргументов, затем применение процедуры>>, которое называется
\index{ru}{аппликативный порядок вычислений||applicative-order evaluation|||}\index{en}{applicative-order evaluation||аппликативный порядок вычислений|||}{\em аппликативным порядком вычислений} (ap\-pli\-ca\-tive-order evaluation).
Можно показать, что для процедур, которые правильно моделируются
с помощью подстановки (включая все процедуры из первых
двух глав этой книги)~и возвращают законные значения,
нормальный~и аппликативный порядки вычисления дают одно~и то же
значение. (См. упражнение~\ref{EX1.5}, где приводится пример
<<незаконного>> выражения, для которого нормальный~и аппликативный порядки
вычисления дают разные результаты.)

В\index{ru}{Lisp (Лисп)|аппликативный порядок вычислений||||}
Лиспе используется \index{ru}{аппликативный порядок вычислений|в Лиспе||||}
аппликативный порядок вычислений, 
отчасти из-за дополнительной эффективности, которую дает возможность
не вычислять многократно выражения вроде приведенных 
выше {\tt (+ 5 1)}~и {\tt (* 5 2)}, а
отчасти, что важнее, потому что~с нормальным порядком вычислений
становится очень сложно обращаться, как только мы покидаем область
процедур, которые можно смоделировать~с помощью подстановки. С другой 
стороны, нормальный порядок вычислений может быть весьма ценным
инструментом,~и некоторые его применения мы рассмотрим~в главах~\ref{MODULARITY-OBJECTS-AND-STATE}~и \ref{METALINGUISTIC-ABSTRACTION}\footnote{В главе~\ref{MODULARITY-OBJECTS-AND-STATE} мы описываем
\index{ru}{обработка потоков||stream processing|||п}\index{en}{stream processing||обработка потоков|||п}{\em обработку потоков} (stream processing),
 которая представляет собой
способ обработки структур данных, кажущихся <<бесконечными>>,~с 
помощью ограниченной формы нормального порядка вычислений.~В 
разделе~\ref{VARIATIONS-ON-A-SCHEME-LAZY-EVALUATION} мы
модифицируем интерпретатор Scheme так, что получается вариант языка с
нормальным порядком вычислений.
}.

\subsection{Условные выражения~и предикаты}
\label{CONDITIONAL-EXPRESSIONS-AND-PREDICATES}


{Выразительная сила того класса процедур, которые мы уже
научились определять, очень ограничена, поскольку пока что~у нас нет
способа производить проверки~и выполнять различные операции в
зависимости от результата проверки.  Например, мы не способны
определить процедуру, вычисляющую модуль числа, проверяя,
положительное ли это число, отрицательное или ноль,~и предпринимая
различные действия~в соответствии~с правилом

\looseness=1
}
$$
     |x| = \left\{
        \begin{array}{rll}
          x & \mbox{если} & x > 0 \\
          0 & \mbox{если} & x = 0 \\
          - x & \mbox{если} & x < 0 \\
        \end{array}
        \right.
$$
{\index{ru}{модуль||absolute value|||}\index{en}{absolute value||модуль|||}%
Такая конструкция называется \index{ru}{разбор случаев||case analysis|||}\index{en}{case analysis||разбор случаев|||}{\em разбором случаев} (case analysis). В
Лиспе су\-щес\-т\-ву\-ет особая форма для обозначения такого разбора
случаев.\index{ru}{условное выражение|{\tt cond}|conditional expression|||}\index{en}{conditional expression||условное выражение|{\tt cond}||}%
Она называется {\tt cond} (от английского
\index{ru}{cond (особая форма)||||pd|}%
\index{ru}{особые формы|\texttt{cond}||||}%
слова {\em conditional}, <<условный>>) и
используется так:

\looseness=1
}
\begin{Verbatim}[fontsize=\small]
(define (abs x)\index{ru}{abs||||pd|}
  (cond ((> x 0) x)
        ((= x 0) 0)
        ((< x 0) (- x))))
\end{Verbatim}
\index{ru}{= (элементарный предикат сравнения чисел)||||pd|}%
\index{ru}{< (элементарный предикат сравнения чисел)||||pd|}%
\index{ru}{> (элементарный предикат сравнения чисел)||||pd|}%
Общая форма условного выражения такова:

\begin{Verbatim}[fontsize=\small]
(cond (\textit{$\langle$p${}_{\mbox{1}}$$\rangle$} \textit{$\langle$e${}_{\mbox{1}}$$\rangle$})
      (\textit{$\langle$p${}_{\mbox{2}}$$\rangle$} \textit{$\langle$e${}_{\mbox{2}}$$\rangle$})
      \vdots
      (\textit{$\langle$p${}_{\mbox{n}}$$\rangle$} \textit{$\langle$e${}_{\mbox{n}}$$\rangle$}))
\end{Verbatim}


Она состоит из символа {\tt cond}, за которым следуют
\index{ru}{скобки|обозначающие клаузу \texttt{cond}||||}заключенные~в скобки пары выражений
{\tt (\textit{$\langle$p$\rangle$} \textit{$\langle$e$\rangle$})},
называемых 
\index{ru}{ветвь {\tt cond}||clause, of a {\tt
    cond}|||}\index{en}{clause, of a {\tt     cond}||ветвь {\tt
    cond}|||}\index{ru}{ветвь||clause|||}\index{en}{clause||ветвь|||}{\em ветвями} (clauses).\index{ru}{cond (особая форма)|ветвь|||p|}
В каждой из этих пар первое выражение~--- \index{ru}{предикат|ветви
  \texttt{cond}||||}\index{ru}{предикат||predicate|||}\index{en}{predicate||предикат|||}{\em предикат} (predicate),
то есть выражение, значение которого ин\-тер\-пре\-ти\-ру\-ет\-ся как истина или
ложь\footnote{\index{ru}{ложь||false|||п}\index{en}{false||ложь|||п}\index{ru}{истина||true|||п}\index{en}{true||истина|||п}<<Интерпретируется
  как истина или ложь>> означает
следующее:~в языке Scheme есть два выделенных значения, которые
обозначаются константами {\tt \#t} и
{\tt \#f}.  Когда интерпретатор проверяет значение
предиката, он интерпретирует {\tt \#f} как ложь.  Любое
другое значение считается истиной. (Таким образом, наличие
{\tt \#t} логически не является необходимым, но иметь его удобно.)
В этой книге мы будем использовать имена {\tt true}\index{ru}{true||||pd|п}
и {\tt false},\index{ru}{false||||pd|п}
которые связаны со значениями
{\tt \#t}~и {\tt \#f},
соответственно.\index{ru}{\#t||||p|п}\index{ru}{\#f||||p|п}}.

\index{ru}{cond (особая
  форма)|вычисление|||p|}\index{ru}{вычисление|{\tt cond}||||}Условные
выражения вычисляются так: сначала вычисляется
предикат \textit{$\langle$p${}_{\mbox{1}}$$\rangle$}.
Если его значением является ложь, вычисляется \textit{$\langle$p${}_{\mbox{2}}$$\rangle$}.
Если значение \textit{$\langle$p${}_{\mbox{2}}$$\rangle$}
также ложь, вычисляется
\textit{$\langle$p${}_{\mbox{3}}$$\rangle$}.  Этот процесс 
продолжается до тех пор, пока не найдется предикат, значением которого 
будет истина, и~в этом случае интерпретатор возвращает значение
соответствующего \index{ru}{выражение-следствие|{\tt cond}|consequent expression|||}\index{en}{consequent expression||выражение-следствие|{\tt cond}||}{\em выражения-следствия} (consequent expression) в качестве значения всего условного выражения.  
Если ни один из
\textit{$\langle$p$\rangle$} ни окажется истинным, значение
условного выражения не определено.

Словом \index{ru}{предикат||predicate|||}\index{en}{predicate||предикат|||}{\em предикат} называют процедуры, 
которые возвращают истину или ложь, а также выражения, которые имеют
значением истину или ложь.  Процедура вычисления модуля использует
элементарные предикаты\index{ru}{числа|сравнение||||}
\index{ru}{элементарные процедуры|\texttt{<}|primitives|||}\index{en}{primitives||элементарные процедуры|\texttt{<}||}
{\tt <},\index{ru}{элементарные процедуры|{\tt =}||||}{\tt =}~и 
\index{ru}{элементарные процедуры|\texttt{>}||||}{\tt >}\footnote{Еще она использует операцию <<минус>>
{\tt -},
\index{ru}{- (элементарная процедура вычитания)|как смена знака|||pd|п}
\index{ru}{элементарные процедуры|{\tt -}||||п}
которая, когда используется~с одним операндом, 
как~в выражении {\tt (- x)}, обозначает смену
знака.}.

\index{ru}{равенство|чисел||||}\index{ru}{числа|равенство||||}Они
принимают~в качестве аргументов по два числа и, проверив, меньше
ли первое из них второго, равно ему или больше,
возвращают~в зависимости от этого истину или ложь.

Можно написать процедуру вычисления модуля~и так:

\begin{Verbatim}[fontsize=\small]
(define (abs x)\index{ru}{abs||||pd|}
  (cond ((< x 0) (- x))
        (else x)))
\end{Verbatim}
что на русском языке можно было бы выразить следующим образом: <<если
$x$ меньше нуля, вернуть $-x$; иначе вернуть
$x$>>. 
{\tt Else}\index{ru}{else (особый символ~в \texttt{cond})||||pd|}
--- специальный символ, который в
заключительной ветви {\tt cond} можно использовать на
месте \textit{$\langle$p$\rangle$}.  Это заставляет
{\tt cond} вернуть~в качестве значения значение
соответствующего \textit{$\langle$e$\rangle$}~в случае, если все
предыдущие ветви были пропущены.  На самом деле, здесь на месте
\textit{$\langle$p$\rangle$} можно было бы использовать любое
выражение, которое всегда имеет значение истина.

Вот еще один способ написать процедуру вычисления
модуля:

\begin{Verbatim}[fontsize=\small]
(define (abs x)
  (if (< x 0)
      (- x)
      x))
\end{Verbatim}
\index{ru}{условное выражение|{\tt if}||||}Здесь употребляется особая форма {\tt if},
\index{ru}{if (особая форма)||||pd|}\index{ru}{особые формы|\texttt{if}||||}ограниченный
вид условного выражения.  Его можно использовать при разборе
случаев, когда есть ровно два возможных исхода.\index{ru}{разбор
  случаев|с двумя случаями||||} Общая форма выражения 
{\tt if} такова:

\begin{Verbatim}[fontsize=\small]
(if \textit{$\langle$предикат$\rangle$} \textit{$\langle$следствие$\rangle$} \textit{$\langle$альтернатива$\rangle$})
\end{Verbatim}
\index{ru}{вычисление|{\tt if}||||}Чтобы вычислить выражение {\tt if}, интерпретатор
\index{ru}{if (особая форма)|вычисление|||p|}\index{ru}{if (особая
  форма)|предикат, следствие~и альтернатива|||p|}сначала вычисляет его
\index{ru}{пре\-ди\-кат|\texttt{if}||||}\textit{$\langle$пре\-ди\-кат$\rangle$}. Если
\textit{$\langle$предикат$\rangle$} дает истинное значение,
интерпретатор вычисляет
\index{ru}{выражение-следствие|{\tt if}||||}\textit{$\langle$след\-ст\-вие$\rangle$}~и 
возвращает его значение.~В противном случае он вычисляет
\index{ru}{альтернатива \texttt{if}||alternative of     {\tt
    if}|||}\index{en}{alternative of     {\tt if}||альтернатива
  \texttt{if}|||}\textit{$\langle$альтернативу$\rangle$}~и возвращает
ее значение\footnote{\index{ru}{cond (особая
    форма)|vs. \texttt{if}|||p|п}\index{ru}{if (особая
    форма)|vs. \texttt{cond}|||p|п}\index{ru}{последовательность
    выражений|в следствии \texttt{cond}||||п}Небольшая разница между
{\tt if}~и {\tt cond} состоит~в том, что в
{\tt cond} каждое \textit{$\langle$e$\rangle$} может
быть последовательностью выражений.  Если соответствующее
\textit{$\langle$p$\rangle$} оказывается истинным, выражения из
\textit{$\langle$e$\rangle$} вычисляются по очереди, и~в качестве
значения {\tt cond} возвращается значение последнего из 
них.  Напротив,~в {\tt if} как
\textit{$\langle$следствие$\rangle$}, так и
\textit{$\langle$альтернатива$\rangle$} обязаны состоять из одного
выражения.}.

В дополнение~к элементарным предикатам вроде
{\tt <}, {\tt =} и
{\tt >}, существуют операции логической композиции,
которые позволяют нам конструировать составные предикаты. Из них чаще
всего используются такие:\index{ru}{вычисление|{\tt and}||||}

\begin{plainlist}
\item
{\tt (and \textit{$\langle$e${}_{\mbox{1}}$$\rangle$}
  . . . \textit{$\langle$e${}_{\mbox{n}}$$\rangle$})}

\index{ru}{and (особая форма)||||p|}\index{ru}{and (особая
  форма)|вычисление|||p|}\index{ru}{особые
  формы|\texttt{and}||||}Интерпретатор вычисляет выражения 
\textit{$\langle$e$\rangle$} по одному, слева направо. Если
какое-нибудь из \textit{$\langle$e$\rangle$} дает ложное значение,
значение всего выражения {\tt and} --- ложь, и
остальные \textit{$\langle$e$\rangle$} не вычисляются. Если все
\textit{$\langle$e$\rangle$} дают истинные значения, значением
выражения {\tt and} является значение последнего из
них.\index{ru}{вычисление|{\tt or}||||}

\item
{\tt (or \textit{$\langle$e${}_{\mbox{1}}$$\rangle$}  . . . \textit{$\langle$e${}_{\mbox{n}}$$\rangle$})}

\index{ru}{or (особая форма)||||p|}\index{ru}{or (особая
  форма)|вычисление|||p|}\index{ru}{особые
  формы|\texttt{or}||||}Интерпретатор вычисляет выражения
\textit{$\langle$e$\rangle$} по одному, слева направо. Если
какое-нибудь из \textit{$\langle$e$\rangle$} дает истинное значение, 
это значение возвращается как результат выражения
{\tt or},~а остальные \textit{$\langle$e$\rangle$} не 
вычисляются.  Если все \textit{$\langle$e$\rangle$} оказываются
ложными, значением выражения {\tt or} является
ложь.

\item
{\tt (not \textit{$\langle$e$\rangle$})}

Значение выражения {\tt not} ---
\index{ru}{not (элементарная процедура)||||pd|}\index{ru}{элементарные
  процедуры|{\tt not}||||}истина, если значение выражения
\textit{$\langle$e$\rangle$} ложно, 
и ложь~в противном случае.
\end{plainlist}

Заметим, что {\tt and}~и {\tt or} ---
\index{ru}{and (особая форма)|почему особая форма|||p|}\index{ru}{or
  (особая форма)|почему особая форма|||p|}особые формы,~а не
процедуры, поскольку не обязательно
вычисляются все подвыражения. {\tt Not} --- обычная
процедура.

Как пример на использование этих конструкций, условие
что число $x$ находится~в диапазоне $5 < x <
10$, можно выразить как

\begin{Verbatim}[fontsize=\small]
(and (> x 5) (< x 10))
\end{Verbatim}
Другой пример: мы можем определить предикат, который проверяет,
что одно число больше или равно другому, как

\begin{Verbatim}[fontsize=\small]
(define (>= x y)
  (or (> x y) (= x y)))
\end{Verbatim}
\index{ru}{>= (элементарный предикат сравнения чисел)||||pd|}
или как

\begin{Verbatim}[fontsize=\small]
(define (>= x y)
  (not (< x y)))
\end{Verbatim}
\begin{exercise}{1.1}\label{EX1.1}%
Ниже приведена последовательность выражений. Какой
результат напечатает интерпретатор в ответ на каждое из них?
Предполагается, что  выражения вводятся в том же порядке,~в каком они написаны.

\begin{Verbatim}[fontsize=\small]
10

(+ 5 3 4)

(- 9 1)

(/ 6 2)

(+ (* 2 4) (- 4 6))

(define a 3)

(define b (+ a 1))

(+ a b (* a b))

(= a b)

(if (and (> b a) (< b (* a b)))
    b
    a)

(cond ((= a 4) 6)
      ((= b 4) (+ 6 7 a))
      (else 25))

(+ 2 (if (> b a) b a))

(* (cond ((> a b) a)
         ((< a b) b)
         (else -1))
   (+ a 1))
\end{Verbatim}
          
\end{exercise}
\begin{exercise}{1.2}\label{EX1.2}%
Переведите следующее выражение~в префиксную форму:
$$
\dfrac{5 + 4 + (2 - (3 - (6 + \dfrac{4}{5})))}
     {3(6 - 2)(2 - 7)}
$$
\end{exercise}
\begin{exercise}{1.3}\label{EX1.3}%
Определите процедуру, которая принимает~в качестве
аргументов три числа~и возвращает сумму квадратов двух б\'ольших из
них. 
\end{exercise}
\begin{exercise}{1.4}\label{EX1.4}%
Заметим, что наша модель вычислений разрешает
существование\index{ru}{составное выражение|как оператор комбинации||||(упр.~1.4)}\index{ru}{оператор комбинации|в виде составного выражения||||(упр.~1.4)} 
\index{ru}{комбинация|составное выражение как оператор||||(упр.~1.4)}
комбинаций, операторы которых --- составные выражения.
С помощью этого наблюдения опишите, как работает следующая
процедура: 

\begin{Verbatim}[fontsize=\small]
(define (a-plus-abs-b a b)
  ((if (> b 0) + -) a b))
\end{Verbatim}

\end{exercise}
\begin{exercise}{1.5}\label{EX1.5}%
Бен Битобор придумал тест для проверки интерпретатора на
то,~с каким порядком вычислений он работает,
\index{ru}{аппликативный порядок вычислений|vs. нормальный
  порядок||||(упр.~1.5)}\index{ru}{нормальный порядок
  вычислений|vs. аппликативный порядок||||(упр.~1.5)}аппликативным или
нормальным.  Бен определяет такие 
две процедуры: 

\begin{Verbatim}[fontsize=\small]
(define (p) (p))

(define (test x y)
  (if (= x 0)
      0
      y))
\end{Verbatim}
Затем он вычисляет выражение

\begin{Verbatim}[fontsize=\small]
(test 0 (p))
\end{Verbatim}
Какое поведение увидит Бен, если интерпретатор использует
аппликативный порядок вычислений?  Какое поведение он увидит, если
интерпретатор использует нормальный порядок? Объясните Ваш
ответ. (Предполагается, что правило вычисления особой формы
{\tt if}\index{ru}{if (особая форма)|нормальный порядок вычисления
  формы|||p|(упр.~1.5)}\index{ru}{нормальный порядок вычислений|
  \texttt{if}||||(упр.~1.5)}
одинаково независимо от того, какой порядок
вычислений используется.  Сначала вычисляется выражение-предикат, и
результат определяет, нужно ли вычислять выражение-следствие или
альтернативу.)
\end{exercise}

\subsection{Пример: вычисление квадратного корня методом Ньютона}
\label{EXAMPLE-SQUARE-ROOTS-BY-NEWTONS-METHOD}


\index{ru}{функция (математическая)|vs. процедура||||}%
\index{ru}{процедура|vs.  математическая функция||||}Процедуры, как
они описаны выше, очень похожи на
обыкновенные математические функции.  Они устанавливают значение,
которое определяется одним или более параметром.  Но есть важное
различие между математическими функциями~и компьютерными процедурами.
Процедуры должны быть эффективными.

В качестве примера рассмотрим задачу вычисления квадратного 
корня.  Мы можем определить функцию <<квадратный корень>> так:
$$
\sqrt{x} = \mbox{ такое } y, \mbox{ что } y \ge 0 \mbox{~и } y^2 = x
$$
Это описывает совершенно нормальную математическую функцию. С помощью
такого определения мы можем решать, является ли одно
число квадратным корнем другого, или выводить общие свойства
квадратных корней. С другой стороны, это определение не описывает
процедуры. В самом деле, оно почти ничего не говорит~о том, как найти
квадратный корень данного числа.  Не поможет~и попытка перевести
это определение на псевдо-Лисп:

\begin{Verbatim}[fontsize=\small]
(define (sqrt x)
  (the y (and (>= y 0)
              (= (square y) x))))
\end{Verbatim}
Это только уход от вопроса.

Противопоставление функций~и процедур отражает общее
различие между описанием свойств объектов~и описанием того, как что-то
делать, или, как иногда говорят,\index{ru}{декларативное
  vs. императивное знание||declarative vs. imperative
  knowledge|||}\index{en}{declarative vs. imperative
  knowledge||декларативное vs. императивное
  знание|||}\index{ru}{императивное vs. декларативное
  знание||imperative vs. declarative
  knowledge|||}\index{en}{imperative vs. declarative
  knowledge||императивное vs. декларативное знание|||}
различие между декларативным
знанием~и императивным знанием.  
\index{ru}{информатика|vs.
  математика||||}\index{ru}{математика|vs. информатика|mathematics|||}\index{en}{mathematics||математика|vs. информатика||}В математике нас обычно интересуют 
декларативные описания (что такое),~а~в информатике императивные
описания (как)\footnote{Декларативные~и императивные описания тесно связаны
между собой, как~и математика~с информатикой.  Например, сказать, что
ответ, получаемый программой, <<верен>>, означает сделать об этой
программе декларативное утверждение.  Существует большое количество
исследований, направленных на отыскание методов 
\index{ru}{доказательство корректности программы||proving programs
  correct|||п}\index{en}{proving programs correct||доказательство
  корректности программы|||п}доказательства того, что
\index{ru}{корректность программы||correctness of a
  program|||п}\index{en}{correctness of a     program||корректность
  программы|||п}программа корректна,~и большая часть сложности этого
предмета
исследования связана~с переходом от императивных утверждений (из
которых строятся программы)~к декларативным (которые можно
использовать для рассуждений).  Связана~с этим~и такая важная область
современных исследований по проектированию языков программирования,
как исследование так называемых\index{ru}{язык программирования|сверхвысокого  уровня||||п}\index{ru}{язык сверхвысокого уровня||very     high-level language|||п}\index{en}{very high-level language||язык сверхвысокого уровня|||п}языков сверхвысокого уровня,~в которых  
программирование на самом деле происходит~в терминах декларативных
утверждений.  Идея состоит~в том, чтобы сделать интерпретаторы
настолько умными, чтобы, получая от программиста знание типа <<что
такое>>, они были бы способны самостоятельно породить знание типа
<<как>>. В общем случае это сделать невозможно, но есть важные
области, где удалось достичь прогресса. Мы вернемся~к этой идее в
главе~\ref{METALINGUISTIC-ABSTRACTION}.}.

Как вычисляются \index{ru}{квадратный корень|||||}квадратные корни?  Наиболее часто
применяется \index{ru}{Ньютона метод|для квадратных корней||||} Ньютонов метод последовательных приближений, который
основан на том, что имея некоторое неточное значение $y$
для квадратного корня из числа $x$, мы можем~с помощью
простой манипуляции получить более точное значение (более близкое к
настоящему квадратному корню), если возьмем среднее между
$y$~и $x/y$\footnote{На самом деле алгоритм нахождения квадратного корня
представляет собой частный случай метода Ньютона, который является
общим методом нахождения корней уравнений.  Собственно алгоритм
нахождения квадратного корня был разработан Героном Александрийским в
\index{ru}{Герон Александрийский||||n|п}
первом веке н.э.  Мы увидим, как выразить общий метод Ньютона~в виде
процедуры на Лиспе, в разделе~\ref{PROCEDURES-AS-RETURNED-VALUES}.}.
Например, мы можем вычислить квадратный корень из 2 следующим образом: 
предположим, что начальное приближение равно 1.
$$ %%%inserted [10pt]
\begin{array}{lll}
  \mbox{Приближение}    & \mbox{Частное } x/y   & \mbox{Среднее} \\[10pt]
  1             & \dfrac{2}{1} = 2               & \dfrac{2+1}{2} = 1.5 \\[10pt]
  1.5           & \dfrac{2}{1.5} = 1.3333        & \dfrac{1.3333+1.5}{2} = 1.4167 \\[10pt]
  1.4167        & \dfrac{2}{1.4167} = 1.4118     & \dfrac{1.4167+1.4118}{2} = 1.4142 \\[10pt]
  1.4142        & \ldots                        & \ldots \\
\end{array}
$$
Продолжая этот процесс, мы получаем все более точные приближения к
квадратному корню.

Теперь формализуем этот процесс~в терминах
процедур. Начнем~с 
\index{ru}{подкоренное
  число||radicand|||}\index{en}{radicand||подкоренное
  число|||}подкоренного числа~и какого-то значения приближения.  Если
приближение достаточно хорошо подходит для наших целей, то процесс закончен;
если нет, мы должны повторить его~с улучшенным значением приближения.
Запишем эту базовую стратегию~в виде процедуры:

\begin{Verbatim}[fontsize=\small]
(define (sqrt-iter guess x)
  (if (good-enough? guess x)
      guess
      (sqrt-iter (improve guess x)
                 x)))
\end{Verbatim}
Значение приближения улучшается~с помощью взятия среднего между ним и
частным подкоренного числа~и старого значения приближения:

\begin{Verbatim}[fontsize=\small]
(define (improve guess x)
  (average guess (/ x guess)))
\end{Verbatim}
где

\begin{Verbatim}[fontsize=\small]
(define (average x y)\index{ru}{average||||pd|}
  (/ (+ x y) 2))
\end{Verbatim}
Нам нужно еще сказать, что такое для нас <<достаточно хорошее>>
приближение.  Следующий вариант сойдет для иллюстрации, но на самом
деле это не очень хороший тест. (См. упражнение~\ref{EX1.7}.)  Идея состоит~в том, чтобы улучшать
приближения до тех пор, пока его квадрат не совпадет с
подкоренным числом~в пределах заранее заданного
допуска (здесь 0.001)\footnote{\index{ru}{соглашение об
    именах|\texttt{?} для
    предикатов||||п}\index{ru}{предикат|соглашение об
    именах||||п}\index{ru}{вопросительный  знак,~в именах
    предикатов||question mark|||п}\index{en}{question
    mark||вопросительный  знак,~в именах предикатов|||п}Обычно мы
  будем давать предикатам
  имена, заканчивающиеся знаком вопроса, чтобы было проще запомнить, что
  это предикаты.  Это не более чем стилистическое соглашение. С точки
  зрения интерпретатора, вопросительный знак --- обыкновенный
  символ.\index{ru}{?,~в именах предикатов||||p|п}}:
\begin{Verbatim}[fontsize=\small]
(define (good-enough? guess x)
  (< (abs (- (square guess) x)) 0.001))
\end{Verbatim}
Наконец, нужно~с чего-то начинать. Например, мы можем для начала
предполагать, что квадратный корень любого числа равен 1\footnote{Обратите внимание, что мы записываем начальное приближение как
1.0,~а не как 1.\index{ru}{зависимость от
  реализации|числа||||п}\index{ru}{целые
  числа|деление||||п}\index{ru}{десятичная точка~в числах||decimal
  point     in numbers|||п}\index{en}{decimal point     in
  numbers||десятичная точка~в числах|||п}\index{ru}{числа|десятичная
  точка||||п}\index{ru}{числа|зависимость от реализации||||п}Во многих
реализациях Лиспа здесь не будет никакой разницы.
Однако интерпретатор \index{ru}{MIT Scheme|числа||||п}MIT Scheme отличает 
\index{ru}{точные целые числа||exact integers|||п}\index{en}{exact
  integers||точные целые числа|||п}\index{ru}{целые
  числа|точные||||п}\index{ru}{числа|точные целые||||п}точные целые числа 
от десятичных значений,~и при 
\index{ru}{деление целых чисел||division of
  integers|||п}\index{en}{division of integers||деление целых
  чисел|||п}делении двух целых получается не 
десятичная дробь, а
\index{ru}{числа|рациональные||||п}\index{ru}{рациональные числа|в MIT
  Scheme||||п}рациональное число.  Например, поделив 10/6,
получим 5/3,~а поделив 10.0/6.0, получим
1.6666666666666667. (Мы увидим, как реализовать арифметические
операции над рациональными числами,~в разделе~\ref{EXMP-ARITH-OPER-FOR-RAT-NUMBERS}.)
Если~в нашей программе квадратного корня мы начнем~с начального
приближения 1,~а $x$ будет точным целым числом, все
последующие значения, получаемые при вычислении квадратного корня,
будут не десятичными дробями,~а рациональными числами.  Поскольку при
смешанных операциях над десятичными дробями~и рациональными числами
всегда получаются десятичные дроби, то начав со значения 1.0, все
прочие мы получим~в виде десятичных дробей.}:
\begin{Verbatim}[fontsize=\small]
(define (sqrt x)\index{ru}{sqrt||||pd|}
  (sqrt-iter 1.0 x))
\end{Verbatim}
Если мы введем эти определения~в интерпретатор, мы сможем использовать 
{\tt sqrt} как любую другую процедуру:

\begin{Verbatim}[fontsize=\small]
(sqrt 9)
\textit{3.00009155413138}

(sqrt (+ 100 37))
\textit{11.704699917758145}

(sqrt (+ (sqrt 2) (sqrt 3)))
\textit{1.7739279023207892}

(square (sqrt 1000))
\textit{1000.000369924366}
\end{Verbatim}

\index{ru}{итеративный процесс|реализованный~с помощью вызова процедуры||||}
Программа {\tt sqrt} показывает также, что того
простого процедурного языка, который мы описали до сих пор,
достаточно, чтобы написать любую чисто вычислительную программу,
которую можно было бы написать, скажем, на Си или Паскале. Это может
показаться удивительным, поскольку~в наш язык мы не включили никаких
\index{ru}{циклические конструкции||looping     constructs|||}\index{en}{looping     constructs||циклические конструкции|||}
итеративных (циклических) конструкций, указывающих компьютеру,
что нужно производить некое действие несколько раз.  {\tt Sqrt-iter}, 
с другой стороны, показывает, как можно выразить итерацию, не имея
никакого специального конструкта, кроме обыкновенной способности
вызвать процедуру\footnote{Читателям, которых заботят вопросы эффективности,
связанные~с использованием вызовов процедур для итерации,
следует обратить внимание на замечания~о <<хвостовой рекурсии>> в
разделе~\ref{LINEAR-RECURSION-AND-ITERATION}.}.
\begin{exercise}{1.6}\label{EX1.6}%
Лиза П. Хакер не понимает, почему {\tt if}\index{ru}{if (особая
  форма)|почему особая форма|||p|(упр.~1.6)}\index{ru}{особая
  форма|необходимость||||(упр.~1.6)}
должна быть особой формой.  <<Почему нельзя просто определить
ее как обычную процедуру~с помощью {\tt cond}?>> --- спрашивает 
она.  Лизина подруга Ева Лу Атор утверждает, что, разумеется, можно,
и определяет новую версию {\tt if}:

\begin{Verbatim}[fontsize=\small]
(define (new-if predicate then-clause else-clause)
  (cond (predicate then-clause)
        (else else-clause)))
\end{Verbatim}
Ева показывает Лизе новую программу:

\begin{Verbatim}[fontsize=\small]
(new-if (= 2 3) 0 5)
\textit{5}

(new-if (= 1 1) 0 5)
\textit{0}
\end{Verbatim}
Обрадованная Лиза переписывает через {\tt new-if}
программу вычисления квадратного корня:
\begin{Verbatim}[fontsize=\small]
(define (sqrt-iter guess x)
  (new-if (good-enough? guess x)
          guess
          (sqrt-iter (improve guess x)
                     x)))
\end{Verbatim}
Что получится, когда Лиза попытается использовать эту процедуру для
вычисления квадратных корней?  Объясните.
\end{exercise}

\begin{exercise}{1.7}\label{EX1.7}%
Проверка {\tt good-enough?}, которую мы
использовали для вычисления квадратных корней, будет довольно
неэффективна для поиска квадратных корней от очень маленьких чисел.
Кроме того,~в настоящих компьютерах арифметические операции почти
всегда вычисляются~с ограниченной точностью.  Поэтому наш тест
оказывается неадекватным~и для очень больших чисел.  Альтернативный
подход~к реализации {\tt good-enough?} состоит~в том, чтобы
следить, как от одной итерации~к другой изменяется {\tt guess}, 
и остановиться, когда изменение оказывается небольшой долей значения
приближения.  Разработайте процедуру вычисления квадратного корня,
которая использует такой вариант проверки на завершение.  Верно ли,
что на больших~и маленьких числах она работает лучше?
\end{exercise}
\begin{exercise}{1.8}\label{EX1.8}%
%\nopagebreak
\index{ru}{кубический корень|метод Ньютона|cubic root|||(упр.~1.8)}%
\index{en}{cubic root||кубический корень|метод Ньютона||(упр.~1.8)}% 
\index{ru}{Ньютона метод|для кубических корней||||(упр.~1.8)}%
Метод Ньютона для кубических корней основан на том, что 
если $y$ является приближением~к кубическому корню из
$x$, то мы можем получить лучшее приближение по формуле
\samepage%%MLR
$$
\dfrac{x/y^2  + 2y}{3}
$$
С помощью этой формулы напишите процедуру вычисления
кубического корня, подобную процедуре для квадратного корня. (В
разделе~\ref{PROCEDURES-AS-RETURNED-VALUES} мы увидим,
что можно реализовать общий метод Ньютона как абстракцию этих процедур для
квадратного~и кубического корня.)
\end{exercise}
\subsection{Процедуры как абстракции типа <<черный ящик>>}
\label{PROCEDURES-AS-BLACK-BOX-ABSTRACTIONS}


{\tt Sqrt} --- наш первый пример процесса,
определенного множеством зависимых друг от друга процедур.  Заметим,
что определение {\tt sqrt-iter}
\index{ru}{рекурсия||recursion|||}\index{en}{recursion||рекурсия|||}{\em рекурсивно} (recursive); 
это означает, что процедура\index{ru}{рекурсивная процедура|определение рекурсивной процедуры||||}
определяется~в терминах самой себя.  Идея, что можно определить
процедуру саму через себя, возможно, кажется Вам подозрительной; 
неясно, как такое <<циклическое>> определение вообще может иметь
смысл, не то что описывать хорошо определенный процесс для исполнения
компьютером.  Более осторожно мы подойдем~к этому~в разделе~\ref{PROCEDURES-AND-THE-PROCESSES-THEY-GENERATE}.
Рассмотрим, однако, некоторые другие важные детали, которые
иллюстрирует пример~с {\tt sqrt}.

Заметим, что задача вычисления квадратных корней
естественным образом\index{ru}{программа|структура||||} разбивается на подзадачи: как понять, что
очередное приближение нас устраивает, как улучшить очередное
приближение,~и так далее.  Каждая из этих задач решается~с помощью
отдельной процедуры. Вся программа {\tt sqrt} может
рассматриваться как пучок процедур (показанный на рис.~\ref{P1.2}), отражающий 
\index{ru}{декомпозиция программы||decomposition of     program into
  parts|||}\index{en}{decomposition of     program into
  parts||декомпозиция программы|||}декомпозицию задачи на
подзадачи.

\begin{cntrfig}
\label{P1.2}
\synttree[ {\tt sqrt} [ {\tt sqrt-iter} [ {\tt good-enough} [ {\tt square} ][ {\tt abs} ]][ {\tt improve} [{\tt average} ]]]]
\caption{Процедурная декомпозиция программы {\tt sqrt}.}
\end{cntrfig}


Важность декомпозиционной стратегии не просто~в том, что
задача разделяется на части. В конце концов, можно взять любую
большую программу~и поделить ее на части: первые десять строк, следующие
десять строк~и так далее.  Существенно то, что каждая процедура
выполняет точно определенную задачу, которая может быть использована
при определении других процедур.  Например, когда мы определяем
процедуру {\tt good-enough?}~с помощью {\tt square}, мы
можем рассматривать процедуру {\tt square} 
как 
\index{ru}{черный ящик||black box|||}\index{en}{black box||черный
  ящик|||}\index{ru}{процедура|как  черный ящик||||}<<черный ящик>>.
В этот момент нас не интересует, {\em как} она
вычисляет свой результат,~--- важно только то, что она способна вычислить
квадрат. О деталях того, как вычисляют квадраты, можно сейчас забыть
и рассмотреть их потом.  Действительно, пока мы рассматриваем
процедуру {\tt good-enough?}, {\tt square} --- не совсем 
процедура, но скорее абстракция процедуры, так называемая 
\index{ru}{процедурная абстракция||procedural abstraction|||}\index{en}{procedural abstraction||процедурная абстракция|||}{\em процедурная
 абстракция} (procedural abstraction). На этом 
уровне абстракции все процедуры, вычисляющие квадрат, одинаково
хороши.
\index{ru}{абстракция|процедурная|abstraction|||}\index{en}{abstraction||абстракция|процедурная||}

Таким образом, если рассматривать только возвращаемые
значения, то следующие две процедуры для возведения числа~в квадрат будут
неотличимы друг от друга. Каждая из них принимает числовой аргумент и
возвращает~в качестве значения квадрат этого числа\footnote{Неясно даже, которая из этих процедур более
эффективна.  Это зависит от того, какая имеется аппаратура.
Существуют машины, на которых <<очевидная>> реализация будет медленней.
Представьте себе машину,~в которой очень эффективным
способом хранятся большие таблицы логарифмов~и обратных
логарифмов.
}.

\begin{Verbatim}[fontsize=\small]
(define (square x) (* x x))

(define (square x) 
  (exp (double (log x))))

(define (double x) (+ x x))
\end{Verbatim}

Таким образом, определение процедуры должно быть способно
скрывать детали.  Может оказаться, что пользователь процедуры не сам
ее написал,~а получил от другого программиста как черный ящик.
От пользователя не должно требоваться знания, как работает процедура, чтобы 
ее использовать.

\paragraph{Локальные имена}


\index{ru}{локальное имя|||||}
Одна из деталей реализации, которая не должна заботить
пользователя процедуры  --- это то, какие человек, писавший процедуру, 
выбрал имена для формальных параметров процедуры. Таким образом,
следующие две процедуры должны быть неотличимы:

\begin{Verbatim}[fontsize=\small]
(define (square x) (* x x))

(define (square y) (* y y))
\end{Verbatim}
Этот принцип --- что значение процедуры не должно зависеть от имен
параметров, которые выбрал ее автор, --- может сначала показаться
очевидным, однако он имеет глубокие следствия.  Простейшее из этих 
следствий состоит~в том, что имена параметров должны быть локальными~в 
теле процедуры.  Например,~в программе вычисления квадратного корня
при определении {\tt good-enough?} мы использовали
{\tt square}: 

\begin{Verbatim}[fontsize=\small]
(define (good-enough? guess x)
  (< (abs (- (square guess) x)) 0.001))
\end{Verbatim}
Намерение автора {\tt good-enough?} состоит~в том, чтобы
определить, достаточно ли близко квадрат первого аргумента лежит ко
второму.  Мы видим, что автор {\tt good-enough?} обращается к
первому аргументу~с помощью имени {\tt guess},~а ко второму с
помощью имени {\tt x}. Аргументом {\tt square} является
{\tt guess}.   Поскольку автор {\tt square} использовал
имя {\tt x} (как мы видели выше), чтобы обратиться~к этому
аргументу, мы видим, что {\tt x}~в {\tt good-enough?}
должно отличаться от {\tt x}~в {\tt square}. Запуск
процедуры {\tt square} не должен отразится на значении
{\tt x}, которое использует {\tt good-enough?},
поскольку это значение {\tt x} понадобится
{\tt good-enough?}, когда {\tt square} будет
вычислена.

Если бы параметры не были локальны по отношению~к телам
своих процедур, то параметр {\tt x}~в {\tt square}
смешался бы~с параметром {\tt x} из {\tt good-enough?},
и поведение {\tt good-enough?} зависело бы от того, какую
версию {\tt square} мы использовали. Таким образом,
процедура {\tt square} не была бы черным ящиком, как мы того хотим.

\index{ru}{формальные параметры процедуры|имена||||}
\index{ru}{имя|формального параметра||||}
У формального параметра особая роль~в определении
процедуры: не имеет значения, какое~у этого
параметра имя. Такое имя называется
\index{ru}{переменная|связанная||||}\index{ru}{связанная переменная||bound variable|||}\index{en}{bound variable||связанная переменная|||}{\em связанной переменной} (bound variable),~и мы будем говорить, что
определение процедуры
\index{ru}{связывание||binding|||}\index{en}{binding||связывание|||}{\em связывает} (binds) свои
формальные параметры.  Значение процедуры не изменяется, если во всем
ее определении параметры последовательным образом переименованы\footnote{Понятие последовательного переименования на самом
деле достаточно тонкое~и трудное для определения.  Знаменитым логикам
случалось делать здесь ужасные ошибки.
}.
Если переменная не связана, мы говорим, что она 
\index{ru}{переменная|свободная||||}
\index{ru}{свободная переменная||free variable|||}\index{en}{free variable||свободная переменная|||}{\em свободна} (free).
Множество выражений, для которых связывание определяет имя, называется
\index{ru}{переменная|область действия||||}
\index{ru}{область действия переменной||scope of a variable|||}\index{en}{scope of a variable||область действия переменной|||}{\em областью действия} (scope) этого имени.~В 
определении процедуры связанные переменные, объявленные как\index{ru}{формальные параметры процедуры|область действия||||}
\index{ru}{процедура|область действия формальных параметров||||} 
\index{ru}{область действия переменной|формальные параметры процедуры||||}
формальные параметры процедуры, имеют своей областью действия тело процедуры.

В приведенном выше определении {\tt good-enough?}, 
{\tt guess}~и {\tt x} --- связанные переменные, а
{\tt <}, {\tt -}, {\tt abs} и
{\tt square} --- свободные.  Значение {\tt good-enough?} 
должно быть независимо от того, какие имена мы выберем для
{\tt guess}~и {\tt x}, пока они остаются отличными друг 
от друга~и от {\tt <}, {\tt -}, {\tt abs} и
{\tt square}. (Если бы мы переименовали {\tt guess} в
{\tt abs}, то породили бы\index{ru}{ошибка|захват          свободной переменной|bug|||}\index{en}{bug||ошибка|захват          свободной переменной||}
ошибку,\index{ru}{свободная переменная|захват||||}
\index{ru}{захват свободной переменной||free variable capture|||}\index{en}{free variable capture||захват свободной переменной|||}{\em захватив} (capture) переменную {\tt abs}. Она
превратилась бы из свободной~в связанную.)  Однако значение
{\tt good-enough?} не является независимым от ее свободных
переменных.  Разумеется, оно зависит от того факта (внешнего по
отношению~к этому определению), что символ {\tt abs} называет
процедуру вычисления модуля числа.  {\tt Good-enough?} будет
вычислять совершенно другую функцию, если~в ее определении мы вместо
{\tt abs} подставим {\tt cos}.

\paragraph{Внутренние определения~и блочная структура}


До сих пор нам был доступен только один вид изоляции
имен: формальные параметры процедуры локальны по отношению~к телу этой 
процедуры.  Программа вычисления квадратного корня иллюстрирует еще
один вид управления использованием имен, которым мы хотели бы
владеть. \index{ru}{программа|структура||||}
Существующая программа состоит из отдельных процедур: 

\begin{Verbatim}[fontsize=\small]
(define (sqrt x)
  (sqrt-iter 1.0 x))

(define (sqrt-iter guess x)
  (if (good-enough? guess x)
      guess
      (sqrt-iter (improve guess x) x)))

(define (good-enough? guess x)
  (< (abs (- (square guess) x)) 0.001))

(define (improve guess x)
  (average guess (/ x guess)))
\end{Verbatim}

Проблема здесь состоит в том, что
единственная процедура, которая важна для пользователей
{\tt sqrt} --- это сама {\tt sqrt}.  Остальные процедуры 
({\tt sqrt-iter}, {\tt good-enough?} и
{\tt improve}) только забивают им головы.  Теперь пользователи не могут
определять других процедур~с именем {\tt good-enough?} ни в
какой другой программе, которая должна работать совместно~с программой 
вычисления квадратного корня, поскольку {\tt sqrt} требуется
это имя.  Эта проблема становится особенно тяжелой при построении
больших систем, которые пишут много различных программистов.
Например, при построении большой библиотеки численных процедур многие
числовые функции вычисляются как последовательные приближения и могут
потому иметь в качестве вспомогательных процедуры
{\tt good-enough?} и {\tt improve}. Нам хотелось бы
локализовать подпроцедуры, спрятав их внутри {\tt sqrt}, так,
чтобы {\tt sqrt} могла сосуществовать~с другими
последовательными приближениями, при том что~у каждой из них была бы
своя собственная процедура {\tt good-enough?}.  Чтобы сделать
это возможным, мы разрешаем процедуре иметь 
\index{ru}{внутренние определения||internal
  definitions|||}\index{en}{internal definitions||внутренние
  определения|||}внутренние определения,
локальные для этой процедуры.  Например, при решении задачи вычисления 
квадратного корня мы можем написать
\looseness=-2

\begin{Verbatim}[fontsize=\small]
(define (sqrt x)
  (define (good-enough? guess x)
    (< (abs (- (square guess) x)) 0.001))
  (define (improve guess x)
    (average guess (/ x guess)))
  (define (sqrt-iter guess x)
    (if (good-enough? guess x)
        guess
        (sqrt-iter (improve guess x) x)))
  (sqrt-iter 1.0 x))
\end{Verbatim}
Такое вложение определений, называемое \index{ru}{блочная структура||block structure|||}\index{en}{block structure||блочная структура|||}{\em блочной структурой} (block struc\-ture), дает правильное решение для
простейшей задачи упаковки имен.  Но здесь таится еще одна идея.
Помимо того, что мы можем вложить определения вспомогательных процедур 
внутрь главной, мы можем их упростить. Поскольку переменная
{\tt x} связана~в определении {\tt sqrt}, процедуры
{\tt good-enough?}, {\tt improve} и
{\tt sqrt-iter}, которые определены внутри {\tt sqrt},
находятся~в области действия {\tt x}. Таким образом, нет нужды
явно передавать {\tt x}~в каждую из этих процедур.  Вместо
этого мы можем сделать {\tt x} свободной переменной во
\index{ru}{внутренние определения|свободная переменная  внутри||||}внутренних определениях, как это показано ниже. Тогда {\tt x}
получит свое значение от аргумента,~с которым вызвана объемлющая их
процедура {\tt sqrt}. Такой порядок называется 
\index{ru}{окружение|и лексическая сфера
  действия||||}\index{ru}{свободная переменная|лексическая сфера
  действия||||}\index{ru}{лексическая сфера действия||lexical
  scoping|||}\index{en}{lexical scoping||лексическая сфера
  действия|||}{\em лексической сферой действия} (lexical scoping)
переменных\footnote{Правило лексической сферы действия говорит, что свободные
переменные~в процедуре ссылаются на связывания этих переменных,
сделанные~в объемлющих определениях процедур; то есть они ищутся в
окружении,~в котором процедура была определена. Мы детально
рассмотрим, как это работает,~в главе~\ref{MODULARITY-OBJECTS-AND-STATE}, когда будем 
подробно описывать окружения~и работу интерпретатора.
\looseness=-1
}.

\begin{Verbatim}[fontsize=\small]
(define (sqrt x)\index{ru}{sqrt|с блочной структурой|||pd|}
  (define (good-enough? guess)
    (< (abs (- (square guess) x)) 0.001))
  (define (improve guess)
    (average guess (/ x guess)))
  (define (sqrt-iter guess)
    (if (good-enough? guess)
        guess
        (sqrt-iter (improve guess))))
  (sqrt-iter 1.0))
\end{Verbatim}

Мы будем часто использовать блочную структуру, чтобы
разбивать большие программы на куски разумного
размера\footnote{\label{F1.28}\index{ru}{внутренние определения|позиция||||п}%
\samepage%
\nopagebreak
Внутренние определения должны быть~в начале тела процедуры.  
За последствия запуска программ, перемешивающих определения 
и их использование, администрация ответственности не несет.}.
Идея\index{ru}{Algol (Алгол)|блочная структура||||}
блочной структуры происходит из языка программирования 
Алгол~60. Она присутствует~в большинстве современных языков
программирования.  Это важный инструмент, который помогает
организовать построение больших программ.
\looseness=-2

\section{Процедуры~и порождаемые ими процессы}
\label{PROCEDURES-AND-THE-PROCESSES-THEY-GENERATE}

В предыдущем разделе мы рассмотрели элементы
программирования. Мы использовали элементарные арифметические операции, 
комбинировали их и абстрагировали получившиеся составные
операции путем определения составных процедур.  Но всего этого еще
недостаточно, чтобы  сказать, что мы умеем программировать.
Положение,~в котором мы находимся, похоже на положение человека,
выучившего шахматные правила, но ничего не знающего об
основных дебютах, тактике и стратегии.  Подобно
шахматисту-новичку, мы пока ничего не знаем об основных схемах
использования понятий~в нашей области знаний.  Нам недостает знаний~о том,
какие именно ходы следует делать (какие именно процедуры имеет
смысл определять), и не хватает опыта предсказания последствий
сделанного хода (выполнения процедуры).
\looseness=-1


Способность предвидеть последствия рассматриваемых действий
необходима для того, чтобы стать квалифицированным
программистом,~--- равно как~и для любой другой синтетической, творческой
деятельности.  Например, квалифицированному фотографу
нужно при взгляде на сцену понимать, насколько темным каждый ее участок
покажется после печати при разном выборе экспозиции~и разных
условиях обработки.  Только после этого можно проводить
обратные рассуждения~и выбирать кадр, освещение, экспозицию~и 
условия обработки так, чтобы получить желаемый результат.  Чтобы стать 
специалистами, нам надо научиться представлять процессы, генерируемые
различными типами процедур.  Только развив в себе 
такую способность, мы сможем научиться надежно строить программы,
которые ведут себя так, как нам надо.
\looseness=-1

\index{ru}{процедура|как шаблон локальной  эволюции процесса||||}\index{ru}{процесс|локальная эволюция||||}%
Процедура представляет собой шаблон 
\index{ru}{локальная эволюция процесса||local evolution of a process|||}\index{en}{local evolution of a process|| процесса|||}{\em локальной эволюции} (local evo\-lu\-tion) вычислительного процесса.  Она
указывает, как следующая стадия процесса строится из предыдущей.  Нам
хотелось бы уметь строить утверждения об общем, или {\em глобальном} 
(global)\index{ru}{глобальное поведение процесса||global behavior of a process|||}\index{en}{global behavior of a process||глобальное поведение процесса|||} поведении процесса, локальная
эволюция которого описана процедурой. В общем случае это сделать
очень сложно, но по крайней мере мы можем попытаться описать некоторые 
типичные схемы эволюции процессов.
\looseness=-1

В этом разделе мы рассмотрим некоторые часто встречающиеся
<<формы>> процессов, генерируемых простыми процедурами.  Кроме того,
мы рассмотрим, насколько сильно эти процессы расходуют такие важные
вычислительные ресурсы, как время~и память. Процедуры, которые мы
будем рассматривать, весьма просты.  Они будут играть такую же роль,
как простые схемы~в фотографии:  это скорее упрощенные прототипические
шаблоны,~а не практические примеры сами по себе.
\looseness=-1

\subsection{Линейные рекурсия~и итерация}
\label{LINEAR-RECURSION-AND-ITERATION}


\index{ru}{итеративный процесс|vs. рекурсивный
  процесс||||}\index{ru}{рекурсивный процесс|vs. итеративный
  процесс||||}Для начала рассмотрим функцию
\index{ru}{факториал||factorial|||}\index{en}{factorial||факториал|||}факториал,
определяемую уравнением 
$$
n! = n \cdot (n - 1) \cdot (n - 2) \cdot \cdot \cdot 3 \cdot 2 \cdot 1
$$
Существует множество способов вычислять факториалы. Один из них
состоит~в том, чтобы заметить, что $n!$ для любого
положительного целого числа $n$ равен
$n$, умноженному на $(n - 1)!$:
$$
n! = n \cdot \lbrack (n - 1) \cdot (n - 2) \cdot \cdot \cdot 3 \cdot 2
\cdot 1 \rbrack = n \cdot (n - 1)!
$$
Таким образом, мы можем вычислить $n!$, вычислив сначала
$(n - 1)!$,~а затем умножив его на $n$. После
того, как мы добавляем условие, что $1!$ равен 1, это
наблюдение можно непосредственно перевести~в процедуру:

\clearpage
\begin{Verbatim}[fontsize=\small]
(define (factorial n)\index{ru}{factorial|линейно рекурсивный вариант|||pd|}
  (if (= n 1)
      1
      (* n (factorial (- n 1)))))
\end{Verbatim}
Можно использовать \index{ru}{подстановочная модель применения процедуры|форма процесса||||}подстановочную модель из раздела~\ref{SUBST-MODEL-FOR-PROC-APPL}
и увидеть эту процедуру~в действии при вычислении 6!, как показано на
рис.~\ref{P1.3}.


\begin{cntrfig}
\input{xfig-mod/1-3.eepic}
\caption{Линейно рекурсивный процесс для вычисления 6!.}
\label{P1.3}
\end{cntrfig}

Теперь рассмотрим вычисление факториала~с другой точки
зрения. Мы можем описать правило вычисления $n!$, сказав,
что мы сначала умножаем 1 на 2, затем результат умножаем на 3, затем
на 4,~и так пока не достигнем $n$. Мы можем описать это
вычисление, сказав, что счетчик~и произведение~с каждым шагом
одновременно изменяются согласно правилу
$$
\begin{array}{c}
  \mbox{произведение} = \mbox{счетчик} \cdot \mbox{произведение} \\
  \mbox{счетчик} = \mbox{счетчик} + 1
\end{array}
$$
и добавив условие, что $n!$ --- это значение произведения~в 
тот момент, когда счетчик становится больше, чем $n$.

Опять же, мы можем перестроить  наше определение в
процедуру вычисления факториала\footnote{В настоящей программе мы,
  скорее всего, спрятали бы определение {\tt fact-iter}~с помощью блочной структуры,
  введенной~в предыдущем разделе:
  
\begin{Verbatim}
(define (factorial n)
  (define (iter product counter)
    (if (> counter n)
        product
        (iter (* counter product)
              (+ counter 1))))
  (iter 1 1))
\end{Verbatim}
  Здесь мы этого не сделали, чтобы как можно меньше думать~о разных
  вещах одновременно.}:

\begin{Verbatim}[fontsize=\small]
(define (factorial n)\index{ru}{factorial|линейно итеративный вариант|||pd|}
  (fact-iter 1 1 n))

(define (fact-iter product counter max-count)
  (if (> counter max-count)
      product
      (fact-iter (* counter product)
                 (+ counter 1)
                 max-count)))
\end{Verbatim}
Как~и раньше, мы можем~с помощью подстановочной модели
изобразить процесс вычисления 6!, как показано на рис.~\ref{P1.4}.


\begin{cntrfig}
\input{xfig-mod/1-4.eepic}
\caption{Линейно итеративный процесс для
вычисления 6!.}
\label{P1.4}
\end{cntrfig}

Сравним эти два процесса. С одной стороны, они
кажутся почти одинаковыми.  Оба они вычисляют одну~и ту же
математическую функцию~с одной~и той же областью определения,~и каждый 
из них для вычисления $n!$ требует количества шагов,
пропорционального $n$.  Действительно, два этих процесса
даже производят одну~и ту же последовательность умножений~и получают
одну~и ту же последовательность частичных произведений. С другой
стороны, когда мы рассмотрим 
\index{ru}{процесс|форма||||}%
\index{ru}{форма процесса||shape of a process|||}\index{en}{shape of a process||форма процесса|||}%
<<формы>> этих двух процессов, мы увидим, 
что они ведут себя совершенно по-разному\-
\looseness=-1

Возьмем первый процесс.  Подстановочная модель
показывает сначала серию расширений,~а затем сжатие, как 
показывает стрелка на рис.~\ref{P1.3}.  Расширение
происходит по мере того, как процесс строит цепочку 
\index{ru}{отложенная операция||deferred operation|||}\index{en}{deferred operation||отложенная операция|||}{\em отложенных операций} (deferred operations),~в данном
случае цепочку умножений.  Сжатие происходит тогда, когда выполняются 
эти отложенные операции.  Такой тип процесса, который характеризуется
цепочкой отложенных операций, называется
\index{ru}{процесс|рекурсивный||||}\index{ru}{рекурсивный
  процесс||recursive process|||}\index{en}{recursive
  process||рекурсивный процесс|||}{\em рекурсивным процессом}
(recursive process).  Выполнение этого
процесса требует, чтобы интерпретатор запоминал, какие операции ему
нужно выполнить впоследствии.  При вычислении $n!$ длина
цепочки отложенных умножений,~а следовательно,~и объем информации,
который требуется, чтобы ее сохранить, растет\index{ru}{линейный
  рост||linear growth|||}\index{en}{linear growth||линейный рост|||}
линейно~с ростом
$n$ (пропорционален $n$), как~и число шагов.
Такой процесс называется \index{ru}{линейно рекурсивный
  процесс||linear recursive process|||}\index{en}{linear recursive
  process||линейно рекурсивный процесс|||}\index{ru}{процесс|линейно
  рекурсивный||||}\index{ru}{рекурсивный процесс|линейный||||}{\em линейно рекурсивным
  процессом} (linear recursive process).

Напротив, второй процесс не растет~и не сжимается.
На каждом шаге при любом значении $n$ необходимо помнить 
лишь текущие значения переменных {\tt pro\-duct},
{\tt counter}~и {\tt max-count}. Такой процесс мы
называем 
\index{ru}{итеративный процесс||iterative        process|||}\index{en}{iterative        process||итеративный процесс|||}\index{ru}{процесс|итеративный||||}{\em итеративным} (iterative        process).

В общем случае, итеративный процесс --- это такой процесс, состояние
которого можно описать конечным числом\index{ru}{переменная состояния||state variable|||}\index{en}{state variable||переменная состояния|||} {\em переменных состояния} (state variables) плюс заранее заданное правило,
определяющее, как эти переменные состояния изменяются от шага~к шагу, и
плюс (возможно) тест на завершение, который определяет условия, при
которых процесс должен закончить работу.  При вычислении
$n!$ число шагов линейно растет~с ростом
$n$. Такой процесс называется 
\index{ru}{итеративный процесс|линейный||||}%
\index{ru}{процесс|линейно итеративный||||}%
\index{ru}{линейно итеративный процесс||linear  iterative process|||}%
\index{en}{linear iterative process||линейно  итеративный процесс|||}{\em линейно итеративным процессом} (linear iterative process).

Можно посмотреть на различие этих двух процессов~и~с другой 
точки зрения. В итеративном случае~в каждый момент переменные
программы дают полное описание состояния процесса.  Если мы остановим
процесс между шагами, для продолжения вычислений нам будет достаточно
дать интерпретатору значения трех переменных программы. С рекурсивным 
процессом это не так. В этом случае имеется дополнительная
<<спрятанная>> информация, которую хранит интерпретатор~и которая не
содержится~в переменных программы.  Она указывает, <<где находится>>
процесс~в терминах цепочки отложенных операций.  Чем длиннее цепочка,
тем больше информации нужно хранить\footnote{Когда~в главе~\ref{COMPUTING-WITH-REGISTER-MACHINES} мы будем
обсуждать реализацию процедур~с помощью регистровых машин, мы увидим,
что итеративный процесс можно реализовать <<в аппаратуре>> как машину, 
у которой есть только конечный набор регистров~и нет никакой
дополнительной памяти.  Напротив, для реализации рекурсивного процесса 
требуется машина со вспомогательной структурой данных,
называемой\index{ru}{стек||stack|||п}\index{en}{stack||стек|||п}{\em стек} (stack).
}.

Противопоставляя итерацию~и рекурсию, нужно вести себя
осторожно~и не смешивать понятие рекурсивного  
\index{ru}{рекурсивная процедура|vs. рекурсивный     процесс|recursive
  procedure|||}\index{en}{recursive procedure||рекурсивная
  процедура|vs. рекурсивный     процесс||}\index{ru}{рекурсивный
  процесс|vs. рекурсивная процедура||||}% 
{\em процесса}
с понятием рекурсивной {\em процедуры}.  Когда мы говорим, что
процедура рекурсивна, мы имеем~в виду факт синтаксиса:
определение процедуры ссылается (прямо или косвенно) на саму эту
процедуру.  Когда же мы говорим~о процессе, что он следует, скажем,
линейно рекурсивной схеме, мы говорим~о развитии процесса,~а не~о 
синтаксисе,~с помощью которого написана процедура.  Может показаться
странным, например, высказывание <<рекурсивная процедура
{\tt fact-iter} описывает итеративный процесс>>.  Однако процесс
действительно является итеративным: его состояние полностью
описывается тремя переменными состояния,~и чтобы выполнить этот
процесс, интерпретатор должен хранить значение только трех
переменных.

Различие между процессами и
процедурами может запутывать отчасти потому, что большинство
реализаций обычных языков (включая Аду, Паскаль~и Си) построены
так,
\index{ru}{Ada (Ада)|рекурсивные процедуры||||}\index{ru}{Pascal
  (Паскаль)|рекурсивные процедуры||||}\index{ru}{C (Си)|рекурсивные
  процедуры||||}что интерпретация любой рекурсивной процедуры
поглощает объем памяти,
линейно растущий пропорционально количеству вызовов процедуры, даже
если описываемый ею процесс~в принципе итеративен.  Как следствие,
эти языки способны описывать итеративные процессы только с
помощью специальных\index{ru}{циклические
  конструкции|||||}<<циклических конструкций>> вроде {\tt do},
{\tt repeat}, {\tt until}, {\tt for} и
{\tt while}.  Реализация Scheme, которую мы рассмотрим~в 
главе~\ref{COMPUTING-WITH-REGISTER-MACHINES}, свободна от этого
недостатка.  Она будет выполнять итеративный процесс, используя
фиксированный объем памяти, даже если он описывается рекурсивной
процедурой.  Такое свойство реализации языка называется поддержкой
\index{ru}{хвостовая рекурсия||tail recursion|||}\index{en}{tail recursion||хвостовая рекурсия|||}{\em хвостовой рекурсии} (tail recursion)\translationnote{Словарь {\tt multitran.ru} дает перевод
<<концевая рекурсия>>.  Наш вариант, как кажется, изящнее~и сохраняет
метафору, содержащуюся~в англоязычном термине.
}.
Если
реализация языка поддерживает хвостовую рекурсию, то 
\index{ru}{итеративный процесс|реализованный~с помощью вызова
  процедуры||||}итерацию можно выразить~с помощью обыкновенного
механизма вызова функций, так что 
специальные циклические конструкции имеют смысл только как
\index{ru}{синтаксический сахар|циклические
  конструкции||||}синтаксический сахар\footnote{Довольно долго
  считалось, что хвостовая рекурсия --- 
особый трюк~в оптимизирующих компиляторах.  Ясное семантическое
основание хвостовой рекурсии было найдено Карлом Хьюиттом (Hewitt
1977),\index{ru}{Хьюитт, Карл Эдди||Carl Eddie
  Hewitt||n|п}\index{en}{Carl Eddie Hewitt||Хьюитт, Карл Эдди||n|п}
который выразил 
ее~в терминах модели вычислений~с помощью \index{ru}{передача сообщений|и хвостовая рекурсия||||п}<<передачи сообщений>> (мы
рассмотрим эту модель~в главе~\ref{MODULARITY-OBJECTS-AND-STATE}).
Вдохновленные этим,  Джеральд Джей Сассман~и  Гай Льюис Стил
мл.\index{ru}{Стил, Гай Льюис мл.||Guy Lewis Steele
  Jr.||n|п}\index{en}{Guy Lewis Steele Jr.||Стил, Гай Льюис мл.||n|п}
(см. Steele 1975) построили
интерпретатор Scheme~с поддержкой хвостовой рекурсии.  Позднее Стил
показал, что хвостовая рекурсия является следствием естественного
способа компиляции вызовов процедур (Steele 1977).
\index{ru}{хвостовая рекурсия|в Scheme||||п}Стандарт Scheme IEEE требует, 
чтобы все реализации Scheme поддерживали хвостовую рекурсию.}.

\begin{exercise}{1.9}\label{EX1.9}%
Каждая из следующих двух процедур определяет способ
сложения двух положительных целых чисел~с помощью процедур
{\tt inc}, которая добавляет~к своему аргументу 1, и
{\tt dec}, которая отнимает от своего аргумента 1.

\begin{Verbatim}[fontsize=\small]
(define (+ a b)
  (if (= a 0)
      b
      (inc (+ (dec a) b))))

(define (+ a b)
  (if (= a 0)
      b
      (+ (dec a) (inc b))))
\end{Verbatim}
Используя подстановочную модель, проиллюстрируйте процесс, порождаемый 
каждой из этих процедур, вычислив {\tt (+ 4 5)}. Являются ли
эти процессы итеративными или рекурсивными?
\end{exercise}
\begin{exercise}{1.10}\label{EX1.10}%
Следующая процедура вычисляет математическую функцию,
называемую функцией Аккермана.\index{ru}{функция (математическая)|Аккермана||||(упр.~1.10)}
\index{ru}{Аккермана функция||Ackermann's function|||(упр.~1.10)}\index{en}{Ackermann's function||Аккермана функция|||(упр.~1.10)}

\begin{Verbatim}[fontsize=\small]
(define (A x y)
  (cond ((= y 0) 0)
        ((= x 0) (* 2 y))
        ((= y 1) 2)
        (else (A (- x 1)
                 (A x (- y 1))))))
\end{Verbatim}
Каковы значения следующих выражений?

\begin{Verbatim}[fontsize=\small]
(A 1 10)

(A 2 4)

(A 3 3)
\end{Verbatim}
Рассмотрим следующие процедуры, где {\tt A} --- процедура,
определенная выше:

\begin{Verbatim}[fontsize=\small]
(define (f n) (A 0 n))

(define (g n) (A 1 n))

(define (h n) (A 2 n))

(define (k n) (* 5 n n))
\end{Verbatim}
Дайте краткие математические определения функций, вычисляемых
процедурами {\tt f}, {\tt g}~и {\tt h} для
положительных целых значений $n$. Например, {\tt (k
n)} вычисляет $5n^2$.
\end{exercise}

\subsection{Древовидная рекурсия}
\label{TREE-RECURSION}


Существует еще одна часто встречающаяся схема вычислений,
называемая 
\index{ru}{процесс|древовидно-рекурсивный||||}%
\index{ru}{рекурсивный процесс|древовидный||||}%
\index{ru}{древовидная рекурсия||tree recursion|||}%
\index{en}{tree recursion||древовидная рекурсия|||}%
{\em древовидная  рекурсия} (tree recursion).~В качестве примера рассмотрим вычисление
последовательности 
\index{ru}{Фибоначчи числа||Fibonacci numbers|||}\index{en}{Fibonacci numbers||Фибоначчи числа|||}%
чисел Фибоначчи,~в которой каждое число является суммой двух предыдущих\-:
$$
0, 1, 1, 2, 3, 5, 8, 13, 21, \ldots
$$
Общее правило для чисел Фибоначчи можно сформулировать так:
$$
\mathop{\rm Fib}(n) =
  \left\{
    \begin{array}{ll}
      0 & \mbox{если } n = 0 \\
      1 & \mbox{если } n = 1 \\
      \mathop{\rm Fib} (n - 1) + \mathop{\rm Fib} (n - 2) & \mbox{в
остальных случаях}\\
   \end{array}
 \right.
$$
Можно немедленно преобразовать это определение~в процедуру:

\begin{Verbatim}[fontsize=\small]
(define (fib n)\index{ru}{fib|древовидно-рекурсивный вариант|||pd|}
  (cond ((= n 0) 0)
        ((= n 1) 1)
        (else (+ (fib (- n 1))
                 (fib (- n 2))))))
\end{Verbatim}

Рассмотрим схему этого вычисления. Чтобы вычислить
{\tt (fib 5)}, мы сначала вычисляем {\tt (fib 4)} и
{\tt (fib 3)}. Чтобы вычислить {\tt (fib 4)}, мы
вычисляем {\tt (fib 3)}~и {\tt (fib 2)}.~В общем,
получающийся процесс похож на дерево, как показано на рис.~\ref{P1.5}.  Заметьте, что на каждом уровне (кроме
дна) ветви разделяются надвое; это отражает тот факт, что процедура
{\tt fib} при каждом вызове обращается~к самой себе
дважды.


\begin{cntrfig}
\input{xfig-mod/1-5.eepic}
\caption{Древовидно-рекурсивный процесс,
порождаемый при вычислении {\tt (fib~5)}.}
\label{P1.5}
\end{cntrfig}

Эта процедура полезна как пример прототипической
древовидной рекурсии, но как метод получения чисел Фибоначчи она ужасна,
поскольку производит массу излишних вычислений.  Обратите внимание на
рис.~\ref{P1.5}: все вычисление {\tt (fib 3)}~--- почти половина общей 
работы,~--- повторяется дважды. В сущности,
нетрудно показать, что общее число раз, которые эта процедура вызовет
{\tt (fib~1)} или {\tt (fib~0)} (в общем, число листьев) 
в точности равняется $\mathop{\rm Fib}(n + 1)$. Чтобы понять,
насколько это плохо, отметим, что значение $\mathop{\rm
Fib}(n)$ 
\index{ru}{древовидно-рекурсивное вычисление чисел     Фибоначчи||tree-recursive Fi\-bo\-nac\-ci-number     computation|||}\index{en}{tree-recursive Fibonacci-number     computation||древовидно-рекурсивное вычисление чисел     Фибоначчи|||} %
растет экспоненциально при увеличении
$n$. Более точно (см. упражнение~\ref{EX1.13}),
$\mathop{\rm Fib}(n)$ --- это целое число, ближайшее~к 
$\phi^n / \sqrt{5}$, где
$$
\phi = (1 + \sqrt{5}) / 2 \approx 1.6180
$$
то есть \index{ru}{золотое сечение||golden ratio|||}%
\index{en}{golden ratio||золотое сечение|||}%
{\em золотое сечение} (golden ratio), которое
удовлетворяет уравнению
$$
\phi^2 = \phi + 1
$$
Таким образом, число шагов нашего процесса растет экспоненциально
при увеличении аргумента. С другой стороны, требования~к памяти
растут при увеличении аргумента всего лишь линейно, поскольку~в каждой 
точке вычисления нам требуется запоминать только те вершины, которые
находятся выше нас по дереву. В общем случае число шагов, требуемых
древовидно-рекурсивным процессом, будет пропорционально числу вершин
дерева,~а требуемый объем памяти будет пропорционален максимальной
глубине дерева.

Для получения чисел Фибоначчи мы можем сформулировать
итеративный процесс.  Идея состоит~в том, чтобы использовать пару целых
$a$~и $b$, которым~в начале даются
значения $\mathop{\rm Fib}(1) = 1$~и $\mathop{\rm
Fib}(0) = 0$,~и на каждом шаге применять одновременную
трансформацию
$$
\begin{array}{l}
 a \gets a + b \\
 b \gets a
\end{array}
$$
Нетрудно показать, что после того, как мы проделаем эту трансформацию
$n$ раз, $a$~и $b$ будут
соответственно равны $\mathop{\rm Fib}(n + 1)$~и 
$\mathop{\rm Fib}(n)$.  Таким образом, мы можем итеративно
вычислять числа Фибоначчи при помощи процедуры

\begin{Verbatim}[fontsize=\small]
(define (fib n)\index{ru}{fib|линейно-итеративный вариант|||p|}
  (fib-iter 1 0 n))

(define (fib-iter a b count)
  (if (= count 0)
      b
      (fib-iter (+ a b) a (- count 1))))
\end{Verbatim}
Второй метод вычисления чисел Фибоначчи представляет собой линейную
итерацию.  Разница~в числе шагов, требуемых двумя этими методами ---
один пропорционален $n$, другой растет так же быстро, как~и 
само $\mathop{\rm Fib}(n)$, --- огромна, даже для небольших 
значений аргумента.

Не нужно из этого делать вывод, что древовидно-рекурсивные
процессы бесполезны.  Когда мы будем рассматривать процессы,
работающие не~с числами, а~с иерархически структурированными данными,
мы увидим, что древовидная рекурсия является естественным~и мощным
инструментом\footnote{Пример этого был упомянут~в разделе~\ref{EVALUATING-COMBINATIONS}: сам интерпретатор
вычисляет выражения~с помощью дре\-во\-видно-рекурсивного процесса.
}.
Но даже при работе~с числами древовидно-рекурсивные процессы могут быть 
полезны~--- они помогают нам понимать~и проектировать программы.  Например, 
хотя первая процедура {\tt fib}~и намного менее эффективна, чем
вторая, зато она проще, поскольку это немногим более, чем перевод
определения последовательности чисел Фибоначчи на Лисп.  Чтобы
сформулировать итеративный алгоритм, нам пришлось заметить, что
вычисление можно перестроить в виде итерации~с тремя 
переменными \mbox{состояния}.

\paragraph{Размен денег}


\index{ru}{размен денег||counting change|||}\index{en}{counting change||размен денег|||}
Чтобы сочинить итеративный алгоритм для чисел Фибоначчи,
нужно совсем немного смекалки.  Теперь для контраста рассмотрим
следующую задачу: сколькими способами можно разменять сумму~в 1
доллар, если имеются монеты по 50, 25, 10, 5~и 1 цент? В более
общем случае, можно ли написать процедуру подсчета способов размена 
для произвольной суммы денег?

У этой задачи есть простое решение~в виде рекурсивной
процедуры.  Предположим, мы как-то упорядочили типы монет, которые у
нас есть.~В таком случае верно будет следующее уравнение:

Число способов разменять сумму $a$~с помощью $n$ типов монет равняется
\begin{plainlist}
\item числу способов разменять сумму
$a$~с помощью всех типов монет, кроме первого, плюс

\item число способов разменять сумму $a -
d$~с использованием всех $n$ типов монет, где
$d$~--- достоинство монет первого типа.
\end{plainlist}

Чтобы увидеть, что это именно так, заметим, что способы
размена могут быть поделены на две группы: те, которые не используют
первый тип монеты,~и те, которые его используют.  Следовательно, общее 
число способов размена какой-либо суммы равно числу способов разменять 
эту сумму без привлечения монет первого типа плюс число способов размена 
в предположении, что мы этот тип используем.  Но последнее число равно 
числу способов размена для суммы, которая остается после того, как мы
один раз употребили первый тип монеты.

Таким образом, мы можем рекурсивно свести задачу размена
данной суммы~к задаче размена меньших сумм~с помощью меньшего
количества типов монет.  Внимательно рассмотрите это правило редукции
и убедите себя, что мы можем использовать его для описания алгоритма,
если укажем следующие вырожденные случаи\footnote{Рассмотрите для примера~в деталях, как применяется правило
редукции, если нужно разменять 10 центов на монеты~в 1~и 5 центов.
}:

\begin{plainlist}


\item
Если $a$~в точности равно 0, мы считаем, 
что имеем 1 способ размена.

\item
Если $a$ меньше 0, мы считаем, что имеем 
0 способов размена.

\item
Если $n$ равно 0, мы считаем, что имеем
0 способов размена.
\end{plainlist}
Это описание легко перевести~в рекурсивную процедуру:

\begin{Verbatim}[fontsize=\small]
(define (count-change amount)\index{ru}{count-change||||pd|}
  (cc amount 5))

(define (cc amount kinds-of-coins)
  (cond ((= amount 0) 1)
        ((or (< amount 0) (= kinds-of-coins 0)) 0)
        (else (+ (cc amount
                     (- kinds-of-coins 1))
                 (cc (- amount
                        (first-denomination kinds-of-coins))
                     kinds-of-coins)))))

(define (first-denomination kinds-of-coins)
  (cond ((= kinds-of-coins 1) 1)
        ((= kinds-of-coins 2) 5)
        ((= kinds-of-coins 3) 10)
        ((= kinds-of-coins 4) 25)
        ((= kinds-of-coins 5) 50)))
\end{Verbatim}
(Процедура {\tt first-denomination} принимает~в качестве входа
число доступных типов монет~и возвращает достоинство первого
типа. Здесь мы упорядочили монеты от самой крупной~к более мелким, но
годился бы~и любой другой порядок.)  Теперь мы можем ответить на
исходный вопрос~о размене доллара:

\begin{Verbatim}[fontsize=\small]
(count-change 100)
\textit{292}
\end{Verbatim}

{\tt Count-change} порождает \index{ru}{эффективность|древовидно-рекурсивного процесса||||}
древовидно-рекурсивный
процесс~с избыточностью, похожей на ту, которая возникает~в нашей
первой реализации {\tt fib}. (На то, чтобы получить ответ 292,
уйдет заметное время.) С другой стороны, неочевидно, как построить
более эффективный алгоритм для получения этого результата,~и мы
оставляем это~в качестве задачи для желающих.  Наблюдение, что древовидная
рекурсия может быть весьма неэффективна, но зато ее часто легко 
сформулировать~и понять, привело исследователей~к мысли, что можно
получить лучшее из двух миров, если спроектировать <<умный
компилятор>>, который мог бы трансформировать древовидно-рекурсивные
процедуры~в более эффективные, но вычисляющие тот же результат\footnote{Один из способов избежать избыточных вычислений
состоит~в том, чтобы автоматически строить таблицу значений по мере
того, как они вычисляются.  Каждый раз, когда нужно применить
процедуру~к какому-нибудь аргументу, мы могли бы сначала обращаться к
таблице, смотреть, не хранится ли~в ней уже значение, и~в этом 
случае мы избежали бы избыточного вычисления.  Такая стратегия,
называемая \index{ru}{табуляризация||tabulation|||п}\index{en}{tabulation||табуляризация|||п}{\em табуляризацией} (tabulation) или
\index{ru}{мемоизация||memoization|||п}\index{en}{memoization||мемоизация|||п}{\em мемоизацией} (memoization), легко реализуется.
Иногда~с помощью табуляризации можно
преобразовать процессы, требующие экспоненциального числа шагов (вроде 
{\tt count-change}),~в процессы, требования которых~к времени и
памяти линейно растут по мере роста ввода. См. упражнение~\ref{EX3.27}.}.
\begin{exercise}{1.11}%
\label{EX1.11}%
Функция $f$ определяется правилом: $f(n) = 
n$, если $n < 3$,~и $f(n) = f(n - 1) + 2 f(n - 2)
+ 3 f(n - 3)$, если $n \ge 3$. Напишите процедуру,
вычисляющую $f$~с помощью рекурсивного процесса.  Напишите
процедуру, вычисляющую $f$~с помощью итеративного процесса.
\end{exercise}
\begin{exercise}{1.12}\label{EX1.12}%
Приведенная ниже таблица называется 
\index{ru}{треугольник Паскаля||Pascal's triangle|||(упр.~1.12)}\index{en}{Pascal's triangle||треугольник Паскаля|||(упр.~1.12)}{\em треугольником Паскаля} (Pascal's triangle).
$$
\begin{array}{ccccccccc}
&&&& 1 \\
&&& 1 && 1 \\
&& 1 && 2 && 1 \\
& 1 && 3 && 3 && 1 \\
1 && 4 && 6 && 4 && 1 \\
&&&& \ldots \\
\end{array}
$$
Все числа по краям треугольника равны 1,~а каждое число внутри
треугольника равно сумме двух чисел над ним\footnote{Элементы треугольника Паскаля называются 
 \index{ru}{биномиальный коэффициент||binomial
    coefficients|||п}\index{en}{binomial coefficients||биномиальный
    коэффициент|||п}{\em биномиальными коэффициентами} (binomial
  coefficients),
  поскольку $n$-й ряд состоит из коэффициентов термов при
  разложении $(x + y)^n$. Эта схема вычисления коэффициентов
  появилась~в передовой работе  Блеза Паскаля\index{ru}{Паскаль,
    Блез||Blaise Pascal||n|п}\index{en}{Blaise Pascal||Паскаль,
    Блез||n|п} 
  1653 года по теории вероятностей
  {\em Trait\'e du triangle arithm\'etique}. Согласно 
  Knuth 1973,\index{ru}{Кнут,
    Дональд~Э.||Donald~E. Knuth||n|п}\index{en}{Donald~E. Knuth||Кнут,
    Дональд~Э.||n|п} 
  та же схема встречается в
  труде {\em Цзу-юань Юй-чэнь} (<<Драгоценное зеркало
  четырех элементов>>), опубликованном китайским математиком Цзю
  Ши-Цзе\index{ru}{Цзю Ши-Цзе||Chu Shih-Chieh||n|п}\index{en}{Chu
    Shih-Chieh||Цзю Ши-Цзе||n|п}
 в 1303 году,~в трудах персидского поэта~и математика
  двенадцатого века Омара Хайяма\index{ru}{Хайям, Омар||||n|п}
  и~в работах индийского математика
  двенадцатого века Бхаскары Ачарьи.\index{ru}{Ачарья,
    Бхаскара||Bh\'ascara \'Ach\'arya||n|п}\index{en}{Bh\'ascara
    \'Ach\'arya||Ачарья, Бхаскара||n|п}}.
Напишите процедуру, вычисляющую элементы треугольника Паскаля с
помощью рекурсивного процесса.
\end{exercise}
\begin{exercise}{1.13}\label{EX1.13}%
Докажите, что $\mathop{\rm Fib}(n)$ есть целое 
число, ближайшее~к $\phi^n / \sqrt{5}$, где $\phi = 
(1 + \sqrt{5}) / 2$. Указание: пусть $\psi = (1 -
\sqrt{5}) / 2$.~С помощью определения чисел
Фибоначчи (см. раздел~\ref{TREE-RECURSION})~и индукции
докажите, что $\mathop{\rm Fib}(n) = (\phi^n - \psi^n) 
/ \sqrt{5}$.
\end{exercise}

\subsection{Порядки роста}
\label{ORDERS-OF-GROWTH}


Предшествующие примеры показывают, что процессы могут
значительно различаться по количеству вычислительных
ресурсов, которые они потребляют.  Удобным способом описания этих
различий является понятие\index{ru}{процесс|порядок  роста||||}
\index{ru}{порядок роста||order of growth|||}\index{en}{order of growth||порядок роста|||}{\em порядка
роста} (order of growth), которое дает общую оценку\index{ru}{процесс|необходимые ресурсы||||} ресурсов, необходимых
процессу при увеличении его входных данных.

Пусть $n$ --- параметр, измеряющий размер
задачи,~и пусть $R(n)$ --- количество ресурсов, необходимых 
процессу для решения задачи размера $n$. В предыдущих
примерах $n$ было числом, для которого требовалось
вычислить некоторую функцию, но возможны~и другие варианты.
Например, если требуется вычислить приближение к
квадратному корню числа, то $n$ может быть числом цифр
после запятой, которые нужно получить. В задаче умножения матриц
$n$ может быть количеством рядов~в матрицах.  Вообще
говоря, может иметься несколько характеристик задачи, относительно
которых желательно проанализировать данный процесс.
Подобным образом, $R(n)$ может измерять количество
используемых целочисленных регистров памяти, количество исполняемых
элементарных машинных операций,~и так далее.~В компьютерах, которые
выполняют определенное число операций за данный отрезок времени,
требуемое время будет пропорционально необходимому числу элементарных
машинных операций.

Мы говорим, что $R(n)$ имеет порядок роста 
\index{ru}{порядок роста|способ записи||||} 
\index{ru}{тета от $f(n)$ ($\Theta(f(n))$)|||||}
$\Theta(f(n))$, что записывается $R(n) =
\Theta(f(n))$~и произносится <<тета от $f(n)$>>, если 
существуют положительные постоянные $k_1$ и
$k_2$, независимые от $n$, такие, что
$$
k_1 f(n) \le R(n) \le k_2 f(n)
$$
для всякого достаточно большого $n$. (Другими словами,
значение $R(n)$ заключено между $k_1 f(n)$ и
$k_2 f(n)$.)

\index{ru}{линейно рекурсивный процесс|порядок роста||||}%
\index{ru}{порядок роста|линейно рекурсивный процесс||||}\index{ru}{рекурсивный процесс|линейный||||}%  
Например, для линейно рекурсивного процесса вычисления
факториала, описанного~в разделе~\ref{LINEAR-RECURSION-AND-ITERATION}, число шагов
растет пропорционально входному значению $n$.  Таким образом, число
шагов, необходимых этому процессу, растет как
$\Theta(n)$.  Мы видели также, что%
\index{ru}{итеративный процесс|линейный||||}%
\index{ru}{линейно итеративный процесс|порядок роста||||}%
требуемый объем памяти%
\index{ru}{порядок роста|линейно итеративный процесс||||}% 
растет как $\Theta(n)$.  Для итеративного факториала число
шагов по-прежнему $\Theta(n)$, но объем памяти
$\Theta(1)$ --- то есть константа\footnote{В этих утверждениях скрывается важное упрощение.
Например, если мы считаем шаги процесса как <<машинные операции>>, мы
предполагаем, что число машинных операций, нужных, скажем, 
для вычисления произведения, не зависит от размера
умножаемых чисел,~а это становится неверным при достаточно больших
числах.  Те же замечания относятся~и~к оценке требуемой памяти.
Подобно проектированию~и описанию процесса, анализ процесса может
происходить на различных уровнях абстракции.
}.
\index{ru}{порядок роста|древовидно-рекурсивный процесс||||}%
\index{ru}{рекурсивный процесс|древовидный||||}%
\index{ru}{древовидная рекурсия|порядок роста||||}%
Древовидно-рекурсивное вычисление чисел Фибоначчи требует
$\Theta(\phi^n)$ шагов~и $\Theta(n)$ памяти, где 
$\phi$ --- золотое сечение, описанное~в разделе~\ref{TREE-RECURSION}.

Порядки роста дают всего лишь грубое описание поведения
процесса.  Например, процесс, которому требуется $n^2$
шагов, процесс, которому требуется $1000n^2$ шагов и
процесс, которому требуется $3n^2 + 10n + 17$ шагов --- все 
имеют порядок роста $\Theta(n^2)$. С другой стороны,
порядок роста показывает, какого изменения можно ожидать в
поведении процесса, когда мы меняем размер задачи.  
\index{ru}{экспоненциальный рост||exponential     growth|||}\index{en}{exponential     growth||экспоненциальный рост|||} 
Для процесса с
порядком\index{ru}{линейный рост|||||} роста $\Theta(n)$ 
(линейного) удвоение размера задачи примерно удвоит количество используемых 
ресурсов.  Для экспоненциального процесса каждое увеличение размера задачи 
на единицу будет умножать количество ресурсов на постоянный коэффициент.  
В оставшейся части раздела~\ref{PROCEDURES-AND-THE-PROCESSES-THEY-GENERATE} мы
рассмотрим два алгоритма, которые имеют\index{ru}{логарифмический
  рост||logarithmic     growth|||}\index{en}{logarithmic
  growth||логарифмический рост|||}
логарифмический порядок роста, 
так что удвоение размера задачи увеличивает требования~к ресурсам на
постоянную величину.
\begin{exercise}{1.14}\label{EX1.14}%
Нарисуйте дерево, иллюстрирующее процесс, который порождается
процедурой {\tt count-change} из раздела~\ref{TREE-RECURSION} при размене 11 центов. Каковы
порядки роста памяти~и числа шагов, используемых этим процессом при
увеличении суммы, которую требуется разменять?
\end{exercise}
\begin{exercise}{1.15}\label{EX1.15}%
\index{ru}{синус|приближение при малых  углах|sine|||(упр.~1.15)}%
\index{en}{sine||синус|приближение при малых  углах||(упр.~1.15)}%
Синус угла (заданного~в радианах) можно вычислить,
если воспользоваться приближением $\sin x \approx x$ при малых
$x$~и употребить тригонометрическое тождество
$$
\sin x = 3 \sin \dfrac{x}{3} - 4 \sin ^3 \dfrac{x}{3}
$$
для уменьшения значения аргумента $\sin$. (В этом
упражнении мы будем считать, что угол <<достаточно мал>>, если он не
больше 0.1 радиана.)  Эта идея используется~в следующих процедурах:

\begin{Verbatim}[fontsize=\small]
(define (cube x) (* x x x))\index{ru}{cube||||pd|(упр.~1.15)}

(define (p x) (- (* 3 x) (* 4 (cube x))))

(define (sine angle)
   (if (not (> (abs angle) 0.1))
       angle
       (p (sine (/ angle 3.0)))))
\end{Verbatim}

\begin{plainenum}

\item
Сколько раз вызывается процедура {\tt p} при 
вычислении {\tt (sine 12.15)}?

\item
Каковы порядки роста~в терминах количества шагов и
используемой памяти (как функция $a$) для процесса,
порождаемого процедурой {\tt sine} при вычислении {\tt (sine a)}?
\end{plainenum}
\end{exercise}

\subsection{Возведение~в степень}
\label{EXPONENTIATION}


\index{ru}{возведение~в степень||exponentiation|||}\index{en}{exponentiation||возведение~в степень|||}
Рассмотрим задачу возведения числа~в степень.  Нам нужна
процедура, которая, приняв~в качестве аргумента основание $b$ 
и положительное целое значение степени $n$, возвращает
$b^n$.  Один из способов получить желаемое --- через
рекурсивное определение
$$
\begin{array}{rcl}
 b^n & = & b \cdot b^{n-1} \\
 b^0 & = & 1
\end{array}
$$
которое прямо переводится~в процедуру

\begin{Verbatim}[fontsize=\small]
(define (expt b n)\index{ru}{expt|линейно рекурсивный вариант|||pd|}
  (if (= n 0)
      1
      (* b (expt b (- n 1)))))
\end{Verbatim}
Это линейно рекурсивный процесс, требующий $\Theta(n)$
шагов~и $\Theta(n)$ памяти.  Подобно факториалу, мы можем
немедленно сформулировать эквивалентную линейную итерацию:

\begin{Verbatim}[fontsize=\small]
(define (expt b n)\index{ru}{expt|линейно итеративный вариант|||pd|}
  (expt-iter b n 1))

(define (expt-iter b counter product)
  (if (= counter 0)
      product
      (expt-iter b
                (- counter 1)
                (* b product)))) 
\end{Verbatim}
Эта версия требует $\Theta(n)$ шагов и
$\Theta(1)$ памяти.

Можно вычислять степени за меньшее число шагов, если
использовать 
\index{ru}{последовательное возведение~в квадрат||successive squaring|||}\index{en}{successive squaring||последовательное возведение~в квадрат|||}
последовательное возведение~в квадрат. Например, вместо
того, чтобы вычислять $b^8$~в виде
$$
b \cdot (b \cdot (b \cdot (b \cdot (b \cdot (b \cdot (b \cdot b))))))
$$
мы можем вычислить его за три умножения:
$$
\begin{array}{l}
 b^2 = b \cdot b \\
 b^4 = b^2 \cdot b^2 \\
 b^8 = b^4 \cdot b^4 \\
\end{array}
$$

Этот метод хорошо работает для степеней, которые сами
являются степенями двойки. В общем случае при вычислении степеней мы
можем получить преимущество от последовательного возведения~в квадрат,
если воспользуемся правилом
$$
\begin{array}{ll}
 b^n = (b^{n / 2})^2 & \mbox{если $n$ четно} \\
 b^n = b \cdot b^{n-1} & \mbox{если $n$ нечетно} \\
\end{array}
$$
Этот метод можно выразить~в виде процедуры

\begin{Verbatim}[fontsize=\small]
(define (fast-expt b n)\index{ru}{fast-expt||||pd|}
  (cond ((= n 0) 1)
        ((even? n) (square (fast-expt b (/ n 2))))
        (else (* b (fast-expt b (- n 1))))))
\end{Verbatim}
где предикат, проверяющий целое число на четность, определен через
элементарную процедуру 
\index{ru}{элементарные процедуры|{\tt remainder}||||}   
\index{ru}{remainder (элементарная процедура)||||pd|} 
{\tt remainder}:

\begin{Verbatim}[fontsize=\small]
(define (even? n)\index{ru}{even?||||pd|}
  (= (remainder n 2) 0))
\end{Verbatim}
Процесс, вычисляющий {\tt fast-expt},\index{ru}{логарифмический
  рост|||||}\index{ru}{порядок роста|логарифмический||||} растет
логарифмически как
по используемой памяти, так~и по количеству шагов.  Чтобы увидеть это, 
заметим, что вычисление $b^{2n}$~с помощью этого алгоритма
требует всего на одно умножение больше, чем вычисление
$b^n$. Следовательно, размер степени, которую мы можем
вычислять, возрастает примерно вдвое~с каждым следующим умножением,
которое нам разрешено делать.  Таким образом, число умножений,
требуемых для вычисления степени $n$, растет приблизительно
так же быстро, как логарифм $n$ по основанию 2. Процесс
имеет степень роста $\Theta(\log(n))$\footnote{Точнее, количество требуемых умножений равно
логарифму $n$ по основанию 2 минус 1~и плюс количество единиц 
в двоичном представлении $n$.  Это число всегда меньше, чем 
удвоенный логарифм $n$ по основанию 2.  Произвольные
константы $k_1$~и $k_2$~в определении порядка
роста означают, что для логарифмического процесса основание, по
которому берется логарифм, не имеет значения, так что все такие
процессы описываются как $\Theta(\log(n))$.
\sloppy
}.

Если $n$ велико, разница между
порядком роста $\Theta(\log(n))$~и $\Theta(n)$
оказывается очень заметной.  Например, {\tt fast-expt} при
$n = 1000$ требует всего 14 умножений\footnote{Если Вас интересует, зачем это кому-нибудь
может понадобиться возводить числа~в 1000-ю степень, смотрите раздел~\ref{EXAMPLE-TESTING-FOR-PRIMALITY}.
}.
С помощью идеи последовательного возведения~в квадрат можно
построить также итеративный алгоритм, который вычисляет
степени за логарифмическое число шагов (см. упражнение~\ref{EX1.16}), хотя, как это часто бывает с
итеративными алгоритмами, его нельзя записать так же просто, как
рекурсивный алгоритм\footnote{Итеративный алгоритм очень стар. Он встречается в
{\em\index{ru}{Чанда-сутра|||||п} Чанда-сутре}  Ачарьи
Пингалы,\index{ru}{Пингала, Ачарья||\'Ach\'arya
  Pingala||n|п}\index{en}{\'Ach\'arya Pingala||Пингала, Ачарья||n|п} 
написанной до 200 года до н.э.~В Knuth 1981,\index{ru}{Кнут,
  Дональд~Э.||Donald~E. Knuth||n|п}\index{en}{Donald~E. Knuth||Кнут,
  Дональд~Э.||n|п}
раздел 4.6.3, содержится
полное обсуждение~и анализ этого~и других методов возведения в
степень.}.

\begin{exercise}{1.16}\label{EX1.16}%
Напишите процедуру, которая развивается~в виде
итеративного процесса~и реализует возведение в
степень за логарифмическое число шагов, как
{\tt fast-expt}. (Указание: используя наблюдение, что
$(b^{n / 2})^2 = (b^2)^{n / 2}$, храните, помимо
значения степени $n$~и основания $b$,
дополнительную переменную состояния $a$,~и определите
переход между состояниями так, чтобы произведение $ab^n$ от 
шага~к шагу не менялось.  Вначале значение $a$ берется
равным 1,~а ответ получается как значение $a$~в момент
окончания процесса. В общем случае метод определения 
\index{ru}{инвариант итеративного процесса||invariant quantity of an iterative process|||(упр.~1.16)}\index{en}{invariant quantity of an iterative process||инвариант итеративного процесса|||(упр.~1.16)}{\em инварианта} (invariant quantity), 
который не изменяется при
переходе между шагами, является мощным способом размышления о
\index{ru}{итеративный процесс|построение алгоритмов||||(упр.~1.16)}
построении итеративных алгоритмов.)

\sloppy
\end{exercise}

\begin{exercise}{1.17}\label{EX1.17}%
Алгоритмы возведения~в степень из этого раздела
основаны на повторяющемся умножении.  Подобным же образом можно
производить умножение~с помощью повторяющегося сложения.  Следующая
процедура умножения (в которой предполагается, что наш язык способен
только складывать, но не умножать) аналогична процедуре
{\tt expt}:

\begin{Verbatim}[fontsize=\small]
(define (* a b)
  (if (= b 0)
      0
      (+ a (* a (- b 1)))))
\end{Verbatim}
Этот алгоритм затрачивает количество шагов, линейно пропорциональное
{\tt b}.  Предположим теперь, что, наряду со сложением,~у нас
есть операции {\tt double}, которая удваивает целое число, и
{\tt halve}, которая делит (четное) число на 2. Используя их,
напишите процедуру, аналогичную {\tt fast-expt}, которая
затрачивает логарифмическое число шагов.
\end{exercise}

\begin{exercise}{1.18}\label{EX1.18}%
Используя результаты упражнений~\ref{EX1.16} и
\ref{EX1.17}, разработайте процедуру, которая порождает
итеративный процесс для умножения двух чисел~с помощью сложения,
удвоения~и деления пополам,~и затрачивает логарифмическое число
шагов\footnote{%
\index{ru}{умножение методом русского крестьянина||Russian peasant method of
mul\-ti\-pli\-ca\-tion|||п}%
\index{en}{Russian peasant method of multiplication||умножение методом русского
    крестьянина|||п}%
\index{ru}{русского крестьянина метод умножения||Russian peasant method of
    mul\-ti\-pli\-ca\-tion|||п}\index{en}{Russian peasant method of
    multiplication||русского крестьянина метод умножения|||п}Этот
  алгоритм, который иногда называют <<методом
  русского крестьянина>>, очень стар.  Примеры его использования найдены
 в Риндском папирусе, одном из двух самых древних существующих
  математических документов, который был записан (и при этом скопирован~с еще
  более древнего документа) египетским писцом по имени А'х-мосе около
  1700 г. до
  н.э.\index{ru}{А'х-мосе||A'h-mose||n|п}\index{en}{A'h-mose||А'х-мосе||n|п}}.
\end{exercise}

\begin{exercise}{1.19}\label{EX1.19}%
Существует хитрый алгоритм получения чисел Фибоначчи за
логарифмическое число шагов.  Вспомните трансформацию переменных
состояния $a$~и $b$ процесса
{\tt fib-iter} из раздела~\ref{TREE-RECURSION}:
$a \gets a+b$~и $b \gets a$. Назовем эту
трансформацию $T$~и заметим, что $n$-кратное
применение $T$, начиная~с 1~и 0, дает нам пару
$\mathop{\rm Fib}(n+1)$~и $\mathop{\rm Fib}(n)$.
Другими словами, числа Фибоначчи получаются путем применения
$T^n$, $n$-ой степени трансформации $T$,~к паре (1,0).
Теперь рассмотрим $T$ как частный случай $p = 0, q =
1$~в семействе трансформаций $T_{pq}$, где
$T_{pq}$ преобразует пару $(a,b)$ по правилу
$a \gets bq + aq + ap, b \gets bp + aq$. Покажите, что
двукратное применение трансформации $T_{pq}$ равносильно
однократному применению трансформации $T_{p'q'}$ того же
типа,~и вычислите $p'$~и $q'$ через
$p$~и $q$. Это дает нам прямой способ возводить
такие трансформации~в квадрат,~и таким образом, мы можем вычислить 
$T^n$~с помощью последовательного возведения~в квадрат, как 
в процедуре {\tt fast-expt}.  Используя все эти идеи,
завершите следующую процедуру, которая дает результат за
логарифмическое число шагов\footnote{Это упражнение нам предложил Джо Стой% 
\index{ru}{Стой, Джозеф~Э.||Joseph~E. Stoy||n|п}\index{en}{Joseph~E. Stoy||Стой, Джозеф~Э.||n|п}%
на основе примера из Kaldewaij 1990.
\index{ru}{Калдевай, Анне||Anne Kaldewaij||n|п}\index{en}{Anne Kaldewaij||Калдевай, Анне||n|п}
}:

\begin{Verbatim}
(define (fib n)\index{ru}{fib|логарифмический вариант|||p|(упр.~1.19)}
  (fib-iter 1 0 0 1 n))

(define (fib-iter a b p q count)
  (cond ((= count 0) b)
        ((even? count)
         (fib-iter a
                   b
                   \textit{$\langle$??$\rangle$} {\em ; вычислить p'}
                   \textit{$\langle$??$\rangle$} {\em ; вычислить q'}
                   (/ count 2)))
        (else (fib-iter (+ (* b q) (* a q) (* a p))
                        (+ (* b p) (* a q))
                        p
                        q
                        (- count 1)))))
\end{Verbatim}

\end{exercise}

\subsection{Нахождение наибольшего общего делителя}
\label{GREATEST-COMMON-DIVISORS}


По определению, 
\index{ru}{наибольший общий делитель||greatest common divisor|||}\index{en}{greatest common divisor||наибольший общий делитель|||} наибольший общий делитель (НОД) двух целых
чисел $a$~и $b$~--- это наибольшее целое число,
на которое~и $a$, и $b$ делятся без
остатка. Например, НОД 16~и 28 равен 4. В главе~\ref{BUILDING-ABSTRACTIONS-WITH-DATA}, когда мы будем 
исследовать реализацию арифметики на рациональных числах, нам
потребуется вы\-чи\-слять НОДы, чтобы сокращать дроби. (Чтобы сократить
дробь, нужно поделить ее числитель~и знаменатель на их НОД.  Например,
16/28 со\-кра\-ща\-ет\-ся до 4/7.) Один из способов найти НОД двух чисел состоит
в том, чтобы разбить каждое из них на простые множители~и найти среди
них общие, однако существует знаменитый~и значительно более
эффективный алгоритм.
%\looseness=1


Этот алгоритм основан на том, что если
$r$ есть остаток от деления $a$ на
$b$, то общие делители $a$~и $b$ в
точности те же, что~и общие делители $b$ и
$r$. Таким образом, можно воспользоваться уравнением
$$
        \mathop{\mbox{НОД}} (a,b) = \mathop{\mbox{НОД}} (b, r)
$$
чтобы последовательно свести задачу нахождения НОД~к задаче нахождения 
НОД все меньших~и меньших пар целых чисел. Например,
$$
\begin{array}{rcl}
 \mathop{\mbox{НОД}} (206,40) & = & \mathop{\mbox{НОД}} (40, 6) \\
                           & = & \mathop{\mbox{НОД}} (6, 4) \\
                           & = & \mathop{\mbox{НОД}} (4, 2) \\
                           & = & \mathop{\mbox{НОД}} (2, 0) \\
                           & = & 2 \\
\end{array}
$$
сводит $\mathop{\mbox{НОД}} (206, 40)$ к
$\mathop{\mbox{НОД}} (2,0)$, что равняется двум.  Можно показать, что если
начать~с произвольных двух целых чисел~и производить последовательные
редукции,~в конце концов всегда получится пара, где вторым элементом
будет 0. Этот способ нахождения НОД известен как
\index{ru}{Евклида алгоритм||Euclid's Algorithm|||}\index{en}{Euclid's
  Algorithm||Евклида
  алгоритм|||}\index{ru}{алгоритм|Евклида|algorithm|Euclid's||}\index{en}{algorithm|Euclid's|алгоритм|Евклида||}{\em алгоритм Евклида} (Euclid's Algorithm)\footnote{Алгоритм Евклида называется так потому, что он
  встречается~в {\em\index{ru}{Евклид, \emph{Начала}|||||п}
    Началах}  Евклида (книга 7, ок. 300 г. до н.э.). По утверждению 
  Кнута (Knuth 1973),\index{ru}{Кнут,
    Дональд~Э.||Donald~E. Knuth||n|п}\index{en}{Donald~E. Knuth||Кнут,
    Дональд~Э.||n|п}
  его можно
  считать самым старым из известных нетривиальных алгоритмов.
  Древнеегипетский метод умножения (упражнение~\ref{EX1.18}),
  разумеется, древнее, но, как объясняет Кнут, алгоритм Евклида ---
  самый старый алгоритм, представленный~в виде общей процедуры,~а не
  через набор иллюстрирующих примеров.}.

Алгоритм Евклида легко выразить~в виде процедуры:

\begin{Verbatim}[fontsize=\small]
(define (gcd a b)\index{ru}{gcd||||pd|}
  (if (= b 0)
      a
      (gcd b (remainder a b))))
\end{Verbatim}
Она порождает итеративный процесс, число шагов которого растет
пропорционально логарифму чисел-аргументов.

Тот факт, что число шагов, затрачиваемых алгоритмом
Евклида,\index{ru}{Евклида алгоритм|порядок роста||||} растет логарифмически, интересным образом связан~с числами 
Фибоначчи:

\begin{quote}
{\bf Теорема Ламэ:}

\index{ru}{Фибоначчи числа|и алгоритм Евклида для НОД||||}
Если алгоритму Евклида требуется $k$ шагов
для вычисления НОД некоторой пары чисел, то меньший из членов этой
пары больше или равен $k$-тому числу Фибоначчи\footnote{Эту теорему
  доказал~в 1845 году Габриэль Ламэ,\index{ru}{Ламэ, Габриэль||Gabriel
    Lam\'e||n|п}\index{en}{Gabriel Lam\'e||Ламэ, Габриэль||n|п}
французский математик~и инженер, который
больше всего известен своим вкладом~в математическую физику.  Чтобы
доказать теорему, рассмотрим пары $(a_k, b_k)$, где
$a_k \ge b_k$~и алгоритм Евклида завершается за
$k$ шагов.  Доказательство основывается на утверждении, что 
если $(a_{k+1}, b_{k+1}) \to (a_k, b_k) \to (a_{k-1},
b_{k-1})$ --- три последовательные пары~в процессе редукции, то
$b_{k+1} \ge b_k + b_{k-1}$.  Чтобы доказать это
утверждение, вспомним, что шаг редукции определяется применением
трансформации $a_{k-1} = b_k, b_{k-1} =$ остаток от деления 
$a_k$ на $b_k$.  Второе из этих уравнений
означает, что $a_k = qb_k + b_{k-1}$ для некоторого
положительного числа $q$.  Поскольку $q$ должно 
быть не меньше 1, имеем $a_k = qb_k + b_{k-1} \ge b_k +
b_{k-1}$.  Но из предыдущего шага редукции мы имеем
$b_{k+1} = a_k$. Таким образом, $b_{k+1} = a_k \ge b_k 
+ b_{k-1}$.  Промежуточное утверждение доказано.  Теперь можно
доказать теорему индукцией по $k$, то есть числу шагов,
которые требуются алгоритму для завершения.  Утверждение теоремы верно 
при $k = 1$, поскольку при этом требуется всего лишь чтобы
$b$ было не меньше, чем $\mathop{\rm Fib}(1) =
1$. Теперь предположим, что утверждение верно для всех чисел, меньших или 
равных $k$,~и докажем  его для $k + 1$. Пусть
$(a_{k+1}, b_{k+1}) \to (a_k, b_k) \to (a_{k-1}, b_{k-1})$
--- последовательные пары~в процессе редукции.  Согласно гипотезе
индукции, $b_{k-1} \ge \mathop{\rm Fib}(k - 1), b_k \ge
\mathop{\rm Fib} (k)$. Таким образом, применение промежуточного
утверждения совместно~с определением чисел Фибоначчи дает
$b_{k+1} \ge b_k + b_{k-1} \ge \mathop{\rm Fib}(k) + \mathop{\rm
Fib}(k-1) = \mathop{\rm Fib} (k+1)$, что~и доказывает теорему Ламэ.}.
\end{quote}

С помощью этой теоремы можно оценить порядок роста 
алгоритма Евклида.  Пусть $n$ будет меньшим из двух
аргументов процедуры. Если процесс завершается за $k$
шагов, должно выполняться $n \ge \mathop{\rm Fib} (k) \approx
\phi^k / \sqrt{5}$. Следовательно, число шагов
$k$ растет как логарифм $n$ (по основанию
$\phi$). Следовательно, порядок роста равен
$\Theta(\log n)$.

\begin{exercise}{1.20}%\label{EX1.20}%
Процесс, порождаемый процедурой, разумеется, зависит от
того, по каким
правилам\index{ru}{аппликативный порядок вычислений|vs. нормальный порядок||||(упр.~1.20)}\index{ru}{нормальный порядок вычислений|vs. аппликативный порядок||||(упр.~1.20)} работает интерпретатор. В качестве примера 
рассмотрим итеративную процедуру {\tt gcd}, приведенную выше.
Предположим, что мы вычисляем эту процедуру~с помощью нормального
порядка,  описанного~в разделе~\ref{SUBST-MODEL-FOR-PROC-APPL}.
(Правило нормального порядка вычислений для {\tt if} описано в
упражнении~\ref{EX1.5}.) Используя подстановочную модель для 
нормального порядка, проиллюстрируйте процесс, порождаемый при
вычислении {\tt (gcd 206 40)}~и укажите, какие операции
вычисления остатка действительно выполняются. Сколько операций
{\tt remainder} выполняется на самом деле при вычислении
{\tt (gcd 206 40)}~в нормальном порядке?  При вычислении в
аппликативном порядке?
\end{exercise}

\subsection{Пример: проверка на простоту}
\label{EXAMPLE-TESTING-FOR-PRIMALITY}

\index{ru}{простые числа|||||}
\index{ru}{простые числа|проверка на простоту||||} 
В этом разделе описываются два метода проверки числа
$n$ на простоту, один~с порядком роста $\Theta
(\sqrt{n})$,~и другой, <<вероятностный>>, алгоритм~с порядком
роста $\Theta(\log n)$. В упражнениях, приводимых~в конце
раздела, предлагаются программные проекты на основе этих
алгоритмов.

\paragraph{Поиск делителей}

С древних времен математиков завораживали проблемы,
связанные~с простыми числами,~и многие люди занимались поисками
способов выяснить, является ли число простым.  Один из способов
проверки числа на простоту состоит~в том, чтобы найти делители числа.
Следующая программа находит наименьший целый делитель (больший 1)
числа $n$.  Она проделывает это <<в лоб>>, путем проверки
делимости $n$ на все последовательные числа, начиная с~2.

\begin{Verbatim}[fontsize=\small]
(define (smallest-divisor n)\index{ru}{smallest-divisor||||pd|}
  (find-divisor n 2))

(define (find-divisor n test-divisor)\index{ru}{find-divisor||||pd|}
  (cond ((> (square test-divisor) n) n)
        ((divides? test-divisor n) test-divisor)
        (else (find-divisor n (+ test-divisor 1)))))

(define (divides? a b)\index{ru}{divides?||||pd|}
  (= (remainder b a) 0))
\end{Verbatim}

Мы можем проверить, является ли число простым, следующим
образом: $n$ простое тогда~и только тогда, когда
$n$ само является своим наименьшим \mbox{делителем}.

\begin{Verbatim}[fontsize=\small]
(define (prime? n)\index{ru}{prime?||||pd|}
  (= n (smallest-divisor n)))
\end{Verbatim}

Тест на завершение основан на том, что если число
$n$ не простое,~у него должен быть делитель, меньше или
равный $\sqrt{n}$\footnote{Если $d$ --- делитель $n$, то
$n / d$ тоже. Но $d$~и $n /
d$ не могут оба быть больше $\sqrt{n}$.
}.
Это означает, что алгоритм может проверять делители только от 1 до
$\sqrt{n}$.  Следовательно, число шагов, которые требуются,
чтобы определить, что $n$ простое, будет иметь порядок
роста $\Theta(\sqrt{n})$.

\paragraph{Тест Ферма}


\index{ru}{Ферма тест на простоту||Fermat test        for
  primality|||}\index{en}{Fermat test        for primality||Ферма тест
  на простоту|||}\index{ru}{простые числа|тест Ферма||||}Тест на
простоту~с порядком роста $\Theta(\log n)$ основан на утверждении из
теории чисел, известном как Малая
теорема Ферма\footnote{Пьер де Ферма (1601-1665)\index{ru}{Ферма,
    Пьер де||Pierre de Fermat||n|п}\index{en}{Pierre de Fermat||Ферма,
    Пьер де||n|п} 
  считается основателем\index{ru}{чисел теория||number theory|||п}\index{en}{number theory||чисел теория|||п}
  современной теории чисел.  Он доказал множество важных теорем, однако,
  как правило, он объявлял только результаты, не
  публикуя своих доказательств.  Малая теорема Ферма была сформулирована 
 в письме, которое он написал~в 1640-м году.  Первое опубликованное
  доказательство было дано\index{ru}{Эйлер, Леонард|доказательство
    Малой теоремы Ферма|Leonhard Euler|||п}\index{en}{Leonhard
    Euler||Эйлер, Леонард|доказательство Малой теоремы
    Ферма||п}\index{ru}{Ферма Малая теорема|доказательство|Fermat's
    Little Theorem|||п}\index{en}{Fermat's Little Theorem||Ферма Малая
    теорема|доказательство||п}Эйлером~в 1736 г. (более раннее,
  идентичное
  доказательство было найдено~в неопубликованных рукописях
  Лейбница).\index{ru}{Лейбниц, барон Готфрид Вильгельм
    фон|доказательство Малой теоремы Ферма|Baron Gottfried Wilhelm von
    Leibniz||n|п}\index{en}{Baron Gottfried Wilhelm von
    Leibniz||Лейбниц, барон Готфрид Вильгельм фон|доказательство Малой
    теоремы Ферма|n|п}
  Самый знаменитый результат Ферма, известный как Большая теорема
  Ферма, был записан~в 1637 году~в его экземпляре книги
 \index{ru}{Диофант, \emph{Арифметика}; экземпляр Ферма|||||п}  {\em
    Арифметика} (греческого математика третьего века  Диофанта) с
  пометкой <<я нашел подлинно удивительное
  доказательство, но эти поля слишком малы, чтобы вместить его>>.
  Доказательство Большой теоремы Ферма стало одним из самых известных
  вопросов теории чисел.  Полное решение было найдено~в 1995 году
  Эндрю Уайлсом\index{ru}{Уайлс, Эндрю||Andrew
    Wiles||n|п}\index{en}{Andrew Wiles||Уайлс, Эндрю||n|п} 
  из Принстонского университета.}.

\begin{quote}
{\bf Малая теорема Ферма:}

\index{ru}{Ферма Малая теорема|||||}Если $n$ --- простое число, а
$a$ --- произвольное целое число меньше, чем $n$, то 
$a$, возведенное~в $n$-ю степень, равно
$a$ по модулю $n$.
\end{quote}
(Говорят, что два числа \index{ru}{равенство по модулю $n$||congruency modulo $n$|||}\index{en}{congruency modulo $n$||равенство по модулю $n$|||}{\em равны по
модулю $n$} (congruent modulo $n$), если они дают одинаковый остаток при
делении на $n$.  Остаток от деления числа $a$ на 
$n$ называется также 
\index{ru}{остаток по модулю||remainder modulo $n$|||}\index{en}{remainder modulo $n$||остаток по модулю|||}{\em остатком $a$ по модулю $n$} (remainder of $a$ modulo $n$) или
просто {\em $a$ по модулю $n$}.)

Если $n$ не является простым, то, вообще
говоря, большинство чисел \mbox{$a < n$} не будут удовлетворять
этому условию.  Это приводит к следующему алгоритму проверки на
простоту:% 
\index{ru}{генератор случайных  чисел|в тесте на простоту|random-number generator|||}%
\index{en}{random-number generator||генератор случайных  чисел|в тесте на простоту||}%
имея число $n$, случайным образом выбрать число 
\mbox{$a < n$} и вычислить остаток от $a^n$ по
модулю $n$.  Если этот остаток не равен $a$, то
$n$ определенно не является простым.  Если он равен
$a$, то мы имеем хорошие шансы, что $n$
простое. Тогда нужно взять еще одно случайное $a$ и
проверить его тем же способом.  Если~и оно удовлетворяет уравнению, мы 
можем быть еще более уверены, что $n$ простое.  Испытывая
все большее количество $a$, мы можем увеличивать нашу
уверенность~в результате.  Этот алгоритм называется тестом Ферма.
\looseness=-1

Для реализации теста Ферма нам нужна процедура, которая
вычисляет \index{ru}{возведение~в степень|по модулю $n$||||}степень числа по модулю другого числа:

\begin{Verbatim}[fontsize=\small]
(define (expmod base exp m)\index{ru}{expmod||||pd|}
  (cond ((= exp 0) 1)
        ((even? exp)
         (remainder (square (expmod base (/ exp 2) m))
                    m))
        (else
         (remainder (* base (expmod base (- exp 1) m))
                    m))))
\end{Verbatim}
Эта процедура очень похожа на {\tt fast-expt} из 
раздела~\ref{EXPONENTIATION}. Она использует последовательное
возведение~в квадрат, так что число шагов логарифмически растет с
увеличением степени\footnote{Шаги редукции для случаев, когда степень больше 1,
основаны на том, что для любых целых чисел $x$,
$y$~и $m$ мы можем найти остаток от деления
произведения $x$~и $y$ на $m$ путем
отдельного вычисления остатков $x$ по модулю
$m$, $y$ по модулю $m$, перемножения
их,~и взятия остатка по модулю $m$ от результата.
Например,~в случае, когда $e$ четно, мы можем вычислить
остаток $b^{e / 2}$ по модулю $m$, возвести
его~в квадрат~и взять остаток по модулю $m$.  Такой метод
полезен потому, что~с его помощью мы можем производить вычисления, не
используя чисел, намного больших, чем $m$. (Сравните с
упражнением~\ref{EX1.25}.)}.

Тест Ферма производится путем случайного выбора числа
$a$ между 1~и $n - 1$ включительно~и проверки,
равен ли $a$ остаток по модулю $n$ от
$n$-ой степени $a$.  Случайное число
$a$ выбирается~с помощью процедуры \index{ru}{элементарные процедуры|{\tt random} {\em (нс)}||||}\index{ru}{random (элементарная процедура)||||p|}{\tt random},
про которую мы предполагаем, что она встроена~в Scheme~в качестве
элементарной процедуры. {\tt Random} возвращает неотрицательное
число, меньшее, чем ее целый аргумент.  Следовательно, чтобы получить
случайное число между 1~и $n - 1$, мы вызываем
{\tt random}~с аргументом $n - 1$~и добавляем к
результату~1:

\begin{Verbatim}[fontsize=\small]
(define (fermat-test n)\index{ru}{fermat-test||||pd|}
  (define (try-it a)
    (= (expmod a n n) a))
  (try-it (+ 1 (random (- n 1)))))
\end{Verbatim}

Следующая процедура прогоняет тест заданное число раз,
как указано ее параметром.  Ее значение истинно, если тест всегда
проходит,~и ложно~в противном случае.

\begin{Verbatim}[fontsize=\small]
(define (fast-prime? n times)\index{ru}{fast-prime||||pd|}
  (cond ((= times 0) true)
        ((fermat-test n) (fast-prime? n (- times 1)))
        (else false)))
\end{Verbatim}

\paragraph{Вероятностные методы}


\index{ru}{алгоритм|вероятностный||||}\index{ru}{вероятностный
  алгоритм||probabilistic algorithm|||}\index{en}{probabilistic
  algorithm||вероятностный алгоритм|||}Тест Ферма отличается по своему
характеру от большинства
известных алгоритмов, где вычисляется результат, истинность
которого гарантирована.  Здесь полученный результат верен лишь с
какой-то вероятностью.  Более точно, если $n$ не проходит
тест Ферма, мы можем точно сказать, что оно не простое.  Но то, что
$n$ проходит тест, хотя~и является очень сильным
показателем, все же не гарантирует, что $n$ простое.  Нам
хотелось бы сказать, что для любого числа $n$, если мы
проведем тест достаточное количество раз~и $n$ каждый раз
его пройдет, то вероятность ошибки~в нашем тесте на простоту может
быть сделана настолько малой, насколько мы того пожелаем.

К сожалению, это утверждение неверно.  Существуют числа,
которые <<обманывают>> тест Ферма: числа, которые не являются
простыми~и тем не менее обладают свойством, что для всех целых чисел
$a < n$ $a^n$ равно $a$ по модулю
$n$.  Такие числа очень редки, так что на практике тест
Ферма вполне надежен\footnote{\label{F47}Числа, <<обманывающие>> тест
  Ферма, называются 
 \index{ru}{Кармайкла числа||Carmichael
    numbers|||п}\index{en}{Carmichael numbers||Кармайкла
    числа|||п}{\em числами Кармайкла} (Carmichael numbers),~и про них
  почти 
  ничего неизвестно, кроме того, что они очень редки. Существует 255
  чисел Кармайкла, меньших 100 000 000.  Несколько первых ---
  561, 1105, 1729, 2465, 2821~и 6601.  При проверке на простоту больших
  чисел, выбранных случайным образом, шанс наткнуться на число,
  <<обманывающее>> тест Ферма, меньше, чем шанс,
  что\index{ru}{космическое излучение||cosmic
    radiation|||п}\index{en}{cosmic radiation||космическое
    излучение|||п} 
  космическое излучение заставит компьютер сделать ошибку при вычислении
  <<правильного>> алгоритма.  То, что по первой из этих причин алгоритм
  считается неадекватным,~а по второй нет, показывает разницу между
 \index{ru}{техника vs. математика||engineering
    vs. mathematics|||п}\index{en}{engineering
    vs. mathematics||техника
    vs. математика|||п}\index{ru}{математика|vs. техника||||п}математикой~и техникой.}.
Существуют варианты теста Ферма, которые обмануть невозможно. В таких 
тестах, подобно методу Ферма, проверка числа $n$ на
простоту ведется путем выбора случайного числа $a < n$ и
проверки некоторого условия, зависящего от $n$ и
$a$. (Пример такого теста см.~в упражнении~\ref{EX1.28}.) С другой стороны,~в отличие от теста 
Ферма, можно доказать, что для любого $n$ условие не
выполняется для большинства чисел $a < n$, если
$n$ не простое.  Таким образом, если $n$
проходит тест для какого-то случайного $a$, шансы, что
$n$ простое, уже больше половины.  Если $n$
проходит тест для двух случайных $a$, шансы, что
$n$ простое, больше, чем 3 из 4.  Проводя тест~с большим
количеством случайных чисел, мы можем сделать вероятность ошибки
сколь угодно малой.

Существование тестов, для которых можно доказать, что
вероятность ошибки можно сделать сколь угодно малой, вызвало большой
интерес~к алгоритмам такого типа.  Их стали называть \index{ru}{вероятностный алгоритм||probabilistic alorithm|||}\index{en}{probabilistic alorithm||вероятностный алгоритм|||}{\em вероятностными алгоритмами} (probabilistic alorithms).  В
этой области ведутся активные исследования,~и вероятностные алгоритмы
удалось~с успехом применить во многих областях\footnote{Одно из наиболее впечатляющих применений
вероятностные алгоритмы получили~в области криптографии.  Хотя в
настоящее время вычислительных ресурсов недостаточно, чтобы разложить 
на множители произвольное число из 200 цифр,~с помощью теста Ферма
проверить, является ли оно простым, можно за несколько секунд.  Этот
факт служит основой предложенного~в Rivest, Shamir, and Adleman
1977%
\index{ru}{Ривест,  Рональд~Л.||Ronald~L. Rivest||n|п}%
\index{en}{Ronald~L. Rivest||Ривест, Рональд~Л.||n|п}%
\index{ru}{Шамир, Ади||Adi Shamir||n|п}%
\index{en}{Adi Shamir||Шамир, Ади||n|п}%
\index{ru}{Адельман, Леонард||Leonard Adleman||n|п}%
\index{en}{Leonard Adleman||Адельман, Леонард||n|п}
метода построения шифров, которые <<невозможно>> взломать. Полученный
\index{ru}{алгоритм|RSA|algorithm|RSA||п}%
\index{en}{algorithm|RSA|алгоритм|RSA||п}%
\index{ru}{RSA алгоритм||RSA  algorithm|||п}%
\index{en}{RSA algorithm||RSA алгоритм|||п}%
{\em  алгоритм RSA} (RSA algorithm) стал широко
используемым методом повышения секретности электронных средств связи.
В результате этого~и других связанных событий исследование
\index{ru}{простые числа|и криптография||||п} простых чисел,
которое раньше считалось образцом <<чистой>> математики, изучаемым
исключительно ради самого себя, теперь получило важные практические
приложения~в таких областях, как 
\index{ru}{криптография||cryptography|||п}\index{en}{cryptography||криптография|||п}криптография,
электронная передача 
денежных сумм~и хранение информации.}.

\begin{exercise}{1.21}\label{EX1.21}%
С помощью процедуры {\tt smallest-divisor}
найдите наименьший делитель следующих чисел: 199, 1999, 19999.
\end{exercise}
\begin{exercise}{1.22}\label{EX1.22}%
Б\'ольшая часть реализаций Лиспа содержат элементарную
процедуру 
\index{ru}{элементарные процедуры|{\tt runtime} {\em (нс)}||||(упр.~1.22)}  
\index{ru}{runtime (элементарная процедура)||||pd|(упр.~1.22)}  
{\tt runtime}, которая возвращает целое число,
показывающее, как долго работала система (например, в
миллисекундах). Следующая процедура {\tt timed-prime-test},
будучи вызвана~с целым числом $n$, печатает $n$
и проверяет, простое ли оно. Если $n$ простое, процедура
печатает три звездочки~и количество времени, затраченное на проверку.
\index{ru}{display (элементарная процедура)||||p|(упр.~1.22)}
\index{ru}{newline (элементарная процедура)||||p|(упр.~1.22)}

\begin{Verbatim}[fontsize=\small]
(define (timed-prime-test n)\index{ru}{timed-prime-test||||pd|(упр.~1.22)}
  (newline)
  (display n)
  (start-prime-test n (runtime)))

(define (start-prime-test n start-time)
  (if (prime? n)
      (report-prime (- (runtime) start-time))))

(define (report-prime elapsed-time)
  (display " *** ")
  (display elapsed-time))
\end{Verbatim}
Используя эту процедуру, напишите процедуру
{\tt search-for-primes}, которая проверяет на простоту
все нечетные числа~в заданном диапазоне. С помощью этой процедуры
найдите наименьшие три простых числа после 1000; после 10~000; после
100~000; после 1~000~000.  Посмотрите, сколько времени затрачивается на
каждое простое число.  Поскольку алгоритм проверки имеет порядок роста 
$\Theta (\sqrt{n})$, Вам следовало бы ожидать, что проверка 
на простоту чисел, близких~к 10~000, занимает~в $\sqrt{10}$
раз больше времени, чем для чисел, близких~к 1000.  Подтверждают ли
это Ваши замеры времени? Хорошо ли поддерживают предсказание
$\sqrt{n}$ данные для 100~000 и 1~000~000?  Совместим ли
Ваш результат~с предположением, что программы на Вашей машине
затрачивают на выполнение задач время, пропорциональное числу шагов?
\end{exercise}

\begin{exercise}{1.23}\label{EX1.23}%
Процедура \index{ru}{smallest-divisor|более эффективный вариант|||p|(упр.~1.23)}{\tt smallest-divisor} 
в начале этого
раздела проводит множество лишних проверок: после того, как она
проверяет, делится ли число на 2, нет никакого смысла проверять
делимость на другие четные числа.  Таким образом, вместо
последовательности 2, 3, 4, 5, 6 \ldots, используемой для
{\tt test-divisor}, было бы лучше использовать 2, 3, 5, 7, 9
\ldots.  Чтобы реализовать такое улучшение, напишите процедуру {\tt next},
которая имеет результатом 3, если получает 2 как аргумент,~а иначе
возвращает свой аргумент плюс 2.  Используйте {\tt (next
test-divisor)} вместо {\tt (+ test-divisor 1)} в
{\tt smallest-divisor}.  Используя процедуру
{\tt timed-prime-test}~с модифицированной версией
{\tt smallest-divisor}, запустите тест для каждого из 12
простых чисел, найденных~в упражнении~\ref{EX1.22}.
Поскольку эта модификация снижает количество шагов проверки вдвое, Вы
должны ожидать двукратного ускорения проверки.  Подтверждаются ли эти
ожидания?  Если нет, то каково наблюдаемое соотношение скоростей двух
алгоритмов,~и как Вы объясните то, что оно отличается от 2?
\end{exercise}
\begin{exercise}{1.24}\label{EX1.24}%
Модифицируйте процедуру {\tt timed-prime-test} из
упражнения~\ref{EX1.22} так, чтобы она использовала
{\tt fast-prime?} (метод Ферма)~и проверьте каждое из 12
простых чисел, найденных~в этом упражнении.  Исходя из того, что у
теста Ферма порядок роста $\Theta (\log n)$, то какого
соотношения времени Вы бы ожидали между проверкой на простоту
поблизости от 1 000 000~и поблизости от 1000?  Подтверждают ли это
Ваши данные?  Можете ли Вы объяснить наблюдаемое несоответствие, если
оно есть?
%MLR%	Написание чисел: оставлять ли пробел?
\end{exercise}
\begin{exercise}{1.25}\label{EX1.25}%
Лиза П. Хакер жалуется, что при написании
{\tt expmod} мы делаем много лишней работы. В конце концов,
говорит она, раз мы уже знаем, как вычислять степени, можно просто
написать

\begin{Verbatim}
(define (expmod base exp m)\index{ru}{expmod||||pd|(упр.~1.25)}
  (remainder (fast-expt base exp) m))
\end{Verbatim}
Права ли она?  Стала бы эта процедура столь же хорошо работать при
проверке простых чисел?  Объясните.
\end{exercise}
\begin{exercise}{1.26}\label{EX1.26}%
У Хьюго Дума большие трудности~в упражнении~\ref{EX1.24}. Процедура {\tt fast-prime?} у
него работает медленнее, чем {\tt prime?}. Хьюго просит помощи у
своей знакомой Евы Лу Атор.  Вместе изучая код Хьюго, они обнаруживают,
что тот переписал процедуру {\tt expmod}~с явным
использованием умножения вместо того, чтобы вызывать
{\tt square}:

\begin{Verbatim}
(define (expmod base exp m)\index{ru}{expmod||||pd|(упр.~1.26)}
  (cond ((= exp 0) 1)
        ((even? exp)
         (remainder (* (expmod base (/ exp 2) m)
                       (expmod base (/ exp 2) m))
                    m))
        (else
         (remainder (* base (expmod base (- exp 1) m))
                    m))))
\end{Verbatim}
Хьюго говорит: <<Я не вижу здесь никакой разницы>>. <<Зато я вижу, --- 
отвечает Ева. ---~Переписав процедуру таким образом, ты превратил
процесс порядка $\Theta (\log n)$~в процесс порядка
$\Theta (n)$>>.  Объясните.
\end{exercise}
\begin{exercise}{1.27}\label{EX1.27}%
Покажите, что\index{ru}{Кармайкла числа|||||(упр.~1.27)} числа Кармайкла, перечисленные~в сноске
\ref{F47}, действительно <<обманывают>> тест Ферма:
напишите процедуру, которая берет целое число $n$ и
проверяет, правда ли $a^n$ равняется $a$ по
модулю $n$ для всех $a < n$,~и проверьте эту 
процедуру на этих числах Кармайкла.
\end{exercise}
\begin{exercise}{1.28}\label{EX1.28}%
\index{ru}{Ферма тест на простоту|вариант||||(упр.~1.28)}%
Один из вариантов теста Ферма, который невозможно 
обмануть, называется \index{ru}{простые числа|тест Миллера-Рабина||||(упр.~1.28)}\index{ru}{Миллера-Рабина тест||Miller-Rabin test|||(упр.~1.28)}\index{en}{Miller-Rabin test||Миллера-Рабина тест|||(упр.~1.28)}{\em тест
Мил\-ле\-ра--Ра\-би\-на} (Miller-Rabin test) (Miller 1976;
\index{ru}{Миллер, Гэри~Л.||Gary~L. Miller||n|(упр.~1.28)}\index{en}{Gary~L. Miller||Миллер, Гэри~Л.||n|(упр.~1.28)}
Rabin 1980).
\index{ru}{Рабин, Майкл~О.||Michael~O. Rabin||n|(упр.~1.28)}\index{en}{Michael~O. Rabin||Рабин, Майкл~О.||n|(упр.~1.28)}
Он основан на\index{ru}{Ферма Малая теорема|альтернативная формулировка||||(упр.~1.28)}альтернативной
формулировке Малой теоремы Ферма, которая состоит~в том, что если
$n$ --- простое число,~а $a$ --- произвольное
положительное целое число, меньшее $n$, то $a$~в 
$n - 1$-ой степени равняется 1 по модулю $n$.
Проверяя простоту числа $n$ методом Миллера--Рабина, мы
берем случайное число $a < n$~и возводим его~в $(n 
-1)$-ю степень по модулю $n$~с помощью процедуры
{\tt expmod}. Однако когда~в процедуре {\tt expmod} мы
проводим возведение~в квадрат, мы проверяем, не нашли ли мы
<<нетривиальный квадратный корень из 1 по модулю $n$>>, то
есть число, не равное 1 или $n - 1$, квадрат которого по
модулю $n$ равен 1.  Можно доказать, что если такой
нетривиальный квадратный корень из 1 существует, то $n$ не
простое число.  Можно, кроме того, доказать, что если
$n$~--- нечетное число, не являющееся простым, то по
крайней мере для 
половины чисел $a < n$ вычисление $a^{n-1}$
с помощью такой процедуры обнаружит нетривиальный квадратный корень из
1 по модулю $n$ (вот почему тест Миллера--Рабина невозможно
обмануть).  Модифицируйте процедуру {\tt expmod} так, чтобы она 
сигнализировала обнаружение нетривиального квадратного корня из 1, и
используйте ее для реализации теста Миллера--Рабина~с помощью
процедуры, аналогичной {\tt fermat-test}.  Проверьте свою
процедуру на нескольких известных Вам простых~и составных
числах.  Подсказка: удобный способ заставить {\tt expmod}
подавать особый сигнал~--- заставить ее возвращать 0.
\end{exercise}

\section{Формулирование абстракций~с помощью про\-це\-дур
высших порядков
\sloppy} %\- подавляет перенос
\label{FORMULATING-ABSTRACTIONS-WITH-HIGHER-ORDER-PROCEDURES}

Мы видели, что процедуры,~в сущности, являются абстракциями, которые
описывают составные операции над числами безотносительно~к конкретным
числам. Например, когда мы определяем

\begin{Verbatim}[fontsize=\small]
(define (cube x) (* x x x))\index{ru}{cube||||pd|}
\end{Verbatim}
мы говорим не~о кубе какого-то конкретного числа,~а~о способе получить 
куб любого числа. Разумеется, мы могли бы обойтись без определения
этой процедуры, каждый раз писать выражения вроде

\begin{Verbatim}[fontsize=\small]
(* 3 3 3)
(* x x x)
(* y y y)
\end{Verbatim}
и никогда явно не упоминать понятие куба.  Это поставило бы нас перед
серьезным затруднением~и заставило бы работать только~в терминах тех
операций, которые оказались примитивами языка (в данном случае,~в терминах
умножения),~а не~в терминах операций более высокого уровня.  Наши
программы были бы способны вычислять кубы, однако~в нашем языке не
было бы возможности выразить идею возведения~в куб.  Одна из тех
вещей, которых мы должны требовать от мощного языка программирования~--- это возможность строить абстракции путем присвоения имен общим
схемам,~а затем прямо работать~с этими абстракциями.  Процедуры дают
нам такую возможность.  Вот почему все языки программирования, кроме
самых примитивных, обладают механизмами определения процедур.

Но даже при обработке численных данных наши возможности
создавать абстракции окажутся сильно ограниченными, если мы сможем
определять только процедуры, параметры которых должны быть
числами. Часто одна~и та же схема программы используется~с различными
процедурами.  Для того чтобы выразить эти схемы как понятия, нам
нужно строить процедуры, которые принимают другие процедуры как
аргументы либо возвращают их как значения.  Процедура, манипулирующая
другими процедурами, называется \index{ru}{процедура высшего порядка||higher-order procedure|||}\index{en}{higher-order procedure||процедура высшего порядка|||}{\em процедурой высшего порядка} (higher-order procedure). В этом разделе
показывается, как процедуры высших порядков могут служить~в качестве
мощного механизма абстракции, резко повышая выразительную силу нашего
языка.

\subsection{Процедуры~в качестве аргументов}
\label{PROCEDURES-AS-ARGUMENTS}


\index{ru}{процедура|в качестве аргумента||||}\index{ru}{процедура
  высшего порядка|процедура~в качестве аргумента||||}Рассмотрим
следующие три процедуры.  Первая из них 
вычисляет сумму целых чисел от {\tt a} до {\tt b}:

\begin{Verbatim}[fontsize=\small]
(define (sum-integers a b)\index{ru}{sum-integers||||pd|}
  (if (> a b)
      0
      (+ a (sum-integers (+ a 1) b))))
\end{Verbatim}
Вторая вычисляет сумму кубов целых чисел~в заданном диапазоне:

\begin{Verbatim}[fontsize=\small]
(define (sum-cubes a b)\index{ru}{sum-cubes||||pd|}
  (if (> a b)
      0
      (+ (cube a) (sum-cubes (+ a 1) b))))
\end{Verbatim}
Третья вычисляет сумму последовательности термов~в ряде
$$
\dfrac{1}{1 \cdot 3} + \dfrac{1}{5 \cdot 7} + \dfrac{1}{9 \cdot 11} + \ldots
$$
который (очень медленно) сходится~к $\pi / 8$\footnote{\index{ru}{пи ($\pi$)|ряд Лейбница||||п}
Этим рядом, который обычно записывают~в эквивалентной форме
$\dfrac{\pi}{4} = 1 - \dfrac{1}{3} + \dfrac{1}{5} - \dfrac{1}{7} +
\ldots$, мы обязаны  Лейбницу.\index{ru}{Лейбниц, барон Готфрид
  Вильгельм фон|ряд для вычисления $\pi$|Baron Gottfried Wilhelm von
  Leibniz||n|п}\index{en}{Baron Gottfried Wilhelm von
  Leibniz||Лейбниц, барон Готфрид Вильгельм фон|ряд для вычисления
  $\pi$|n|п}
В разделе~\ref{EXPLOITING-THE-STREAM-PARADIGM} мы увидим,
как использовать его как основу для некоторых изощренных
вычислительных трюков.}.

\begin{Verbatim}[fontsize=\small]
(define (pi-sum a b)\index{ru}{pi-sum||||pd|}
  (if (> a b)
      0
      (+ (/ 1.0 (* a (+ a 2))) (pi-sum (+ a 4) b))))
\end{Verbatim}
Ясно, что за этими процедурами стоит одна общая схема.  Большей частью 
они идентичны~и различаются только именем процедуры, функцией, которая 
вычисляет терм, подлежащий добавлению,~и функцией, вычисляющей
следующее значение {\tt a}.  Все эти процедуры можно породить,
заполнив дырки~в одном шаблоне:
\index{ru}{абстракция|выделение общей схемы||||}

\begin{Verbatim}[fontsize=\small]
(define (\textit{$\langle$имя$\rangle$} a b)
  (if (> a b)
      0
      (+ (\textit{$\langle$терм$\rangle$} a)
         (\textit{$\langle$имя$\rangle$} (\textit{$\langle$следующий$\rangle$} a) b))))
\end{Verbatim}

Присутствие такого общего шаблона является веским доводом~в пользу того, что здесь
скрыта полезная абстракция, которую только надо вытащить на
поверхность.  Действительно, математики давно выделили абстракцию 
\index{ru}{суммирование последовательности||summation of a series|||}\index{en}{summation of a series||суммирование последовательности|||}{\em суммирования
последовательности} (summation of a series)~и изобрели <<сигма-запись>>, например
\index{ru}{сигма-запись ($\sum$)|||||}
$$
\sum_{n=a}^b f(n) = f(a) + \ldots + f(b)
$$
чтобы выразить это понятие.  Сила сигма-записи состоит~в том, что
она позволяет математикам работать~с самим понятием суммы,~а не просто 
с конкретными суммами --- например, формулировать общие утверждения о
суммах, независимые от конкретных суммируемых
последовательностей.

Подобным образом, мы как проектировщики программ хотели бы, 
чтобы наш язык был достаточно мощным~и позволял написать
процедуру, которая выражала бы само понятие суммы,~а не только процедуры, 
вычисляющие конкретные суммы. В нашем процедурном языке мы можем без
труда это сделать, взяв приведенный выше шаблон~и преобразовав
<<дырки>>~в формальные параметры:

\begin{Verbatim}[fontsize=\small]
(define (sum term a next b)\index{ru}{sum||||pd|}
  (if (> a b)
      0
      (+ (term a)
         (sum term (next a) next b))))
\end{Verbatim}
Заметьте, что {\tt sum} принимает~в качестве аргументов как
нижнюю~и верхнюю границы {\tt a}~и {\tt b}, так и
процедуры {\tt term}~и {\tt next}. {\tt Sum}
можно использовать так, как мы использовали бы любую другую
процедуру. Например,~с ее помощью (вместе~с процедурой
{\tt inc}, которая увеличивает свой аргумент на 1), мы можем
определить {\tt sum-cubes}:

\begin{Verbatim}[fontsize=\small]
(define (inc n) (+ n 1))\index{ru}{inc||||pd|}

(define (sum-cubes a b)\index{ru}{sum-cubes|через процедуры высших порядков|||pd|}
  (sum cube a inc b))
\end{Verbatim}
Воспользовавшись этим определением, мы можем вычислить сумму кубов чисел от 1
до 10:

\begin{Verbatim}[fontsize=\small]
(sum-cubes 1 10)
\textit{3025}
\end{Verbatim}
С помощью процедуры идентичности (которая просто возвращает свой
аргумент) для вычисления терма, мы можем определить
{\tt sum-integers} через {\tt sum}:

\begin{Verbatim}[fontsize=\small]
(define (identity x) x)\index{ru}{identity||||pd|}

(define (sum-integers a b)\index{ru}{sum-integers|через процедуры высших порядков|||pd|}
  (sum identity a inc b))
\end{Verbatim}
Теперь можно сложить целые числа от 1 до 10:

\begin{Verbatim}[fontsize=\small]
(sum-integers 1 10)
\textit{55}
\end{Verbatim}
Таким же образом определяется {\tt pi-sum}\footnote{Обратите внимание, что мы использовали блочную структуру
(раздел~\ref{PROCEDURES-AS-BLACK-BOX-ABSTRACTIONS}),
чтобы спрятать определения {\tt pi-next}~и {\tt pi-term} 
внутри {\tt pi-sum}, поскольку вряд ли эти процедуры
понадобятся зачем-либо еще. В разделе~\ref{CONSTRUCTING-PROCEDURES-USING-LAMBDA} мы совсем от них избавимся.}:

\begin{Verbatim}[fontsize=\small]
(define (pi-sum a b)\index{ru}{pi-sum|через процедуры высших порядков|||pd|}
  (define (pi-term x)
    (/ 1.0 (* x (+ x 2))))
  (define (pi-next x)
    (+ x 4))
  (sum pi-term a pi-next b))
\end{Verbatim}
С помощью этих процедур мы можем вычислить приближение к
$\pi$:

\begin{Verbatim}[fontsize=\small]
(* 8 (pi-sum 1 1000))
\textit{3.139592655589783}
\end{Verbatim}

Теперь, когда~у нас есть {\tt sum}, ее можно
использовать~в качестве строительного блока при формулировании
других понятий.  Например,  
\index{ru}{определенный интеграл||definite
  integral|||}\index{en}{definite     integral||определенный
  интеграл|||}определенный интеграл функции 
$f$ между пределами $a$~и $b$ можно
численно оценить~с помощью формулы
$$
\int_a^b f = \left\lbrack
   f\left(a+\dfrac{dx}{2}\right) 
   + f\left(a + dx + \dfrac{dx}{2}\right)
   + f\left(a + 2dx + \dfrac{dx}{2}\right)
   + \ldots
  \right\rbrack dx
$$
для малых значений $dx$.  Мы можем прямо выразить это~в виде 
процедуры:

\begin{Verbatim}[fontsize=\small]
(define (integral f a b dx)\index{ru}{integral||||pd|}
  (define (add-dx x) (+ x dx))
  (* (sum f (+ a (/ dx 2)) add-dx b)
     dx))

(integral cube 0 1 0.01)
\textit{.24998750000000042}

(integral cube 0 1 0.001)
\textit{.249999875000001}
\end{Verbatim}
(Точное значение интеграла {\tt cube} от 0 до 1 равно
1/4.)
\begin{exercise}{1.29}\label{EX1.29}%
\index{ru}{Симпсона правило для численного интегрирования||Simpson's Rule for nu\-me\-ri\-cal integration|||(упр.~1.29)}%
\index{en}{Simpson's Rule for numerical integration||Симпсона правило для численного интегрирования|||(упр.~1.29)}%
Правило Симпсона --- более точный метод численного
интегрирования, чем представленный выше. С помощью правила Симпсона
интеграл функции $f$ между $a$~и $b$
приближенно вычисляется~в виде
$$
\dfrac{h}{3}\lbrack y_0 + 4y_1 + 2y_2 + 4y_3 + 2y_4 + \ldots + 2y_{n-2}
                + 4y_{n-1} + y_n\rbrack
$$
где $h = (b - a) / n$, для какого-то четного целого
числа $n$,~а $y_k = f(a + kh)$. (Увеличение
$n$ повышает точность приближенного вычисления.)
Определите процедуру, которая принимает~в качестве аргументов
$f$, $a$, $b$~и $n$, и
возвращает значение интеграла, вычисленное по
правилу Симпсона. С помощью этой процедуры проинтегрируйте
{\tt cube} между 0~и 1 (с $n = 100$~и $n =
1000$)~и сравните результаты~с процедурой {\tt integral}, 
приведенной выше.
\end{exercise}
\begin{exercise}{1.30}\label{EX1.30}%
Процедура \index{ru}{sum|итеративный вариант|||p|(упр.~1.30)}{\tt sum} порождает линейную рекурсию.
Ее можно переписать так, чтобы суммирование выполнялось итеративно.
Покажите, как сделать это, заполнив пропущенные выражения~в следующем
определении: 

\begin{Verbatim}
(define (sum term a next b)
  (define (iter a result)
     (if \textit{$\langle$??$\rangle$}
         \textit{$\langle$??$\rangle$}
         (iter \textit{$\langle$??$\rangle$} \textit{$\langle$??$\rangle$})))
  (iter \textit{$\langle$??$\rangle$} \textit{$\langle$??$\rangle$}))
\end{Verbatim}

\end{exercise}
\begin{exercise}[]{1.31}\label{EX1.31}%
%\samepage
\begin{plainenum}
\item
Процедура {\tt sum} --- всего лишь
простейшая из обширного множества подобных абстракций, которые можно
выразить через процедуры высших порядков.\footnote{Смысл упражнений~\ref{EX1.31}--\ref{EX1.33} состоит~в том, чтобы
продемонстрировать выразительную мощь, получаемую, когда~с помощью подходящей абстракции
обобщается множество операций, казалось бы, не связанных между собой.  Однако, хотя накопление и
фильтрация --- изящные приемы, при их использовании руки~у нас пока что 
несколько связаны, поскольку пока что~у нас нет структур данных,
которые дают подходящие~к этим абстракциям средства комбинирования. В 
разделе~\ref{SEQUENCES-AS-CONVENTIONAL-INTERFACES} мы
вернемся~к этим приемам~и покажем, как использовать 
\index{ru}{последовательности||sequences|||п}\index{en}{sequences||последовательности|||п}{\em последовательности} (sequences)~в качестве
интерфейсов для комбинирования  фильтров~и накопителей, так что
получаются еще более мощные абстракции.  Мы увидим, как эти методы
сами по себе становятся мощным~и изящным подходом~к проектированию
программ.}.
Напишите аналогичную процедуру под названием \index{ru}{product||||p|(упр.~1.31)}{\tt product},
которая вычисляет произведение значений функции~в точках на указанном
интервале.  Покажите, как~с помощью этой процедуры определить
{\tt factorial}.\index{ru}{factorial|через процедуры высших порядков|||p|(упр.~1.31)}
Кроме того, при помощи {\tt product}
вычислите приближенное значение $\pi$ по формуле\footnote{Эту формулу открыл английский математик семнадцатого
века Джон Уоллис.\index{ru}{Уоллис, Джон||John
  Wallis||n|п}\index{en}{John Wallis||Уоллис, Джон||n|п}}\index{ru}{пи
($\pi$)|формула Уоллиса||||(упр.~1.31)} 
$$
\dfrac{\pi}{4} = \dfrac{2 \cdot 4 \cdot 4 \cdot 6 \cdot 6 \cdot 8 \cdots}
                     {3 \cdot 3 \cdot 5 \cdot 5 \cdot 7 \cdot 7 \cdots}
$$
\item
Если Ваша процедура {\tt product} порождает
рекурсивный процесс, перепишите ее так, чтобы она порождала
итеративный.  Если она порождает итеративный процесс,
перепишите ее так, чтобы она порождала рекурсивный.
\end{plainenum}
\end{exercise}
\begin{exercise}[]{1.32}\label{EX1.32}%
\begin{plainenum}
\item
Покажите, что \index{ru}{sum|как накопление|||p|(упр.~1.32)}{\tt sum}~и \index{ru}{product|как накопление|||p|(упр.~1.32)}
{\tt product} (упражнение~\ref{EX1.31}) являются
частными случаями еще более общего понятия, называемого 
\index{ru}{накопление||accumulation|||(упр.~1.32)}\index{en}{accumulation||накопление|||(упр.~1.32)}{\em накопление} (accumulation), которое комбинирует множество 
термов~с помощью некоторой общей функции накопления

\begin{Verbatim}[fontsize=\small]
(accumulate combiner null-value term a next b)
\end{Verbatim}
{\tt Accumulate} принимает~в качестве аргументов те же описания 
термов~и диапазона, что~и {\tt sum}~с {\tt product}, а
еще процедуру {\tt combiner} (двух аргументов), которая
указывает, как нужно присоединить текущий терм~к результату накопления
предыдущих,~и {\tt null-value}, базовое
значение, которое нужно использовать, когда термы закончатся.
Напишите {\tt accumulate}~и покажите, как~и {\tt sum},~и 
{\tt product} можно определить~в виде простых вызовов
{\tt accumulate}.\index{ru}{accumulate||||p|(упр.~1.32)}

\item
Если Ваша процедура {\tt accumulate}
порождает рекурсивный процесс, перепишите ее так, чтобы она порождала
итеративный.  Если она порождает итеративный процесс, перепишите ее
так, чтобы она порождала рекурсивный.
\end{plainenum}
\end{exercise}
\begin{exercise}{1.33}\label{EX1.33}%
Можно получить еще более общую версию
{\tt accumulate} (упражнение~\ref{EX1.32}), если
ввести понятие \index{ru}{фильтр||filter|||(упр.~1.33)}%
\index{en}{filter||фильтр|||(упр.~1.33)}{\em фильтра} (filter) на комбинируемые
термы.  То есть комбинировать только те термы, порожденные из значений 
диапазона, которые удовлетворяют указанному условию.  Получающаяся
абстракция {\tt filtered-accumulate}
\index{ru}{filtered-accumulate||||p|(упр.~1.33)}
получает те же аргументы,
что~и {\tt accumulate}, плюс дополнительный одноаргументный
предикат, который определяет фильтр.  Запишите
{\tt filtered-accumulate}~в виде процедуры.  Покажите, как с
помощью {\tt filtered-accumulate} выразить следующее:

\begin{plainenum}
\item
сумму квадратов простых чисел~в интервале от
{\tt a} до {\tt b} (в предположении, что процедура
{\tt prime?} уже написана);

\item
произведение всех положительных целых чисел меньше
$n$, которые\index{ru}{числа|простые по отношению~к другому числу||||(упр.~1.33)}
просты по отношению~к $n$ (то есть
всех таких положительных целых чисел $i < n$, что
$\mathop{\mbox{НОД}} (i,n) = 1$).
\end{plainenum}
\end{exercise}

\subsection{Построение процедур~с помощью {\tt lambda}}
\label{CONSTRUCTING-PROCEDURES-USING-LAMBDA}


Когда~в разделе~\ref{PROCEDURES-AS-ARGUMENTS}
мы использовали {\tt sum}, очень неудобно было
определять тривиальные процедуры вроде {\tt pi-term} 
и {\tt pi-next} только ради того, чтобы передать их как
аргументы~в процедуры высшего порядка.  Было бы проще вместо того, чтобы
вводить имена {\tt pi-next}~и {\tt pi-term}, прямо
определить <<процедуру, которая 
возвращает свой аргумент плюс 4>>~и <<процедуру, которая вычисляет
число, обратное произведению аргумента~и аргумента плюс 2>>.  Это
можно сделать, введя особую форму {\tt lambda},
\index{ru}{lambda (особая форма)||||pd|}
которая создает процедуры. С использованием {\tt lambda} мы можем
записать требуемое~в таком виде:

\begin{Verbatim}[fontsize=\small]
(lambda (x) (+ x 4))
\end{Verbatim}
и

\begin{Verbatim}[fontsize=\small]
(lambda (x) (/ 1.0 (* x (+ x 2))))
\end{Verbatim}
Тогда нашу процедуру {\tt pi-sum} можно выразить безо всяких
вспомогательных процедур:

\begin{Verbatim}[fontsize=\small]
(define (pi-sum a b)\index{ru}{pi-sum|через \texttt{lambda}|||pd|}
  (sum (lambda (x) (/ 1.0 (* x (+ x 2))))
       a
       (lambda (x) (+ x 4))
       b))
\end{Verbatim}

Еще~с помощью {\tt lambda} мы можем записать
процедуру {\tt integral}, не определяя вспомогательную
процедуру {\tt add-dx}:

\begin{Verbatim}[fontsize=\small]
(define (integral f a b dx)\index{ru}{integral|с использованием \texttt{lambda}|||pd|}
  (* (sum f
          (+ a (/ dx 2.0))
          (lambda (x) (+ x dx))
          b)
     dx))
\end{Verbatim}

\index{ru}{процедура|создание~с помощью {\tt lambda}||||}\index{ru}{особые формы|\texttt{lambda}||||}~В общем случае, {\tt lambda} 
используется для
создания процедур точно так же, как {\tt define}, только
\index{ru}{define (особая форма)|vs. \texttt{lambda}|||p|}
\index{ru}{define (особая форма)|для процедур|||p|}
\index{ru}{lambda (особая форма)|vs. \texttt{define}|||p|}
никакого имени для процедуры не указывается:\index{ru}{процедура|безымянная||||}

\begin{Verbatim}[fontsize=\small]
(lambda (\textit{$\langle$формальные-параметры$\rangle$}) \textit{$\langle$тело$\rangle$})
\end{Verbatim}
Получается столь же полноценная процедура, как~и~с помощью
{\tt define}.  Единственная разница состоит~в том, что она не
связана ни~с каким именем~в окружении.  На самом деле

\begin{Verbatim}[fontsize=\small]
(define (plus4 x) (+ x 4))
\end{Verbatim}
эквивалентно

\begin{Verbatim}[fontsize=\small]
(define plus4 (lambda (x) (+ x 4)))
\end{Verbatim}
Можно читать выражение {\tt lambda} так:


\begin{center}
\begin{tabular}{ccccccl}
\tt{(lambda} & \tt{(x)}        &         & \hspace{-0,5em}\tt{(+}    & \tt{x}     & & {\tt 4))} \\
$\uparrow$   & $\uparrow$      &         & $\uparrow$ & $\uparrow$ & & $\uparrow$ \\ 
Процедура    & от аргумента x, & которая & складывает & x &~и & 4
\end{tabular}
\end{center}

Подобно любому выражению, значением которого является
процедура, выражение~с {\tt lambda} можно использовать как
оператор~в комбинации, например
\index{ru}{оператор комбинации|в виде \texttt{lambda}-выражения||||}
\index{ru}{\texttt{lambda}-выражение|как оператор~в комбинации|||p|}
\index{ru}{комбинация|\texttt{lambda}-выражение как оператор||||}

\begin{Verbatim}[fontsize=\small]
((lambda (x y z) (+ x y (square z))) 1 2 3)
\textit{12}
\end{Verbatim}
Или,~в более общем случае,~в любом контексте, где обычно используется
имя процедуры\footnote{Было бы более понятно~и менее страшно для изучающих Лисп, 
если бы здесь использовалось более ясное имя, чем {\tt lambda}, 
например {\tt make-procedure}.  Однако традиция уже прочно
укоренилась.  Эта нотация заимствована из 
$\lambda$-исчисления, формализма,
изобретенного математическим логиком  Алонсо Чёрчем
\index{ru}{Ч\"ерч, Алонсо||Alonzo Church||n|п}\index{en}{Alonzo Church||Ч\"ерч, Алонсо||n|п}
(Church 1941). Чёрч
разработал $\lambda$-исчисление, чтобы найти строгое
основание для понятий функции~и применения
функции. $\lambda$-исчисление стало основным инструментом
математических исследований по семантике языков
программирования.
\index{ru}{лямбда-исчисление ($\lambda$-исчисление)||$\lambda$ calculus|||п}\index{en}{$\lambda$ calculus||лямбда-исчисление ($\lambda$-исчисление)|||п}
}.

\paragraph{Создание локальных переменных~с помощью {\tt let}}


Еще одно применение {\tt lambda} состоит во
введении 
\index{ru}{локальное имя||local name|||}\index{en}{local name||локальное имя|||} 
\index{ru}{локальная переменная||local variable|||}\index{en}{local variable||локальная переменная|||} 
локальных переменных.  Часто нам~в процедуре бывают нужны
локальные переменные помимо тех, что связаны формальными
параметрами.  Допустим, например, что нам надо вычислить функцию
$$
f (x,y) = x (1+xy)^3 + y(1-y) + (1+xy)(1-y)
$$
которую мы также могли бы выразить как
$$
\begin{array}{rcl}
  a & = & 1 + xy \\
  b & = & 1 - y \\
  f (x,y) & = & xa^2 + yb + ab \\
\end{array}
$$
Когда мы пишем процедуру для вычисления $f$, хотелось
бы иметь как локальные переменные не только $x$ и
$y$, но~и имена для промежуточных результатов вроде
$a$~и $b$.  Можно сделать это~с помощью
вспомогательной процедуры, которая связывает локальные переменные:

\begin{Verbatim}[fontsize=\small]
(define (f x y)
  (define (f-helper a b)
    (+ (* x (square a))
       (* y b)
       (* a b)))
  (f-helper (+ 1 (* x y)) 
            (- 1 y)))
\end{Verbatim}

Разумеется, безымянную процедуру для 
связывания локальных переменных мы можем записать через
{\tt lambda}-выражение.  При этом тело {\tt f}
оказывается просто вызовом этой процедуры.

\begin{Verbatim}[fontsize=\small]
(define (f x y)
  ((lambda (a b)
     (+ (* x (square a))
        (* y b)
        (* a b)))
   (+ 1 (* x y))
   (- 1 y)))
\end{Verbatim}
Такая конструкция настолько полезна, что есть особая форма под
названием {\tt let}, 
\index{ru}{let (особая форма)||||pd|}
которая делает ее более удобной.  С
использованием {\tt let} процедуру {\tt f} можно
записать так:

\begin{Verbatim}[fontsize=\small]
(define (f x y)
  (let ((a (+ 1 (* x y)))
        (b (- 1 y)))
    (+ (* x (square a))
       (* y b)
       (* a b))))
\end{Verbatim} 
\index{ru}{особые формы|\texttt{let}||||}Общая форма выражения~с {\tt let} такова:

\begin{Verbatim}[fontsize=\small]
(let ((\textit{$\langle$пер${}_{\mbox{1}}$$\rangle$} \textit{$\langle$выр${}_{\mbox{1}}$$\rangle$})
      (\textit{$\langle$пер${}_{\mbox{2}}$$\rangle$} \textit{$\langle$выр${}_{\mbox{2}}$$\rangle$})
      ...
      (\textit{$\langle$пер${}_{\mbox{n}}$$\rangle$} \textit{$\langle$выр${}_{\mbox{n}}$$\rangle$}))
  \textit{$\langle$тело$\rangle$})
\end{Verbatim}
Это можно понимать как

\begin{quote}
Пусть \textit{$\langle$пер${}_{\mbox{1}}$$\rangle$} имеет значение
\textit{$\langle$выр${}_{\mbox{1}}$$\rangle$}\\
и \textit{$\langle$пер${}_{\mbox{2}}$$\rangle$} имеет значение \textit{$\langle$выр${}_{\mbox{2}}$$\rangle$}\\
...\\
и \textit{$\langle$пер${}_{\mbox{n}}$$\rangle$} имеет значение \textit{$\langle$выр${}_{\mbox{n}}$$\rangle$}\\
в \textit{$\langle$теле$\rangle$}
\end{quote}
Первая часть {\tt let}-выражения представляет собой список пар
вида имя--зна\-че\-ние. Когда {\tt let} вычисляется, каждое имя
связывается со значением соответствующего выражения.  Затем
вычисляется тело {\tt let}, причем эти имена связаны как локальные
переменные.  Происходит это так:
выражение {\tt let} интерпретируется как альтернативная форма
для

\begin{Verbatim}[fontsize=\small]
((lambda (\textit{$\langle$пер${}_{\mbox{1}}$$\rangle$} ... \textit{$\langle$пер${}_{\mbox{n}}$$\rangle$})
   \textit{$\langle$тело$\rangle$})
  \textit{$\langle$выр${}_{\mbox{1}}$$\rangle$} ... \textit{$\langle$выр${}_{\mbox{n}}$$\rangle$})
\end{Verbatim}
От интерпретатора не требуется никакого нового механизма связывания
переменных.  Выражение~с {\tt let}~--- это всего лишь синтаксический
сахар для вызова {\tt lambda}.
\index{ru}{let (особая форма)|как синтаксический сахар|||p|}
\index{ru}{синтаксический сахар|\texttt{let}||||}

\index{ru}{область действия переменной|в \texttt{let}||||}
Из этой эквивалентности мы видим, что область определения 
переменной, введенной~в {\tt let}-выражении --- тело
{\tt let}.  Отсюда следует, что:

\begin{plainlist}

\item
{\tt Let}
\index{ru}{let (особая форма)|область действия переменных|||p|}
позволяет связывать переменные
сколь угодно близко~к тому месту, где они используются. Например, если
значение {\tt x} равно 5, значение выражения

\begin{Verbatim}[fontsize=\small]
(+ (let ((x 3))
     (+ x (* x 10)))
   x)
\end{Verbatim}
равно 38.  Значение {\tt x}~в теле {\tt let} равно 3,
так что значение {\tt let}-выражения равно 33. С другой
стороны, {\tt x} как второй аргумент~к внешнему {\tt +}
по-прежнему равен~5.

\item
Значения переменных вычисляются за пределами
{\tt let}.  Это существенно, когда выражения, дающие
значения локальным переменным, зависят от переменных, которые имеют те
же имена, что~и сами локальные переменные.  Например, если значение
{\tt x} равно 2, выражение

\begin{Verbatim}[fontsize=\small]
(let ((x 3)
      (y (+ x 2)))
  (* x y))
\end{Verbatim}
будет иметь значение 12, поскольку внутри тела {\tt let}
{\tt x} будет равно 3,~а {\tt y} 4 (что равняется
внешнему {\tt x} плюс 2).
\end{plainlist}

\index{ru}{внутренние определения|vs. \texttt{let}||||}%
Иногда~с тем же успехом, что~и {\tt let}, можно
использовать внутренние определения.  Например, вышеописанную
процедуру {\tt f} мы могли бы определить как

\begin{Verbatim}[fontsize=\small]
(define (f x y)
  (define a (+ 1 (* x y)))
  (define b (- 1 y))
  (+ (* x (square a))
     (* y b)
     (* a b)))
\end{Verbatim}
В таких ситуациях, однако, мы предпочитаем использовать
{\tt let}, 
\index{ru}{let (особая форма)|vs. внутреннее определение|||p|}
а {\tt define} писать только при определении
локальных процедур\footnote{Если мы хотим понимать внутренние определения
настолько, чтобы быть уверенными, что программа действительно
соответствует нашим намерениям, то нам требуется более
сложная модель процесса вычислений, чем приведенная в
этой главе.  Однако~с внутренними определениями процедур эти тонкости
не возникают. К этому вопросу мы вернемся~в разделе~\ref{INTERNAL-DEFINITIONS-CH4}, после того, как
больше узнаем~о вычислении.
}.
\begin{exercise}{1.34}\label{EX1.34}%
Допустим, мы определили процедуру

\begin{Verbatim}
(define (f g)
  (g 2))
\end{Verbatim}
Тогда мы имеем

\begin{Verbatim}
(f square)
\textit{4}

(f (lambda (z) (* z (+ z 1))))
\textit{6}
\end{Verbatim}
Что случится, если мы (извращенно) попросим интерпретатор вычислить
комбинацию {\tt (f f)}? Объясните.
\end{exercise}

\subsection{Процедуры как обобщенные методы}
\label{PROCEDURES-AS-GENERAL-METHODS}

\index{ru}{процедура|как обобщенный метод||||}
Мы ввели составные процедуры~в разделе~\ref{COMPOUND-PROCEDURES}~в качестве механизма для
абстракции схем числовых операций, так, чтобы они были независимы от
конкретных используемых чисел. С процедурами высших порядков,
такими, как процедура {\tt integral} из раздела~\ref{PROCEDURES-AS-ARGUMENTS}, мы начали исследовать
более мощный тип абстракции:\index{ru}{процедура высшего порядка|процедура как обобщенный метод||||} процедуры, которые используются 
для выражения обобщенных методов вычисления, независимо от конкретных
используемых функций. В этом разделе мы рассмотрим два более
подробных примера --- общие методы нахождения нулей~и неподвижных
точек функций, ---~и покажем, как эти методы могут быть прямо выражены 
в виде процедур.

\paragraph{Нахождение корней уравнений методом половинного
деления}


\index{ru}{половинного деления метод||half-interval method|||}\index{en}{half-interval method||половинного деления метод|||}{\em Метод
половинного деления} (half-interval method) --- это простой, но мощный способ
нахождения корней уравнения $f(x) = 0$, где
$f$~--- непрерывная функция.  Идея состоит~в том, что если
нам даны такие
точки $a$~и $b$, что $f(a) < 0 <
f(b)$, то функция $f$ должна иметь по крайней мере
один ноль на отрезке между $a$~и $b$.  Чтобы
найти его, возьмем $x$, равное среднему между
$a$~и $b$,~и вычислим $f(x)$. Если
$f(x) > 0$, то $f$ должна иметь ноль на
отрезке между $a$~и $x$. Если $f(x) <
0$, то $f$ должна иметь ноль на отрезке между
$x$~и $b$.  Продолжая таким образом, мы сможем
находить все более узкие интервалы, на которых $f$ должна
иметь ноль.  Когда мы дойдем до точки, где этот интервал достаточно
мал, процесс останавливается.  Поскольку интервал неопределенности
уменьшается вдвое на каждом шаге процесса, число требуемых шагов
растет как $\Theta (\log (L / T))$, где $L$
есть длина исходного интервала,~а $T$ есть допуск 
ошибки (то есть размер интервала, который мы считаем <<достаточно
малым>>).  Вот процедура, которая реализует эту стратегию:

\begin{Verbatim}[fontsize=\small]
(define (search f neg-point pos-point)\index{ru}{search||||pd|}
  (let ((midpoint (average neg-point pos-point)))
    (if (close-enough? neg-point pos-point)
        midpoint
        (let ((test-value (f midpoint)))
          (cond ((positive? test-value)
                 (search f neg-point midpoint))
                ((negative? test-value)
                 (search f midpoint pos-point))
                (else midpoint))))))
\end{Verbatim}

Мы предполагаем, что вначале нам дается функция
$f$~и две точки,~в одной из которых значение функции
отрицательно,~в другой положительно.  Сначала мы вычисляем среднее
между двумя краями интервала.  Затем мы проверяем, не является ли
интервал уже достаточно малым,~и если да, сразу возвращаем среднюю
точку как ответ.  Если нет, мы вычисляем значение $f$ в
средней точке. Если это значение положительно, мы продолжаем процесс
с интервалом от исходной отрицательной точки до средней точки.  Если
значение~в средней точке отрицательно, мы продолжаем процесс с
интервалом от средней точки до исходной положительной точки.  Наконец, 
существует возможность, что значение~в средней точке~в точности равно
0,~и тогда средняя точка~и есть тот корень, который мы ищем.

Чтобы проверить, достаточно ли близки концы интервала, мы 
можем взять процедуру, подобную той, которая используется в
разделе~\ref{EXAMPLE-SQUARE-ROOTS-BY-NEWTONS-METHOD} при
вычислении квадратных корней\footnote{Мы использовали 0.001 как достаточно <<малое>> число, 
чтобы указать допустимую ошибку вычисления.
Подходящий допуск~в настоящих вычислениях зависит от
решаемой задачи, ограничений компьютера~и алгоритма.  Часто это весьма 
тонкий вопрос,~в котором требуется помощь 
\index{ru}{специалист по численному анализу||numerical analyst|||п}\index{en}{numerical analyst||специалист по численному анализу|||п} 
специалиста по численному
анализу или волшебника какого-нибудь другого рода.
}:

\begin{Verbatim}[fontsize=\small]
(define (close-enough? x y)
  (< (abs (- x y)) 0.001))
\end{Verbatim}

Использовать процедуру {\tt search}
непосредственно ужасно неудобно, поскольку случайно мы можем дать ей
точки,~в которых значения $f$ не имеют нужных знаков,~и в
этом случае мы получим неправильный ответ.  Вместо этого мы будем
использовать {\tt search} посредством следующей процедуры,
которая проверяет, который конец интервала имеет положительное, а
который отрицательное значение,~и соответствующим образом зовет
{\tt search}.  Если на обоих концах интервала функция имеет
одинаковый знак, метод половинного деления использовать нельзя, и
тогда процедура сообщает об ошибке\footnote{Этого можно добиться~с помощью процедуры
{\tt error}, 
\index{ru}{error (элементарная процедура)||||pd|п}
\index{ru}{элементарные процедуры|{\tt error} {\em (нс)}||||п} 
которая~в качестве аргументов принимает несколько
значений~и печатает их как сообщение об ошибке.
}:
\index{ru}{половинного деления метод|\texttt{half-interval-method}||||}

\begin{Verbatim}[fontsize=\small]
(define (half-interval-method f a b)\index{ru}{half-interval-method||||pd|}
  (let ((a-value (f a))
        (b-value (f b)))
    (cond ((and (negative? a-value) (positive? b-value))
           (search f a b))
          ((and (negative? b-value) (positive? a-value))
           (search f b a))
          (else
           (error "У аргументов не разные знаки " a b)))))
\end{Verbatim}

В следующем примере метод половинного деления используется,
чтобы вычислить\index{ru}{пи ($\pi$)|приближенное вычисление методом половинного деления||||}
$\pi$ как корень уравнения $\sin x =
0$, лежащий между 2~и 4.

\begin{Verbatim}[fontsize=\small]
(half-interval-method sin 2.0 4.0)
\textit{3.14111328125}
\end{Verbatim}

Во втором примере через метод половинного деления ищется
корень уравнения $x^3 - 2x - 3 = 0$, расположенный между 1~и 2:

\begin{Verbatim}[fontsize=\small]
(half-interval-method (lambda (x) (- (* x x x) (* 2 x) 3))
                      1.0
                      2.0)
\textit{1.89306640625}
\end{Verbatim}

\paragraph{Нахождение неподвижных точек функций}


Число $x$ называется 
\index{ru}{функция (математическая)|неподвижная точка||||}
\index{ru}{неподвижная точка||fixed point, of a function|||}\index{en}{fixed point, of a function||неподвижная точка|||}{\em неподвижной точкой} (fixed point)
функции $f$, если оно удовлетворяет уравнению $f(x) =
x$.  Для некоторых функций $f$ можно найти
неподвижную точку, начав~с какого-то значения~и применяя
$f$ многократно:
$$
f(x), f(f(x)), f(f(f(x))), \ldots
$$
--- пока значение не перестанет сильно изменяться. С помощью этой идеи мы 
можем составить процедуру {\tt fixed-point}, которая~в качестве 
аргументов принимает функцию~и начальное значение~и производит
приближение~к неподвижной точке функции. Мы многократно применяем
функцию, пока не найдем два последовательных значения, разница между
которыми меньше некоторой заданной чувствительности:

\begin{Verbatim}[fontsize=\small]
(define tolerance 0.00001)

(define (fixed-point f first-guess)\index{ru}{fixed-point||||pd|}
  (define (close-enough? v1 v2)
    (< (abs (- v1 v2)) tolerance))
  (define (try guess)
    (let ((next (f guess)))
      (if (close-enough? guess next)
          next
          (try next))))
  (try first-guess))
\end{Verbatim}
Например,~с помощью этого метода мы можем приближенно вычислить
\index{ru}{косинус|неподвижная точка функции|cosine|||}\index{en}{cosine||косинус|неподвижная точка функции||}
\index{ru}{неподвижная точка|функции косинус||||}
неподвижную точку функции косинус, начиная~с 1 как стартового 
приближения\footnote{Попробуйте во время 
\index{ru}{лекция, что на ней делать||something to do during a lecture|||п}\index{en}{something to do during a lecture||лекция, что на ней делать|||п} 
скучной лекции установить
\index{ru}{калькулятор; поиск неподвижных точек||fixed points with calculator|||п}\index{en}{fixed points with calculator||калькулятор; поиск неподвижных точек|||п} 
калькулятор в
режим радиан~и нажимать кнопку {\tt cos}, пока  
не найдете \index{ru}{неподвижная точка|вычисление~с помощью  калькулятора||||п} неподвижную точку.
}:
\index{ru}{cos (элементарная процедура)||||pd|}\index{ru}{элементарные процедуры|{\tt cos}||||} 

\begin{Verbatim}[fontsize=\small]
(fixed-point cos 1.0)
\textit{.7390822985224023}
\end{Verbatim}
Подобным образом можно найти решение уравнения $y = sin y +
cos y$:

\begin{Verbatim}[fontsize=\small]
(fixed-point (lambda (y) (+ (sin y) (cos y)))\index{ru}{элементарные процедуры|{\tt sin}||||}\index{ru}{sin (элементарная процедура)||||pd|} 
             1.0)
\textit{.2587315962971173}
\end{Verbatim}

Процесс поиска неподвижной точки похож на процесс,
с помощью которого мы искали квадратный корень~в 
разделе~\ref{EXAMPLE-SQUARE-ROOTS-BY-NEWTONS-METHOD}. И тот, и
другой основаны на идее последовательного улучшения приближений, пока
результат не удовлетворит какому-то критерию.  На самом деле мы без
труда можем сформулировать\index{ru}{неподвижная точка|квадратный корень||||}вычисление квадратного корня как поиск
неподвижной точки.  Вычислить квадратный корень из произвольного
числа $x$ означает найти такое $y$, что
$y^2 = x$. Переведя это уравнение~в эквивалентную форму
$y = x / y$, мы обнаруживаем, что должны найти
неподвижную точку функции\footnote{\index{ru}{функция (математическая)|$\mapsto$-нотация|function|||п}\index{en}{function||функция (математическая)|$\mapsto$-нотация||п}
\index{ru}{$\mapsto$, математическая запись для функций|||||п}
$\mapsto$ (произносится <<отображается
в>>) --- это математический способ написать
{\tt lambda}. $y \mapsto x / y$ означает
{\tt (lambda (y) (/ x y))}, то есть функцию, значение которой~в 
точке $y$ есть $x / y$.
}
$y \mapsto x / y$, и, следовательно, мы можем
попытаться вычислять квадратные корни так:

\begin{Verbatim}[fontsize=\small]
(define (sqrt x)
  (fixed-point (lambda (y) (/ x y))
               1.0))
\end{Verbatim}

К сожалению, этот поиск неподвижной точки не
сходится. Рассмотрим исходное значение $y_1$. Следующее
значение равно $y_2 = x / y_1$,~а следующее за ним
$y_3 = x / y_2 = x / (x / y_1) = y_1$.  В
результате выходит бесконечный цикл,~в котором два значения
$y_1$~и $y_2$ повторяются снова~и снова, прыгая
вокруг правильного ответа.

Один из способов управлять такими прыжками состоит~в том, 
чтобы заставить значения изменяться не так сильно.  Поскольку ответ
всегда находится между текущим значением $y$~и $x
/ y$, мы можем взять новое значение, не настолько далекое от
$y$, как $x / y$, взяв среднее между ними,
так что следующее значение будет не $x / y$, а
$\dfrac{1}{2}(y + x / y)$. Процесс получения такой
последовательности есть всего лишь процесс поиска неподвижной точки
$y \mapsto \dfrac{1}{2} (y + x / y)$.

\begin{Verbatim}[fontsize=\small]
(define (sqrt x)\index{ru}{sqrt|как неподвижная точка|||pd|}
  (fixed-point (lambda (y) (average y (/ x y)))
               1.0))
\end{Verbatim}
(Заметим, что $y = \dfrac{1}{2} (y + x / y)$ всего лишь
простая трансформация уравнения $y = x / y$; чтобы ее
получить, добавьте $y$~к обоим частям уравнения~и поделите
пополам.)

После такой модификации процедура поиска квадратного
корня начинает работать. В сущности, если мы рассмотрим определения,
мы увидим, что последовательность приближений~к квадратному корню,
порождаемая здесь,~в точности та же, что порождается нашей исходной
процедурой поиска квадратного корня из раздела~\ref{EXAMPLE-SQUARE-ROOTS-BY-NEWTONS-METHOD}. Этот
подход~с усреднением последовательных приближений~к решению, метод,
который мы называем 
\index{ru}{торможение усреднением||average damping|||}\index{en}{average damping||торможение усреднением|||}{\em торможение
усреднением} (average damping), часто помогает достичь сходимости при поисках неподвижной
точки.
\begin{exercise}{1.35}\label{EX1.35}%
Покажите, что\index{ru}{золотое сечение|как неподвижная точка||||(упр.~1.35)}\index{ru}{неподвижная точка|золотое  сечение||||(упр.~1.35)} золотое сечение $\phi$ 
(раздел~\ref{TREE-RECURSION}) есть неподвижная точка трансформации
$x \mapsto 1 + 1 / x$,~и используйте этот факт для
вычисления $\phi$~с помощью процедуры {\tt fixed-point}.
\end{exercise}
\begin{exercise}{1.36}\label{EX1.36}%
Измените процедуру {\tt fixed-point} так, чтобы
она печатала последовательность приближений, которые порождает, с
помощью примитивов {\tt newline}~и {\tt display},
показанных~в упражнении~\ref{EX1.22}. Затем найдите решение
уравнения $x^x = 1000$ путем поиска неподвижной точки
$x \mapsto \log (1000) / \log (x)$. (Используйте
встроенную процедуру Scheme {\tt log},
\index{ru}{log (элементарная процедура)||||pd|(упр.~1.36)}
\index{ru}{элементарные процедуры|{\tt log}||||(упр.~1.36)} 
которая вычисляет
натуральные логарифмы.) Посчитайте, сколько шагов это занимает при
использовании торможения усреднением~и без него. (Учтите, что нельзя
начинать {\tt fixed-point} со значения 1, поскольку это вызовет 
деление на $\log(1) = 0$.)
\end{exercise}
\begin{exercise}[]{1.37}\label{EX1.37}%
\begin{plainenum}
\item Бесконечная\index{ru}{цепная дробь||continued fraction|||(упр.~1.37)}\index{en}{continued fraction||цепная дробь|||(упр.~1.37)}{\em цепная
дробь} (continued fraction) есть выражение вида
$$
f = \dfrac{N_1}{D_1 + \dfrac{N_2}{D_2 + \dfrac{N_3}{D_3 + \ldots}}}
$$
В качестве примера можно показать, что расширение бесконечной цепной
дроби при всех $N_i$~и $D_i$, равных 1, дает
$1 / \phi$, где $\phi$ --- золотое сечение
\index{ru}{цепная дробь|золотое сечение||||(упр.~1.37)}
\index{ru}{золотое сечение|как цепная дробь||||(упр.~1.37)}
(описанное~в разделе~\ref{TREE-RECURSION}). Один из
способов вычислить цепную дробь состоит~в том, чтобы после заданного
количества термов оборвать вычисление.  Такой обрыв --- так называемая
\index{ru}{конечная цепная дробь||finite continued fraction|||(упр.~1.37)}\index{en}{finite continued fraction||конечная цепная дробь|||(упр.~1.37)}{\em конечная цепная дробь} (finite continued fraction) из
$k$ элементов, --- имеет вид
$$
f = \dfrac{N_1}{D_1 + \dfrac{N_2}{D_2 + \ldots \dfrac{N_k}{D_k}}}
$$
Предположим, что {\tt n}~и {\tt d} --- процедуры одного
аргумента (номера элемента $i$), возвращающие
$N_i$~и $D_i$ элементов цепной дроби.  Определите
процедуру {\tt cont-frac} так, чтобы вычисление
{\tt (cont-frac n d k)} давало значение $k$-элементной
конечной цепной дроби.  Проверьте свою процедуру, вычисляя приближения 
к $1 / \phi$~с помощью

\begin{Verbatim}
(cont-frac (lambda (i) 1.0)
           (lambda (i) 1.0)
           k)
\end{Verbatim}

для последовательных значений {\tt k}.  Насколько большим
пришлось сделать {\tt k}, чтобы получить приближение, верное с
точностью 4 цифры после запятой?

\item Если Ваша процедура {\tt cont-frac}
порождает рекурсивный процесс, напишите вариант, который порождает
итеративный процесс.  Если она порождает итеративный процесс, напишите 
вариант, порождающий рекурсивный процесс.
\end{plainenum}
\end{exercise}
\begin{exercise}{1.38}\label{EX1.38}%
В 1737 году швейцарский математик Леонард Эйлер
\index{ru}{Эйлер, Леонард||Leonhard Euler||n|(упр.~1.38)}\index{en}{Leonhard Euler||Эйлер, Леонард||n|(упр.~1.38)}
опубликовал статью {\em De fun\-cti\-oni\-bus
Continuis}, которая содержала расширение цепной дроби для
\index{ru}{$e$|как цепная дробь||||(упр.~1.38)}
$e - 2$, где $e$ --- основание натуральных
логарифмов.\index{ru}{цепная дробь|$e$||||(упр.~1.38)} В этой дроби все $N_i$ равны 1, а
$D_i$ последовательно равны $1, 2, 1, 1, 4, 1, 1, 6,
1, 1, 8, \ldots$Напишите программу, использующую Вашу процедуру
{\tt cont-frac} из упражнения~\ref{EX1.37} для
вычисления $e$ на основании формулы Эйлера.
\end{exercise}
\begin{exercise}{1.39}\label{EX1.39}%
\index{ru}{цепная дробь|тангенс||||(упр.~1.39)}%
\index{ru}{тангенс|как цепная дробь|tangent|||(упр.~1.39)}%
\index{en}{tangent||тангенс|как цепная дробь||(упр.~1.39)}%
Представление тангенса~в виде цепной дроби было
опубликовано~в 1770 году немецким математиком  Й.Х. Ламбертом:
$$
\tg x = \dfrac{x}{1 - \dfrac{x^2}{3 - \dfrac{x^2}{5 - \ldots}}}
$$%%%%!!!! Что со степенями при x????!!!! 
%% tan или tg? -- MR
где $x$ дан~в радианах.  Определите процедуру {\tt (tan-cf 
x k)}, которая вычисляет приближение~к тангенсу на основе
формулы Ламберта. {\tt K} указывает количество термов, которые
требуется вычислить, как~в упражнении~\ref{EX1.37}.
\end{exercise}

\subsection{Процедуры как возвращаемые значения}
\label{PROCEDURES-AS-RETURNED-VALUES}


\index{ru}{процедура высшего порядка|процедура как возвращаемое значение||||}\index{ru}{процедура|как  возвращаемое значение||||}Предыдущие примеры показывают, что возможность передавать
процедуры~в качестве аргументов значительно увеличивает выразительную
силу нашего языка программирования.  Мы можем добиться еще большей
выразительной силы, создавая процедуры, возвращаемые значения которых
сами являются процедурами.

Эту идею можно проиллюстрировать примером с
поиском неподвижной точки, обсуждаемым~в конце раздела~\ref{PROCEDURES-AS-GENERAL-METHODS}.  Мы
сформулировали новую версию процедуры вычисления квадратного корня как 
поиск неподвижной точки, начав~с наблюдения, что $\sqrt{x}$ 
есть неподвижная точка функции $y \mapsto x / y$.
Затем мы использовали торможение усреднением, чтобы заставить
приближения сходиться.  Торможение усреднением само по себе является
полезным приемом. А именно, получив функцию $f$, мы
возвращаем функцию, значение которой~в точке х есть среднее
арифметическое между $x$~и $f(x)$.

Идею торможения усреднением мы можем выразить при помощи
следующей процедуры:

\begin{Verbatim}[fontsize=\small]
(define (average-damp f)\index{ru}{average-damp||||pd|}
  (lambda (x) (average x (f x))))
\end{Verbatim}
{\tt Average-damp} --- это процедура, принимающая~в качестве
аргумента процедуру {\tt f}~и возвращающая~в качестве значения
процедуру (полученную~с помощью {\tt lambda}), которая, будучи
применена~к числу {\tt x}, возвращает среднее между
{\tt x}~и {\tt (f x)}.  Например, применение
{\tt average-damp}~к процедуре {\tt square} получает
процедуру, значением которой для некоторого числа $x$ будет 
среднее между $x$~и $x^2$.  Применение этой
процедуры~к числу 10 возвращает среднее между 10~и 100, то есть 55\footnote{Заметьте, что здесь мы имеем 
\index{ru}{оператор комбинации|как комбинация||||п} 
\index{ru}{комбинация|с оператором-комбинацией||||п}
\index{ru}{комбинация|как оператор комбинации||||п}
комбинацию, оператор
которой сам по себе комбинация.~В упражнении~\ref{EX1.4} уже 
была продемонстрирована возможность таких комбинаций, но то был всего
лишь игрушечный пример.  Здесь мы начинаем чувствовать настоящую
потребность~в выражениях такого рода --- когда нам нужно применить
процедуру, полученную~в качестве значения из процедуры высшего порядка.
}:

\begin{Verbatim}[fontsize=\small]
((average-damp square) 10)
\textit{55}
\end{Verbatim}

\index{ru}{неподвижная точка|квадратный корень||||} Используя {\tt average-damp}, мы можем
переформулировать процедуру вычисления квадратного корня следующим
образом:

\begin{Verbatim}[fontsize=\small]
(define (sqrt x) \index{ru}{sqrt|как неподвижная точка|||pd|}
  (fixed-point (average-damp (lambda (y) (/ x y)))
               1.0))
\end{Verbatim}
Обратите внимание, как такая формулировка делает явными три идеи нашего метода: 
поиск неподвижной точки, торможение усреднением~и функцию $y
\mapsto x / y$.  Полезно сравнить такую формулировку метода
поиска квадратного корня~с исходной версией, представленной в
разделе~\ref{EXAMPLE-SQUARE-ROOTS-BY-NEWTONS-METHOD}.
Вспомните, что обе процедуры выражают один~и тот же процесс, и
посмотрите, насколько яснее становится его идея, когда мы выражаем
процесс~в терминах этих абстракций. В общем случае существует много
способов сформулировать процесс~в виде процедуры.  Опытные
программисты знают, как выбрать те формулировки процедур, которые
наиболее ясно выражают их мысли,~и где полезные элементы процесса
показаны~в виде отдельных сущностей, которые можно использовать в
других приложениях.  Чтобы привести простой пример такого нового использования,
заметим, что кубический корень $x$ является неподвижной
точкой функции $y \mapsto x / y^2$, так что мы можем
немедленно обобщить нашу процедуру поиска квадратного корня так, чтобы
она извлекала\index{ru}{неподвижная точка|кубический корень||||} кубические корни\footnote{См. дальнейшее обобщение~в упражнении~\ref{EX1.45}}:

\begin{Verbatim}[fontsize=\small]
(define (cube-root x)\index{ru}{cube-root||||pd|}\index{ru}{кубический корень|как неподвижная точка||||}
  (fixed-point (average-damp (lambda (y) (/ x (square y))))
               1.0))
\end{Verbatim}

\paragraph{Метод Ньютона}


\index{ru}{Ньютона метод|для дифференцируемых функций||||} Когда~в разделе~\ref{EXAMPLE-SQUARE-ROOTS-BY-NEWTONS-METHOD} мы впервые
представили процедуру извлечения квадратного корня, мы упомянули, что
это лишь частный случай{\em метода
Ньютона} (Newton's method).\index{ru}{Ньютона метод||Newton's method|||}\index{en}{Newton's method||Ньютона метод|||} Если $x \mapsto g(x)$ есть дифференцируемая 
функция, то решение уравнения $g(x) = 0$ есть неподвижная 
точка функции $x \mapsto f(x)$, где
$$
f(x) = x - \dfrac{g(x)}{Dg(x)}
$$
\index{ru}{неподвижная точка|в методе Ньютона||||}а $Dg(x)$ есть
производная $g$, вычисленная в
точке $x$. Метод Ньютона состоит~в том, чтобы применить
описанный способ поиска неподвижной точки~и аппроксимировать
решение уравнения путем поиска неподвижной точки функции
$f$.\footnote{Вводные курсы анализа обычно описывают метод Ньютона
через последовательность приближений $x_{n+1} = x_n - g(x_n)
/ Dg(x_n)$.  Наличие языка, на котором мы можем
говорить~о процессах,~а также использование идеи неподвижных точек,
упрощают описание этого метода.
}
Для многих функций $g$ при достаточно хорошем начальном
значении $x$ метод Ньютона очень быстро приводит~к решению
уравнения $g(x) = 0$\footnote{Метод Ньютона не всегда приводит~к решению, но можно
показать, что~в удачных случаях каждая итерация удваивает точность
приближения~в терминах количества цифр после запятой.\index{ru}{Ньютона метод|vs. метод половинного деления||||п} Для таких
случаев метод Ньютона сходится гораздо быстрее, чем метод половинного
деления.
}.

\index{ru}{дифференцирование|численное|differentiation|||}\index{en}{differentiation||дифференцирование|численное||}
Чтобы реализовать метод Ньютона~в виде процедуры, 
сначала нужно выразить понятие\index{ru}{функция (математическая)|производная||||} производной.  
Заметим, что <<взятие производной>>, подобно торможению усреднением,
трансформирует одну функцию~в другую.  Например, производная функции
$x \mapsto x^3$ есть функция $x \mapsto 3x^2$.~В 
общем случае, если $g$ есть функция,~а $dx$ ---
маленькое число, то производная $Dg$ функции $g$ есть
функция, значение которой~в каждой точке $x$ описывается
формулой (при $dx$, стремящемся~к нулю)
$$
Dg(x) = \dfrac{g(x + dx) - g(x)}{dx}
$$
Таким образом, мы можем выразить понятие\index{ru}{производная функции|||||}
производной (взяв $dx$ равным, например, 0.00001)~в виде процедуры

\begin{Verbatim}[fontsize=\small]
(define (deriv g)\index{ru}{deriv (численная)||||pd|}
  (lambda (x)
    (/ (- (g (+ x dx)) (g x))
       dx)))
\end{Verbatim}
дополненной определением

\begin{Verbatim}[fontsize=\small]
(define dx 0.00001)
\end{Verbatim}

Подобно {\tt average-damp}, {\tt deriv}
является процедурой, которая берет процедуру~в качестве аргумента и
возвращает процедуру как значение.  Например, чтобы найти приближенное 
значение производной $x \mapsto x^3$~в точке 5 (точное
значение производной равно 75), можно вычислить 

\begin{Verbatim}[fontsize=\small]
(define (cube x) (* x x x))\index{ru}{cube||||pd|}

((deriv cube) 5)
\textit{75.00014999664018}
\end{Verbatim}

С помощью {\tt deriv} мы можем выразить метод
Ньютона как процесс поиска неподвижной точки:

\begin{Verbatim}[fontsize=\small]
(define (newton-transform g)\index{ru}{newton-transform||||pd|}
  (lambda (x)
    (- x (/ (g x) ((deriv g) x)))))

(define (newtons-method g guess)\index{ru}{newtons-method||||pd|}
  (fixed-point (newton-transform g) guess))
\end{Verbatim}
Процедура {\tt newton-transform} выражает формулу, приведенную
в начале этого раздела,~а {\tt newtons-method} легко
определяется~с ее помощью. В качестве аргументов она принимает
процедуру, вычисляющую функцию, чей ноль мы хотим найти, а
также начальное значение приближения. \index{ru}{Ньютона метод|для квадратных корней||||}
Например, чтобы найти
квадратный корень $x$, мы можем~с помощью метода Ньютона
найти ноль функции $y \mapsto y^2 - x$, начиная со значения 
1\footnote{\index{ru}{половинного деления метод|vs. метод Ньютона||||п} При поиске квадратных корней метод
Ньютона быстро сходится~к правильному решению, начиная~с любой точки.}.
Это дает нам еще одну форму процедуры вычисления квадратного корня:

\begin{Verbatim}[fontsize=\small]
(define (sqrt x)\index{ru}{sqrt|с методом Ньютона|||pd|}
  (newtons-method (lambda (y) (- (square y) x))
                  1.0))
\end{Verbatim}

\paragraph{Абстракции~и процедуры как полноправные
объекты}


Мы видели два способа представить вычисление квадратного
корня как частный случай более общего \mbox{метода}; один раз это был поиск
неподвижной точки, другой~--- метод Ньютона.  Поскольку сам метод Ньютона
был выражен как процесс поиска неподвижной точки, на самом деле мы
увидели два способа вычислить квадратный корень как неподвижную точку.
Каждый из этих методов получает некоторую функцию и
находит\index{ru}{неподвижная точка|трансформации некоторой
  функции||||}
неподвижную точку для некоторой трансформации этой функции. Эту общую идею 
мы можем выразить как процедуру:

\begin{Verbatim}[fontsize=\small]
(define (fixed-point-of-transform g transform guess)\index{ru}{fixed-point-of-transform||||pd|}
  (fixed-point (transform g) guess))
\end{Verbatim}
Эта очень общая процедура принимает~в качестве аргументов процедуру
{\tt g}, которая вычисляет некоторую функцию, процедуру,
которая трансформирует {\tt g},~и начальное приближение.
Возвращаемое значение есть неподвижная точка трансформированной
функции.

\index{ru}{неподвижная точка|квадратный корень||||}С помощью такой абстракции можно
переформулировать 
процедуру вычисления квадратного корня из этого раздела (ту, где мы
ищем неподвижную точку версии $y \mapsto x / y$,
заторможенной усреднением) как частный случай общего метода:

\begin{Verbatim}[fontsize=\small]
(define (sqrt x) \index{ru}{sqrt|как неподвижная точка|||pd|}
  (fixed-point-of-transform (lambda (y) (/ x y))
                            average-damp
                            1.0))
\end{Verbatim}
Подобным образом, вторую процедуру нахождения\index{ru}{Ньютона метод|для квадратных корней||||} 
квадратного корня из этого раздела (пример применения метода
Ньютона, который находит неподвижную точку Ньютонова преобразования
$y \mapsto y^2 - x$) можно представить так:

\begin{Verbatim}[fontsize=\small]
(define (sqrt x)\index{ru}{sqrt|как неподвижная точка|||pd|} \index{ru}{sqrt|с методом Ньютона|||pd|}
  (fixed-point-of-transform (lambda (y) (- (square y) x))
                            newton-transform
                            1.0))
\end{Verbatim}

Мы начали раздел~\ref{FORMULATING-ABSTRACTIONS-WITH-HIGHER-ORDER-PROCEDURES}
с наблюдения, что составные процедуры являются важным механизмом
абстракции, поскольку они позволяют выражать общие методы вычисления~в 
виде явных элементов нашего языка программирования.  Теперь мы
увидели, как процедуры высших порядков позволяют нам манипулировать
этими общими методами~и создавать еще более глубокие абстракции.

Как программисты, мы должны быть готовы распознавать
возможности поиска абстракций, лежащих~в основе наших программ,
строить нашу работу на таких абстракциях~и обобщать их, создавая еще
более мощные абстракции.  Это не значит, что программы
всегда нужно писать на возможно более глубоком уровне абстракции:
опытные программисты умеют выбирать тот уровень, который лучше всего
подходит~к их задаче.  Однако важно быть готовыми мыслить~в терминах
этих абстракций~и быть готовым применить их~в новых контекстах.
Важность процедур высшего порядка состоит~в том, что они позволяют нам 
явно представлять эти абстракции~в качестве элементов нашего языка
программирования, так что мы можем обращаться~с ними так же, как~и с
другими элементами вычисления.

В общем случае языки программирования накладывают
ограничения на способы,~с помощью которых можно манипулировать элементами
вычисления.  Говорят, что элементы, на которые накладывается наименьшее число
ограничений, имеют статус элементов вычисления 
\index{ru}{элементы вычисления первого класса||first-class elements of computation|||}\index{en}{first-class elements of computation||элементы вычисления первого класса|||}{\em первого 
класса} (first-class) или \index{ru}{полноправные элементы вычисления||first-class elements of computation|||}\index{en}{first-class elements of computation||полноправные элементы вычисления|||}{\em полноправных}. Вот
некоторые из их <<прав~и привилегий>>\footnote{Понятием полноправного статуса элементов языка
программирования мы обязаны британскому специалисту по информатике Кристоферу Стрейчи (1916-1975).
\index{ru}{Стрейчи, Кристофер||Christopher Strachey||n|п}\index{en}{Christopher Strachey||Стрейчи, Кристофер||n|п}
}:

\begin{plainlist}

\item
Их можно называть~с помощью переменных.

\item
Их можно передавать~в процедуры~в качестве аргументов.

\item
Их можно возвращать из процедур~в виде результата.

\item
Их можно включать~в структуры данных\footnote{Примеры этого мы увидим после того, как введем
понятие структур данных~в главе~\ref{BUILDING-ABSTRACTIONS-WITH-DATA}.
}.
\end{plainlist}

\index{ru}{Lisp (Лисп)|процедуры как объекты первого класса||||}Лисп,~в отличие от
других распространенных языков программирования, дает
процедурам\index{ru}{процедура|полноправный статус~в Лиспе||||} полноправный статус.  Это может быть проблемой для
эффективной реализации, но зато получаемый выигрыш~в выразительной
силе огромен\footnote{Основная цена, которую реализации приходится платить
за придание процедурам статуса полноправных объектов, состоит~в том,
что, поскольку мы разрешаем возвращать процедуры как значения, нам
нужно оставлять память для хранения свободных переменных процедуры
даже тогда, когда она не выполняется. В реализации Scheme, которую мы 
рассмотрим~в разделе~\ref{THE-METACIRCULAR-EVALUATOR}, эти
переменные хранятся~в окружении процедуры.}.
%2myself: там сноска пока что залазитт на сл. страницу, проверить после того,
%как уберем лишние верт. пробелы~в упр.

\begin{exercise}{1.40}\label{EX1.40}%
Определите процедуру {\tt cubic}, которую можно
было бы использовать совместно~с процедурой
{\tt newtons-method}~в выражениях вида

\begin{Verbatim}[fontsize=\small]
(newtons-method (cubic a b c) 1)
\end{Verbatim}
для приближенного вычисления нулей кубических уравнений $x^3 +
ax^2 + bx + c$.
\end{exercise}
\begin{exercise}{1.41}\label{EX1.41}%
Определите процедуру {\tt double}, которая
принимает как аргумент процедуру~с одним аргументом~и возвращает
процедуру, которая применяет исходную процедуру дважды.  Например,
если процедура {\tt inc} добавляет~к своему аргументу 1, то
{\tt (double inc)} должна быть процедурой, которая добавляет
2.  Скажите, какое значение возвращает

\begin{Verbatim}
(((double (double double)) inc) 5)
\end{Verbatim}
\end{exercise}
\begin{exercise}{1.42}\label{EX1.42}%
Пусть $f$~и $g$ --- две
одноаргументные функции.  По определению,\index{ru}{функция (математическая)|композиция||||(упр.~1.42)} 
\index{ru}{композиция функций||composition of functions|||(упр.~1.42)}\index{en}{composition of functions||композиция функций|||(упр.~1.42)}{\em композиция} 
(com\-po\-si\-tion) 
$f$~и $g$ есть функция 
$x \mapsto f(g(x))$. Определите процедуру {\tt compose}
которая реализует композицию.  Например, если {\tt inc} ---
процедура, добавляющая к своему аргументу~1,

\begin{Verbatim}
((compose square inc) 6)
\textit{49}
\end{Verbatim}

\end{exercise}
\begin{exercise}{1.43}\label{EX1.43}%
Если $f$ есть численная функция, а
$n$ --- положительное целое число, то мы можем построить
\index{ru}{функция (математическая)|многократное применение||||(упр.~1.43)} 
$n$-кратное применение $f$, которое
определяется как функция, значение которой~в точке $x$
равно $f(f( \ldots (f(x)) \ldots ))$. Например, если
$f$ есть функция $x \mapsto x + 1$, то
$n$-кратным применением $f$ будет функция
$x \mapsto x + n$.  Если $f$ есть операция
возведения~в квадрат, то $n$-кратное применение
$f$ есть функция, которая возводит свой аргумент в
$2^n$-ю степень.  Напишите процедуру, которая принимает~в 
качестве ввода процедуру, вычисляющую $f$,~и положительное
целое $n$,~и возвращает процедуру, вычисляющую
$n$-кратное применение $f$.  Требуется, чтобы
Вашу процедуру можно было использовать~в таких контекстах:

\begin{Verbatim}
((repeated square 2) 5)
\textit{625}
\end{Verbatim}

Подсказка: может оказаться удобно использовать {\tt compose} из 
упражнения~\ref{EX1.42}.
\end{exercise}
\begin{exercise}{1.44}\label{EX1.44}%
\index{ru}{обработка сигналов|сглаживание функции|signal processing|||(упр.~1.44)}%
\index{en}{signal processing||обработка сигналов|сглаживание функции||(упр.~1.44)}% 
\index{ru}{функция (математическая)|сглаживание||||(упр.~1.44)}% 
\index{ru}{сглаживание функции|||||(упр.~1.44)}%
Идея \index{ru}{сглаживание функции||smoothing a function|||(упр.~1.44)}\index{en}{smoothing a function||сглаживание функции|||(упр.~1.44)}{\em  
сглаживания} (smoothing a function) играет 
важную роль~в обработке сигналов.  Если $f$ --- функция, а
$dx$ --- некоторое малое число, то сглаженная версия
$f$ есть функция, значение которой~в точке $x$
есть среднее между $f (x-dx)$, $f(x)$~и $f
(x+dx)$. Напишите процедуру {\tt smooth}, которая в
качестве ввода принимает процедуру, вычисляющую $f$, и
возвращает процедуру, вычисляющую сглаженную версию $f$.
Иногда бывает удобно проводить повторное сглаживание (то есть
сглаживать сглаженную функцию~и т.д.), получая \index{ru}{n-кратно сглаженная функция||n-fold smoothed function|||(упр.~1.44)}\index{en}{n-fold smoothed function||n-кратно сглаженная функция|||(упр.~1.44)}{\em $n$-кратно сглаженную функцию} (n-fold smoothed function).
Покажите, как породить $n$-кратно сглаженную функцию с
помощью {\tt smooth}~и {\tt repeated} из 
упражнения~\ref{EX1.43}.
\end{exercise}
\begin{exercise}{1.45}\label{EX1.45}%
В разделе~\ref{PROCEDURES-AS-GENERAL-METHODS} мы видели, что
попытка вычисления квадратных корней путем наивного поиска неподвижной 
точки $y \mapsto x / y$ не сходится,~и что это можно
исправить путем торможения усреднением.  Тот же самый метод работает
для нахождения кубического корня как неподвижной точки $y \mapsto 
x / y^2$, заторможенной усреднением. К сожалению, этот
процесс не работает для 
\index{ru}{корень четвертой степени как неподвижная точка||fourth root as fixed point|||(упр.~1.45)}\index{en}{fourth root as fixed point||корень четвертой степени как неподвижная точка|||(упр.~1.45)}
\index{ru}{неподвижная точка|корень  четвертой степени||||(упр.~1.45)}корней четвертой степени --- однажды
примененного торможения усреднением недостаточно, чтобы заставить
сходиться процесс поиска неподвижной точки $y \mapsto x /
y^3$. С другой стороны, если мы применим торможение усреднением 
дважды (т.е. применим торможение усреднением~к результату торможения
усреднением от $y \mapsto x / y^3$), то поиск
неподвижной точки начнет сходиться.  Проделайте эксперименты, чтобы
понять, сколько торможений усреднением нужно, чтобы вычислить 
\index{ru}{корень $n$-й степени как неподвижная точка||$n$th root as fixed point|||(упр.~1.45)}\index{en}{$n$th root as fixed point||корень $n$-й степени как неподвижная точка|||(упр.~1.45)}
корень $n$-ой степени как неподвижную точку на основе
многократного торможения усреднением функции $y \mapsto x /
y^{n-1}$.  Используя свои результаты для того, напишите
простую процедуру вычисления\index{ru}{неподвижная точка|корень $n$-ной степени||||(упр.~1.45)}корней $n$-ой степени с
помощью процедур {\tt fixed-point}, {\tt average-damp}~и 
{\tt repeated} из упражнения~\ref{EX1.43}.  Считайте, 
что все арифметические операции, какие Вам понадобятся, присутствуют~в 
языке как примитивы.
\end{exercise}

\begin{exercise}{1.46}\label{EX1.46}%
Некоторые из вычислительных методов, описанных~в этой
главе, являются примерами чрезвычайно общей вычислительной стратегии,
называемой\index{ru}{пошаговое улучшение||iterative improvement|||(упр.~1.46)}\index{en}{iterative improvement||пошаговое улучшение|||(упр.~1.46)}{\em \index{ru}{неподвижная точка|как пошаговое улучшение||||(упр.~1.46)} пошаговое 
улучшение} (iterative improvement).  Пошаговое улучшение состоит~в следующем: чтобы
что-то вычислить, нужно взять какое-то начальное значение,
проверить, достаточно ли оно хорошо, чтобы служить ответом,~и если
нет, то улучшить это значение~и продолжить процесс~с новым
значением.  Напишите процедуру {\tt iterative-improve}, которая 
принимает~в качестве аргументов две процедуры:  проверку, достаточно
ли хорошо значение,~и метод улучшения значения.
{\tt Iterative-improve} должна возвращать процедуру, которая
принимает начальное значение~в качестве аргумента~и улучшает его, пока 
оно не станет достаточно хорошим.  Перепишите процедуру
{\tt sqrt}
\index{ru}{sqrt|как пошаговое улучшение|||p|(упр.~1.46)}
из раздела~\ref{EXAMPLE-SQUARE-ROOTS-BY-NEWTONS-METHOD}
и процедуру {\tt fixed-point} из
\index{ru}{fixed-point|как пошаговое улучшение|||p|(упр.~1.46)}
раздела~\ref{PROCEDURES-AS-GENERAL-METHODS}~в терминах
{\tt iterative-improve}. 
\end{exercise}
